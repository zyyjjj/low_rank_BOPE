{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f2441e",
   "metadata": {},
   "source": [
    "#  LSPE for logD Optimization with Human Feedback\n",
    "\n",
    "This notebook illustrates a use-case for LSPE in the screening of molecules based on their octanol/water distribution coefficient (logD at pH 7.4)  using simulated binary feedback from a human research chemist. The dataset used is from [1] and the code for the molecular GP kernels is from [2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dbd2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports \"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Turn off Graphein warnings\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "from itertools import combinations\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit import Chem\n",
    "\n",
    "from botorch import fit_gpytorch_model\n",
    "from botorch.acquisition import GenericMCObjective, LearnedObjective\n",
    "from botorch.acquisition.monte_carlo import qNoisyExpectedImprovement, qSimpleRegret\n",
    "from botorch.acquisition.preference import AnalyticExpectedUtilityOfBestOption\n",
    "from botorch.models.deterministic import FixedSingleSampleModel\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.sampling import SobolQMCNormalSampler\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "from molecule_utilities.dataloader import DataLoaderMP\n",
    "from molecule_utilities.dataloader.data_utils import transform_data\n",
    "from molecule_utilities.kernels.tanimoto_kernel import TanimotoKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35a944b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Utility functions for generating ground truth preference data simulated from a research chemist.\"\"\"\n",
    "\n",
    "def generate_initial_comparisons(y, n_comp, replace=False):\n",
    "    \"\"\"Create noiseless pairwise comparisons with noise assuming y is 1d. This function is used to \n",
    "       generate initial comparisons only.\n",
    "    \n",
    "    Args:\n",
    "        y: 1D Tensor of ground truth utilities (labels)\n",
    "        n_comp: Int specifying the number of initial pairwise comparisons\n",
    "        replace: Bool indicating whether to generate comparisons with replacement\n",
    "        \n",
    "    Returns:\n",
    "        comp_pairs: NumPy array of pairwise prefernces\n",
    "    \"\"\"\n",
    "    \n",
    "    # generate all possible pairs of elements in y\n",
    "    all_pairs = np.array(list(combinations(range(y.shape[0]), 2)))\n",
    "    # randomly select n_comp pairs from all_pairs\n",
    "    comp_pairs = all_pairs[np.random.choice(range(len(all_pairs)), n_comp, replace=replace)]\n",
    "    c0 = y[comp_pairs[:, 0]]\n",
    "    c1 = y[comp_pairs[:, 1]]\n",
    "    reverse_comp = (c0 < c1)\n",
    "    comp_pairs[reverse_comp, :] = np.flip(comp_pairs[reverse_comp, :], 1)\n",
    "    comp_pairs = torch.tensor(comp_pairs).long()\n",
    "\n",
    "    return comp_pairs\n",
    "\n",
    "def generate_comparisons(util):\n",
    "    \"\"\"Given an 1-d tensor of utility, create pairwise comparisons between adjacent items. This function\n",
    "       is used only within the Bayesian optimization loop (i.e. not for intialization).\n",
    "    \n",
    "    Args:\n",
    "        util: 1D Tensor of ground truth utilities (labels)\n",
    "        \n",
    "    Returns:\n",
    "        comp_pairs: NumPy array of pairwise preferences\n",
    "    \"\"\"\n",
    "    \n",
    "    util = util.reshape(-1, 2)\n",
    "    comp_pairs = torch.arange(util.numel()).reshape(-1, 2)\n",
    "    flip = util[:, 0] < util[:, 1]\n",
    "    comp_pairs[flip, [0]], comp_pairs[flip, [1]] = comp_pairs[flip, [1]], comp_pairs[flip, [0]]\n",
    "\n",
    "    return comp_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c832cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_random_observations(best_random, heldout_inputs, heldout_outputs):\n",
    "    \"\"\"\n",
    "    Simulates a random policy by taking a the current list of best values observed randomly,\n",
    "    drawing a new random point from the heldout set, observing its value, and updating the list.\n",
    "\n",
    "    Args:\n",
    "        best_random: List of best random values observed so far\n",
    "        heldout_inputs: Tensor of inputs\n",
    "        heldout_outputs: Tensor of output values\n",
    "\n",
    "    Returns: best_random, float specifying the objective function value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Take a random sample by permuting the indices and selecting the first element.\n",
    "    index = torch.randperm(len(heldout_outputs))[0]\n",
    "    next_random_best = heldout_outputs[index]\n",
    "    best_random.append(max(best_random[-1], next_random_best))\n",
    "\n",
    "    # Delete the selected input and value from the heldout set.\n",
    "    heldout_inputs = torch.cat((heldout_inputs[:index], heldout_inputs[index+1:]), axis=0)\n",
    "    heldout_outputs = torch.cat((heldout_outputs[:index], heldout_outputs[index+1:]), axis=0)\n",
    "\n",
    "    return best_random, heldout_inputs, heldout_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac16db8",
   "metadata": {},
   "source": [
    "To featurize the molecules in the ESOL dataset we use Mordred descriptors [3], which are high-dimensional continuous vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68f9ac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mordred descriptor computation takes 270.91417813301086 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Mordred descriptor computation is expensive\"\"\"\n",
    "\n",
    "# Load the Photoswitch dataset\n",
    "loader = DataLoaderMP()\n",
    "loader.load_benchmark(\"Lipophilicity\", \"molecule_utilities/dataset/Lipophilicity.csv\")\n",
    "subsample=300 # subsample dataset for speed\n",
    "y = loader.labels[0:subsample]\n",
    "# y = loader.labels\n",
    "\n",
    "calc = Calculator(descriptors, ignore_3D=True)\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in loader.features[0:subsample]] #subsample for speed\n",
    "# mols = [Chem.MolFromSmiles(smi) for smi in loader.features] #subsample for speed\n",
    "t0 = time.time()\n",
    "X = [calc(mol) for mol in mols]\n",
    "t1 = time.time()\n",
    "print(f'Mordred descriptor computation takes {t1 - t0} seconds')\n",
    "X = np.array(X).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1d7d7",
   "metadata": {},
   "source": [
    "In the BOPE setting we assume that we map an input space to a high-dimensional outcome space. In this instance we choose our input space $\\mathbf{x}$ to be fragprints, a concatenated vector of ECFP fingerprints and RDKit fragment features. Our outcome space $y$ is then the Mordred descriptor vector and our utility $g(y)$ is the logD of the molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de804d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fragprint descriptor computation\"\"\"\n",
    "\n",
    "loader.featurize('fragprints')\n",
    "X_frag = loader.features[0:subsample]\n",
    "# X_frag = loader.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10847364",
   "metadata": {},
   "source": [
    "We preprocess the Mordred descriptors to remove NaN features and features that have a variance threshold smaller than 0.05 post-standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32ed7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Collect nan indices\"\"\"\n",
    "\n",
    "nan_dims = []\n",
    "\n",
    "for i in range(len(X)):\n",
    "    nan_indices = list(np.where(np.isnan(X[i, :]))[0])\n",
    "    for dim in nan_indices:\n",
    "        if dim not in nan_dims:\n",
    "            nan_dims.append(dim)\n",
    "            \n",
    "X_mordred_nonan = np.delete(X, nan_dims, axis=1)\n",
    "\n",
    "# Remove variables with near-constant variance\n",
    "variance_threshold = 0.05\n",
    "selector = VarianceThreshold(variance_threshold)\n",
    "X_rem = selector.fit_transform(X_mordred_nonan)\n",
    "\n",
    "# Store values for BayesOpt\n",
    "y_bo = X_rem\n",
    "\n",
    "# Compute outcome space dimensionality\n",
    "outcome_dim = X_rem.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0ad951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BOPE specific utilities\"\"\"\n",
    "\n",
    "def fit_outcome_model(X, Y):\n",
    "    \"\"\"Fit the outcome model f(x). We use a Tanimoto kernel to operate on the\n",
    "       fragprints representation.\n",
    "    \n",
    "    Args:\n",
    "        X: Tensor of fragprints representation\n",
    "        Y: Tensor of PCA-reduced Mordred descriptors\n",
    "        \n",
    "    Returns:\n",
    "        GP model instance for the outcome model f(x)\n",
    "    \"\"\"\n",
    "    outcome_model = SingleTaskGP(\n",
    "        train_X=X,\n",
    "        train_Y=Y,\n",
    "        outcome_transform=Standardize(m=Y.shape[-1]),\n",
    "        covar_module = gpytorch.kernels.ScaleKernel(TanimotoKernel()),\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(outcome_model.likelihood, outcome_model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return outcome_model\n",
    "\n",
    "\n",
    "def fit_pref_model(Y, comps):\n",
    "    \"\"\"Fit the preference model g(y).\n",
    "    \n",
    "    Args:\n",
    "        Y: Tensor of PCA-reduced Mordred descriptors\n",
    "        comps: Tensor of pairwise comparisons\n",
    "        \n",
    "    Returns:\n",
    "        model: GP model instance for the preference function g(y)\n",
    "    \n",
    "    \"\"\"\n",
    "    model = PairwiseGP(Y, comps)\n",
    "    mll = PairwiseLaplaceMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_pref_learn(outcome_model, train_Y, train_comps, n_comps, heldout_inputs, heldout_outputs, previous_winner,\n",
    "                  previous_winner_util):\n",
    "    \"\"\"Perform preference exploration for n_comps rounds.\n",
    "    \n",
    "    Args:\n",
    "        outcome_model: GP model instance for f(x)\n",
    "        train_Y: Tensor of PCA-reduced Mordred descriptors\n",
    "        train_comps: Tensor of pairwise comparisons\n",
    "        n_comps: Int specifying the number of comparisons to generate in the preference exploration stage\n",
    "        heldout_inputs: updated heldout set of molecules in their fragprints representation x\n",
    "        heldout_outputs: updated heldout set of true molecule utilities (labels)\n",
    "        previous_winner: the x-value of the selected point on the previous iteration of BO\n",
    "        previous_winner_util: the true utilty g(y) of the previously selected point.\n",
    "        \n",
    "    Returns:\n",
    "        train_Y: updated training set of PCA-reduced outcomes\n",
    "        train_comps: updated set of pairwise comparisons\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(n_comps):\n",
    "        \n",
    "        pref_model = fit_pref_model(train_Y, train_comps)\n",
    "        \n",
    "        # EUBO-zeta\n",
    "        one_sample_outcome_model = FixedSingleSampleModel(model=outcome_model)\n",
    "        \n",
    "        acqf = AnalyticExpectedUtilityOfBestOption(\n",
    "            pref_model=pref_model, \n",
    "            outcome_model=one_sample_outcome_model, \n",
    "            previous_winner=previous_winner\n",
    "        )\n",
    "        \n",
    "        # Loop over the discrete set of points to evaluate the acquisition function at.\n",
    "        acq_vals = []\n",
    "        for i in range(len(heldout_outputs)):\n",
    "            acq_vals.append(acqf(heldout_inputs[i].unsqueeze(-2)))  # use unsqueeze to append batch dimension\n",
    "\n",
    "        # observe new values\n",
    "        acq_vals = torch.tensor(acq_vals)\n",
    "        best_idx = torch.argmax(acq_vals)\n",
    "        cand_X = heldout_inputs[best_idx].unsqueeze(-2)  # add batch dimension\n",
    "        new_util = heldout_outputs[best_idx].unsqueeze(-1)\n",
    "        \n",
    "        cand_Y = one_sample_outcome_model(cand_X)\n",
    "        cand_Y = cand_Y.detach().clone()\n",
    "        cand_comps = generate_comparisons(torch.cat((previous_winner_util, new_util)).squeeze(-1))\n",
    "\n",
    "        train_comps = torch.cat((train_comps, cand_comps))\n",
    "        train_Y = torch.cat((train_Y, cand_Y))\n",
    "\n",
    "    return train_Y, train_comps\n",
    "\n",
    "\n",
    "def gen_exp_cand(outcome_model, objective, q, heldout_inputs, heldout_outputs, heldout_ys):\n",
    "    \"\"\"Given an outcome model and an objective, generate q experimental candidates\n",
    "    using specified acquisition function.\n",
    "    \n",
    "    Args:\n",
    "        outcome_model: GP model instance of f(x)\n",
    "        objective: objective given by the preference model g(y)\n",
    "        q: Int specifying the batch size\n",
    "        heldout_inputs: heldout set of molecules in their fragprints representation x\n",
    "        heldout_outputs: heldout set of true molecule utilities (labels)\n",
    "        heldout_ys: heldout set of Mordred descriptors for molecules\n",
    "        \n",
    "    Returns:\n",
    "        cand_X: The new input to query (heldout molecule)\n",
    "        new_util: The utility (label) of said molecule\n",
    "        heldout_inputs: updated heldout set of molecules in their fragprints representation x\n",
    "        heldout_outputs: updated heldout set of true molecule utilities (labels)\n",
    "        new_y: New Mordred representation for the selected molecule\n",
    "        heldout_ys: updated heldout set of Mordred representation\n",
    "    \"\"\"\n",
    "    # generate experimental candidates with qNEI/qNEIUU\n",
    "    acq_func = qNoisyExpectedImprovement(\n",
    "        model=outcome_model,\n",
    "        objective=objective,\n",
    "        X_baseline=outcome_model.train_inputs[0][0, :], # TODO: Improve me\n",
    "        prune_baseline=True,\n",
    "    )\n",
    "    \n",
    "    # Loop over the discrete set of points to evaluate the acquisition function at.\n",
    "    acq_vals = []\n",
    "    for i in range(len(heldout_outputs)):\n",
    "        acq_vals.append(acq_func(heldout_inputs[i].unsqueeze(-2)))  # use unsqueeze to append batch dimension\n",
    "\n",
    "    # observe new values\n",
    "    acq_vals = torch.tensor(acq_vals)\n",
    "    best_idx = torch.argmax(acq_vals)\n",
    "    cand_X = heldout_inputs[best_idx].unsqueeze(-2)  # add batch dimension\n",
    "    new_util = heldout_outputs[best_idx].unsqueeze(-1)  # add output dimension\n",
    "    new_y = heldout_ys[best_idx].unsqueeze(-2)  # add batch dimension\n",
    "\n",
    "    # Delete the selected input and value from the heldout set.\n",
    "    heldout_inputs = torch.cat((heldout_inputs[:best_idx], heldout_inputs[best_idx+1:]), axis=0)\n",
    "    heldout_outputs = torch.cat((heldout_outputs[:best_idx], heldout_outputs[best_idx+1:]), axis=0)\n",
    "    heldout_ys = torch.cat((heldout_ys[:best_idx], heldout_ys[best_idx+1:]), axis=0)\n",
    "\n",
    "    return cand_X, new_util, heldout_inputs, heldout_outputs, new_y, heldout_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603882ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial  1 of 30 ....................\n",
      "Trial  2 of 30 ....................\n",
      "Trial  3 of 30 ....................\n",
      "Trial  4 of 30 ....................\n",
      "Trial  5 of 30 ......."
     ]
    }
   ],
   "source": [
    "\"\"\"Bayesian optimisation loop comparing LSPE-PCA, LSPE-REMBO and random search\"\"\"\n",
    "\n",
    "N_TRIALS = 30\n",
    "holdout_set_size = 0.85\n",
    "n_components = 5\n",
    "N_ITERS = 20\n",
    "m = 300 # Initial comparisons\n",
    "n_comps = 1 # comparisons per iteration\n",
    "NUM_OUTCOME_SAMPLES = 64\n",
    "\n",
    "# precompute random projection matrix and its inverse for REMBO\n",
    "\n",
    "A = torch.randn((outcome_dim, n_components)).numpy().astype(np.float64)\n",
    "# A_inv = torch.pinverse(A) - inverse not needed\n",
    "\n",
    "best_observed_all_eubo, best_observed_all_rembo, best_random_all = [], [], []\n",
    "\n",
    "# average over multiple random trials (each trial splits the initial training set for the GP in a random manner)\n",
    "for trial in range(1, N_TRIALS + 1):\n",
    "    \n",
    "    # Experimentation stage: initial exploration batch\n",
    "    torch.manual_seed(trial+20)\n",
    "    np.random.seed(trial+20)\n",
    "\n",
    "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
    "    best_observed_eubo, best_observed_rembo, best_random = [], [], []\n",
    "    \n",
    "    # Generate initial outcome data and initialize model\n",
    "    train_x_eubo, heldout_x_eubo, train_y_eubo, heldout_y_eubo = train_test_split(X_frag, y_bo, test_size=holdout_set_size, random_state=trial)\n",
    "    train_x_rembo, heldout_x_rembo, train_y_rembo, heldout_y_rembo = train_x_eubo, heldout_x_eubo, train_y_eubo, heldout_y_eubo\n",
    "    # Generate the true utility values using the same split\n",
    "    _, _, train_utils, heldout_utils = train_test_split(X_frag, y, test_size=holdout_set_size, random_state=trial)\n",
    "    train_utils_rembo, heldout_utils_rembo = train_utils, heldout_utils\n",
    "        \n",
    "    # Apply PCA to the outcomes\n",
    "    scaler = StandardScaler()\n",
    "    train_y_eubo_pca = scaler.fit_transform(train_y_eubo)\n",
    "    heldout_y_eubo_pca = scaler.transform(heldout_y_eubo)\n",
    "    pca_mordred = PCA(n_components=n_components)\n",
    "    train_y_eubo_pca = pca_mordred.fit_transform(train_y_eubo_pca)\n",
    "    heldout_y_eubo_pca = pca_mordred.transform(heldout_y_eubo_pca)    \n",
    "    best_observed_value_eubo = torch.tensor(np.max(train_utils))\n",
    "    \n",
    "    # Apply random embedding to the outcomes\n",
    "    scaler_rembo = StandardScaler()\n",
    "    train_y_rembo_emb = scaler_rembo.fit_transform(train_y_rembo)\n",
    "    heldout_y_rembo_emb = scaler_rembo.transform(heldout_y_rembo)\n",
    "    train_y_rembo_emb = train_y_rembo_emb@A\n",
    "    heldout_y_rembo_emb = heldout_y_rembo_emb@A\n",
    "    best_observed_value_rembo = torch.tensor(np.max(train_utils_rembo))\n",
    "        \n",
    "    # Set the previous winner for the first round\n",
    "    previous_winner = torch.tensor(train_y_eubo_pca[np.argmax(train_utils)]).unsqueeze(-2)\n",
    "    previous_winner_util = torch.tensor(np.max(train_utils)).unsqueeze(-1).unsqueeze(-1)\n",
    "    \n",
    "    # Set the previous winner for rembo\n",
    "    previous_winner_rembo = previous_winner\n",
    "    previous_winner_util_rembo = previous_winner_util\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors and flatten the label vectors\n",
    "    train_x_eubo = torch.tensor(train_x_eubo.astype(np.float64))\n",
    "    heldout_x_eubo = torch.tensor(heldout_x_eubo.astype(np.float64))\n",
    "    train_y_eubo_pca = torch.tensor(train_y_eubo_pca.astype(np.float64))\n",
    "    heldout_y_eubo_pca = torch.tensor(heldout_y_eubo_pca.astype(np.float64))\n",
    "    train_utils = torch.tensor(train_utils)\n",
    "    heldout_utils = torch.tensor(heldout_utils)\n",
    "    train_y_eubo = torch.tensor(train_y_eubo)\n",
    "    heldout_y_eubo = torch.tensor(heldout_y_eubo)\n",
    "    \n",
    "    train_x_rembo = torch.tensor(train_x_rembo.astype(np.float64))\n",
    "    heldout_x_rembo = torch.tensor(heldout_x_rembo.astype(np.float64))\n",
    "    train_y_rembo_emb = torch.tensor(train_y_rembo_emb.astype(np.float64))\n",
    "    heldout_y_rembo_emb = torch.tensor(heldout_y_rembo_emb.astype(np.float64))\n",
    "    train_utils_rembo = torch.tensor(train_utils_rembo)\n",
    "    heldout_utils_rembo = torch.tensor(heldout_utils_rembo)\n",
    "    train_y_rembo = torch.tensor(train_y_rembo)\n",
    "    heldout_y_rembo = torch.tensor(heldout_y_rembo)\n",
    "    \n",
    "    # Generate initial comparisons\n",
    "    train_comps = generate_initial_comparisons(train_utils.squeeze(-1), m)\n",
    "    train_comps_rembo = train_comps\n",
    "\n",
    "    # The initial heldout set is the same for random search and rembo\n",
    "    heldout_x_random = heldout_x_eubo\n",
    "    heldout_utils_random = heldout_utils\n",
    "    \n",
    "    # Initialize the outcome model for PCA\n",
    "    outcome_model = fit_outcome_model(train_x_eubo, train_y_eubo_pca)\n",
    "    \n",
    "    # Initialize the outcome model for REMBO\n",
    "    \n",
    "    outcome_model_rembo = fit_outcome_model(train_x_rembo, train_y_rembo_emb)\n",
    "\n",
    "    best_observed_eubo.append(best_observed_value_eubo)\n",
    "    best_random.append(best_observed_value_eubo)\n",
    "    best_observed_rembo.append(best_observed_value_rembo)\n",
    "\n",
    "    # run N_ITERS rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(1, N_ITERS + 1):\n",
    "                                                    \n",
    "        # Run preference exploration\n",
    "        try:\n",
    "            _, train_comps = run_pref_learn(outcome_model, train_y_eubo_pca, train_comps, n_comps, \n",
    "                                                  heldout_x_eubo, heldout_utils, previous_winner,\n",
    "                                                  previous_winner_util)\n",
    "\n",
    "            # Run preferece exploration for REMBO\n",
    "            _, train_comps_rembo = run_pref_learn(outcome_model_rembo, train_y_rembo_emb, train_comps_rembo, n_comps, \n",
    "                                                  heldout_x_rembo, heldout_utils_rembo, previous_winner_rembo,\n",
    "                                                  previous_winner_util_rembo)\n",
    "        except:\n",
    "            break\n",
    "                        \n",
    "        # Run experimentation with the learned preference model and qNEIUU\n",
    "        pref_model = fit_pref_model(train_y_eubo_pca, train_comps)\n",
    "        pref_obj = LearnedObjective(pref_model=pref_model)\n",
    "        new_x_eubo, new_util, heldout_x_eubo, heldout_utils, new_y_eubo, heldout_y_eubo = gen_exp_cand(outcome_model, pref_obj, q=1, \n",
    "                                                                           heldout_inputs=heldout_x_eubo, \n",
    "                                                                           heldout_outputs=heldout_utils,\n",
    "                                                                           heldout_ys=heldout_y_eubo)\n",
    "        \n",
    "        # Run experimentation with the learned preference model for REMBO\n",
    "        pref_model_rembo = fit_pref_model(train_y_rembo_emb, train_comps_rembo)\n",
    "        pref_obj_rembo = LearnedObjective(pref_model=pref_model_rembo)\n",
    "        new_x_rembo, new_util_rembo, heldout_x_rembo, heldout_utils_rembo, new_y_rembo, heldout_y_rembo = gen_exp_cand(outcome_model_rembo, pref_obj_rembo, q=1, \n",
    "                                                                           heldout_inputs=heldout_x_rembo, \n",
    "                                                                           heldout_outputs=heldout_utils_rembo,\n",
    "                                                                           heldout_ys=heldout_y_rembo)\n",
    "                        \n",
    "        # update training points\n",
    "        train_x_eubo = torch.cat([train_x_eubo, new_x_eubo])\n",
    "        train_y_eubo = torch.cat([train_y_eubo, new_y_eubo])\n",
    "        \n",
    "        # Update training points for rembo\n",
    "        train_x_rembo = torch.cat([train_x_rembo, new_x_rembo])\n",
    "        train_y_rembo = torch.cat([train_y_rembo, new_y_rembo])\n",
    "        \n",
    "        # Re-apply PCA to the outcomes\n",
    "        scaler = StandardScaler()\n",
    "        train_y_eubo_pca = scaler.fit_transform(train_y_eubo)\n",
    "        heldout_y_eubo_pca = scaler.transform(heldout_y_eubo)\n",
    "        pca_mordred = PCA(n_components=n_components)\n",
    "        train_y_eubo_pca = torch.tensor(pca_mordred.fit_transform(train_y_eubo_pca))\n",
    "        heldout_y_eubo_pca = torch.tensor(pca_mordred.transform(heldout_y_eubo_pca))    \n",
    "        \n",
    "        # Recompute random embedding\n",
    "        scaler_rembo = StandardScaler()\n",
    "        train_y_rembo_emb = scaler_rembo.fit_transform(train_y_rembo)\n",
    "        heldout_y_rembo_emb = scaler_rembo.transform(heldout_y_rembo)\n",
    "        train_y_rembo_emb = torch.tensor(train_y_rembo_emb@A)\n",
    "        heldout_y_rembo_emb = torch.tensor(heldout_y_rembo_emb@A)\n",
    "        \n",
    "        # update previous winners\n",
    "        previous_winner = torch.tensor(pca_mordred.transform(scaler.transform(new_y_eubo)))\n",
    "        previous_winner_util = new_util\n",
    "        \n",
    "        # update previous winners for REMBO\n",
    "        previous_winner_rembo = torch.tensor(scaler_rembo.transform(new_y_rembo)@A)\n",
    "        previous_winner_util_rembo = new_util_rembo\n",
    "        \n",
    "        # update random search progress\n",
    "        best_random, heldout_x_random, heldout_utils_random = update_random_observations(best_random,\n",
    "                                                                                     heldout_inputs=heldout_x_random,\n",
    "                                                                                     heldout_outputs=heldout_utils_random)\n",
    "        best_value_eubo = torch.max(new_util, best_observed_eubo[-1])\n",
    "        best_observed_eubo.append(best_value_eubo)\n",
    "        \n",
    "        best_value_rembo = torch.max(new_util_rembo, best_observed_rembo[-1])\n",
    "        best_observed_rembo.append(best_value_rembo)\n",
    "        \n",
    "        # reinitialize the outcome model so it is ready for fitting on the next iteration\n",
    "        outcome_model = fit_outcome_model(train_x_eubo, train_y_eubo_pca)\n",
    "        \n",
    "        # reinitialize the outcome model for RemBO so it is ready for fitting on the next iteration\n",
    "        outcome_model_rembo = fit_outcome_model(train_x_rembo, train_y_rembo_emb)\n",
    "        \n",
    "        print(\".\", end=\"\")\n",
    "\n",
    "    best_observed_all_eubo.append(best_observed_eubo)\n",
    "    best_random_all.append(best_random)\n",
    "    best_observed_all_rembo.append(best_observed_rembo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb82dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot the results\"\"\"\n",
    "\n",
    "# Define a confidence interval function for plotting.\n",
    "def ci(y):\n",
    "    return 1.96 * y.std(axis=0) / np.sqrt(N_TRIALS)\n",
    "\n",
    "iters = np.arange(N_ITERS + 1)\n",
    "y_eubo = torch.tensor(best_observed_all_eubo)\n",
    "y_rembo = torch.tensor(best_observed_all_rembo)\n",
    "y_rnd = torch.tensor(best_random_all)\n",
    "\n",
    "y_rnd_mean = y_rnd.mean(axis=0)\n",
    "y_eubo_mean = y_eubo.mean(axis=0)\n",
    "y_rembo_mean = y_rembo.mean(axis=0)\n",
    "\n",
    "lower_rnd = y_rnd_mean - ci(y_rnd)\n",
    "upper_rnd = y_rnd_mean + ci(y_rnd)\n",
    "lower_eubo = y_eubo_mean - ci(y_eubo)\n",
    "upper_eubo = y_eubo_mean + ci(y_eubo)\n",
    "lower_rembo = y_rembo_mean - ci(y_rembo)\n",
    "upper_rembo = y_rembo_mean + ci(y_rembo)\n",
    "\n",
    "plt.plot(iters, y_rnd_mean, label='Random search', color='tab:green')\n",
    "plt.fill_between(iters, lower_rnd, upper_rnd, alpha=0.2, color='tab:green')\n",
    "plt.plot(iters, y_eubo_mean, label='LSPE-PCA', color='tab:red')\n",
    "plt.fill_between(iters, lower_eubo, upper_eubo, alpha=0.2, color='tab:red')\n",
    "plt.plot(iters, y_rembo_mean, label='LSPE-REMBO', color='tab:blue')\n",
    "plt.fill_between(iters, lower_rembo, upper_rembo, alpha=0.2, color='tab:blue')\n",
    "plt.xlabel('Number of BO stages')\n",
    "plt.ylabel('Best utility achieved')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(list(np.arange(0, 21, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Optionally save values for replotting\"\"\"\n",
    "\n",
    "save_for_replot = False\n",
    "\n",
    "if save_for_replot:\n",
    "    np.savetxt('y_eubo_lipophilicity.txt', y_eubo)\n",
    "    np.savetxt('y_rnd_lipophilicity.txt', y_rnd)\n",
    "    np.savetxt('y_rembo_lipophilicity.txt', y_rembo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82d3d1",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Hersey, A. ChEMBL Deposited Data Set - AZ dataset; 2015\n",
    "\n",
    "[2] Griffiths, R.R., Klarner, L., Moss, H.B., Ravuri, A., Truong, S., Rankovic, B., Du, Y., Jamasb, A., Schwartz, J., Tripp, A. and Kell, G. et al. 2022. [GAUCHE: A Library for Gaussian Processes in Chemistry](https://arxiv.org/abs/2212.04450). arXiv preprint arXiv:2212.04450.\n",
    "\n",
    "[3] Moriwaki, H., Tian, Y.S., Kawashita, N. and Takagi, T., 2018. [Mordred: a molecular descriptor calculator](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0258-y?ref=https://githubhelp.com). Journal of cheminformatics, 10(1), pp.1-14."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
