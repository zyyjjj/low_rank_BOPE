{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "customInput": null,
        "customOutput": null,
        "originalKey": "ceb71afe-4052-4baf-b062-7437fc0cec4e",
        "showInput": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "customInput": null,
        "customOutput": null,
        "originalKey": "1aaef392-6015-47c8-b00a-b7d8415faf68",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# BO experiment name: feed_integrity_control_panel_vm_tuning_quickbo\n",
        "# PE experiment name: pe_pilot_feed_integrity_control_panel_vm_tuning_quickbo_no_ci"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "customInput": null,
        "customOutput": null,
        "originalKey": "6b2efe9c-a8df-44c8-9830-2ba293cf45bb",
        "showInput": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "customInput": null,
        "customOutput": null,
        "originalKey": "9dec4772-a321-411e-9f9d-cbca58b2f61f",
        "showInput": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "customInput": null,
        "customOutput": null,
        "originalKey": "a4a6da3e-8e8b-478b-a49b-139e4321ede8",
        "showInput": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "code_folding": [],
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038113871,
        "executionStopTime": 1673038117014,
        "hidden_ranges": [],
        "originalKey": "7bab2fa6-c346-42e3-87e1-a667eb3ffe17",
        "requestMsgId": "ad8d01cb-b4e1-4106-ae8b-d580acc00b88",
        "showInput": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0106 124836.904 magics.py:79] %autoreload 2 was called with \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The python.parsh.autoreload.magics extension is already loaded. To reload it, use:\n",
            "  %reload_ext python.parsh.autoreload.magics\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import copy\n",
        "import time\n",
        "import warnings  # noqa\n",
        "\n",
        "from collections import defaultdict\n",
        "from typing import Dict, Optional, Tuple, Type\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from ae.pca.models import compute_principal_axes\n",
        "\n",
        "# import my own code, which is under ae/pca/\n",
        "from ae.pca.simulation import generate_principal_axes, PCATestProblem\n",
        "from ae.pca.transforms import (\n",
        "    generate_random_projection,\n",
        "    InputCenter,\n",
        "    LinearProjectionInputTransform,\n",
        "    LinearProjectionOutcomeTransform,\n",
        "    PCAInputTransform,\n",
        "    PCAOutcomeTransform,\n",
        "    SubsetOutcomeTransform,\n",
        ")\n",
        "\n",
        "from ax.core.data import Data\n",
        "from ax.core.experiment import Experiment\n",
        "from ax.core.metric import Metric\n",
        "from ax.core.objective import MultiObjective, Objective, ScalarizedObjective\n",
        "from ax.core.observation import ObservationFeatures\n",
        "from ax.core.optimization_config import (\n",
        "    MultiObjectiveOptimizationConfig,\n",
        "    OptimizationConfig,\n",
        ")\n",
        "from ax.core.parameter import ParameterType, RangeParameter\n",
        "from ax.core.runner import Runner\n",
        "from ax.core.search_space import SearchSpace\n",
        "from ax.fb.metrics.deltoid3 import Deltoid3Metric\n",
        "from ax.fb.models.torch.botorch_modular.preference import PreferenceModelAcquisition\n",
        "from ax.fb.plot.notebook import render\n",
        "from ax.fb.service.ax_batch_client import AxBatchClient\n",
        "from ax.fb.storage.registries.pts_registry_bundle import PTS_REGISTRY_BUNDLE\n",
        "from ax.fb.storage.sqa_store.load import load_experiment\n",
        "from ax.fb.storage.sqa_store.save import save_experiment\n",
        "from ax.modelbridge.cross_validation import cross_validate\n",
        "from ax.modelbridge.modelbridge_utils import extract_search_space_digest\n",
        "from ax.modelbridge.pairwise import PairwiseModelBridge\n",
        "from ax.modelbridge.registry import Cont_X_trans, Models, ST_MTGP_trans\n",
        "from ax.modelbridge.transforms.derelativize import Derelativize\n",
        "from ax.modelbridge.transforms.relativize import Relativize\n",
        "from ax.modelbridge.transforms.task_encode import TaskEncode\n",
        "from ax.modelbridge.transforms.trial_as_task import TrialAsTask\n",
        "from ax.models.torch.botorch_modular.list_surrogate import ListSurrogate\n",
        "from ax.models.torch.botorch_modular.model import BoTorchModel\n",
        "from ax.models.torch.botorch_modular.surrogate import Surrogate\n",
        "from ax.plot.diagnostic import interact_cross_validation\n",
        "from ax.plot.scatter import interact_fitted, tile_fitted\n",
        "from ax.service.ax_client import AxClient\n",
        "from ax.service.utils.instantiation import ObjectiveProperties\n",
        "from ax.utils.stats.statstools import relativize_data\n",
        "from botorch import fit_gpytorch_model\n",
        "from botorch.acquisition import LearnedObjective\n",
        "from botorch.acquisition.monte_carlo import qNoisyExpectedImprovement\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.models.gp_regression import FixedNoiseGP\n",
        "from botorch.models.gpytorch import GPyTorchModel\n",
        "from botorch.models.multitask import FixedNoiseMultiTaskGP\n",
        "from botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood\n",
        "from botorch.models.transforms.input import (\n",
        "    ChainedInputTransform,\n",
        "    InputStandardize,\n",
        "    InputTransform,\n",
        "    Normalize,\n",
        ")\n",
        "from botorch.models.transforms.outcome import (\n",
        "    ChainedOutcomeTransform,\n",
        "    OutcomeTransform,\n",
        "    Standardize,\n",
        ")\n",
        "from botorch.optim.fit import fit_gpytorch_scipy\n",
        "from botorch.posteriors import TransformedPosterior\n",
        "from botorch.test_functions.multi_objective import BraninCurrin\n",
        "from gpytorch.likelihoods import GaussianLikelihood, Likelihood\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from gpytorch.priors import GammaPrior\n",
        "from IPython.display import clear_output\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# To determine whether we are generating the new BO batch with MTGP\n",
        "BO_MTGP = False\n",
        "# To determine whether we are using MTGP for PE\n",
        "PE_MTGP = False\n",
        "LONG_TRIAL_INDEX = 0\n",
        "\n",
        "DELTOID3_DELTA_TYPE_SUFFICES = (\n",
        "    \"_MEAN\",\n",
        "    \"_PARTICIPATION_RATE\",\n",
        "    \"_CONDITIONAL_MEAN\",\n",
        "    \"_LOG\",\n",
        "    \"_NO_WINSORIZATION_MEAN\",\n",
        "    \"_NO_WINSORIZATION_CONDITIONAL_MEAN\",\n",
        "    \"_REGRESSION_ADJUSTED_MEAN\",\n",
        "    \"_DJ_RECOMMENDED\",\n",
        ")\n",
        "METRIC_STRIP_REGEX = \"|\".join(\n",
        "    [f\"({suffix})\" for suffix in DELTOID3_DELTA_TYPE_SUFFICES]\n",
        ")\n",
        "\n",
        "REL_DATA_AS_PERCENT = True\n",
        "PERCENT_FORMATTER_XMAX = 100.0 if REL_DATA_AS_PERCENT else 1.0\n",
        "\n",
        "if PE_MTGP:\n",
        "    pe_fixed_features = ObservationFeatures(parameters={}, trial_index=LONG_TRIAL_INDEX)\n",
        "    bo_trial_indices = None\n",
        "    raise ValueError(\"Using MTGP for PE is not supported!\")\n",
        "else:\n",
        "    pe_fixed_features = None\n",
        "    bo_trial_indices = [0, 1]\n",
        "\n",
        "if BO_MTGP:\n",
        "    bo_fixed_features = ObservationFeatures(parameters={}, trial_index=LONG_TRIAL_INDEX)\n",
        "else:\n",
        "    bo_fixed_features = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "code_folding": [],
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1671575164417,
        "executionStopTime": 1671575164444,
        "hidden_ranges": [],
        "originalKey": "5971fee6-d3d4-4471-b7d7-8cacb88338bf",
        "requestMsgId": "5971fee6-d3d4-4471-b7d7-8cacb88338bf",
        "showInput": false
      },
      "outputs": [],
      "source": [
        "EXPERIMENT_NAME = \"watch_chaining_vm_tuning_quickbo\"\n",
        "\n",
        "# If none, will use objective + constraints for PE\n",
        "custom_pe_metric_names = [\n",
        "    \"company_core_metrics:time_spent:overall_blue\",\n",
        "    \"games:gaming_video:all:watch_hours:overall\",\n",
        "    \"video:fi_re:entertainment_non_rec:vod:watchtime_rate\",\n",
        "    \"video:live:viewer:overall:is_live_time_spent_total_s\",\n",
        "    \"video:planned_viewing:video_home_watch_time_ms:overall\",\n",
        "    \"video:vpi:consumption:time_spent_s:overall\",\n",
        "    \"video:watch:num_watch_10min_actives:overall\",\n",
        "    \"video:watch:num_watch_1min_actives:overall\",\n",
        "]\n",
        "\n",
        "EXPERIMENT_NAME_CI = \"pe_pilot_\" + EXPERIMENT_NAME + \"_test\"\n",
        "EXPERIMENT_NAME_NO_CI = \"pe_pilot_\" + EXPERIMENT_NAME + \"_no_ci\"\n",
        "\n",
        "\n",
        "# BO experiment name: feed_integrity_control_panel_vm_tuning_quickbo\n",
        "# PE experiment name: pe_pilot_feed_integrity_control_panel_vm_tuning_quickbo_no_ci"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "2f89bc92-0dc0-4052-9479-4f4544b55117",
        "showInput": false
      },
      "source": [
        "# Useful code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038122732,
        "executionStopTime": 1673038122761,
        "originalKey": "d0f083c0-ebff-4c24-a450-05356b4a2d1a",
        "requestMsgId": "2dd900b0-9635-4df3-aad8-fc74647812a7",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# largely inspired by Wesley's implementation\n",
        "\n",
        "# credit to Sait\n",
        "\n",
        "class ModifiedTransformedPosterior(TransformedPosterior):\n",
        "    @property\n",
        "    def event_shape(self) -> torch.Size:\n",
        "        r\"\"\"The event shape (i.e. the shape of a single sample).\"\"\"\n",
        "        return self.rsample().shape[-2:]\n",
        "\n",
        "    def _extended_shape(\n",
        "        self, sample_shape: torch.Size = torch.Size()  # noqa: B008\n",
        "    ) -> torch.Size:\n",
        "        r\"\"\"Returns the shape of the samples produced by the posterior with\n",
        "        the given `sample_shape`.\n",
        "\n",
        "        NOTE: This assumes that the `sample_transform` does not change the\n",
        "        shape of the samples.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.rsample().shape[-2:]\n",
        "\n",
        "\n",
        "class PCAOutcomeTransform(OutcomeTransform):\n",
        "    def __init__(self, variance_explained_threshold: float = 0.9, num_axes: int = None, *tkwargs):\n",
        "        r\"\"\"\n",
        "        Initialize PCAOutcomeTransform() instance\n",
        "        Args:\n",
        "            variance_explained_threshold: fraction of variance in the data that we want the selected principal axes to explain;\n",
        "                if num_axes is None, use this to decide the number of principal axes to select\n",
        "            num_axes: number of principal axes to select\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.variance_explained_threshold = variance_explained_threshold\n",
        "        self.num_axes = num_axes\n",
        "\n",
        "    def forward(\n",
        "        self, Y: torch.Tensor, Yvar: Optional[torch.Tensor] = None, **tkwargs\n",
        "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
        "        r\"\"\"\n",
        "        Perform PCA on data Y and transforms it to a lower-dimensional representation in terms of principal components.\n",
        "        Args:\n",
        "            Y: `batch_shape x num_samples x output_dim` tensor of metric observations;\n",
        "                assume that it is centered already, since we would normally chain the PCATransform() after a Standardize()\n",
        "            Yvar: (optional) `batch_shape x num_samples x output_dim` tensor of metric noises (variance)\n",
        "        Returns:\n",
        "            Y_transformed: `batch_shape x num_samples x PC_dim` tensor of PC values\n",
        "            Yvar_transformed: `batch_shape x num_samples x PC_dim` tensor of estimated PC variances\n",
        "        \"\"\"\n",
        "\n",
        "        if self.training:\n",
        "\n",
        "            # TODO: use pytorch's SVD rather than sklearn to perform PCA\n",
        "            # Reason: axes_learned depends on the training targets (Y);\n",
        "            # any quantity that depends on the posterior in the metrics space will have its gradient\n",
        "            # d f(metric posterior)\n",
        "            # dependent on d (axes_learned) / d (training targets)\n",
        "            # but this step is done in sklearn, so torch gradient computation can't propagate through\n",
        "            # (we can of course use the sklearn results to check correctness)\n",
        "\n",
        "            pca = PCA()\n",
        "            _ = pca.fit_transform(Y)\n",
        "            explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "            if self.num_axes is None:\n",
        "                # decide the number of principal axes to keep (that makes explained variance exceed the specified threshold)\n",
        "                exceed_thres = np.cumsum(explained_variance) > self.variance_explained_threshold\n",
        "                self.num_axes = len(exceed_thres) - sum(exceed_thres) + 1\n",
        "\n",
        "            axes_learned = pca.components_[: self.num_axes, :]\n",
        "\n",
        "            # print(f\"PCs from sklearn: {Y_transformed_full[:, :self.num_axes]}\")\n",
        "            # print(\"explained variance\", explained_variance)\n",
        "\n",
        "            self.PCA_explained_variance = sum(explained_variance[: self.num_axes])\n",
        "\n",
        "            print(f\"num_axes = {self.num_axes}, explains {self.PCA_explained_variance} variance\")\n",
        "\n",
        "            self.axes_learned = torch.tensor(axes_learned, **tkwargs)\n",
        "            # print(\"axes learned: \", self.axes_learned)\n",
        "            # print(\"self.axes_learned norms\", torch.linalg.norm(self.axes_learned, dim=1))\n",
        "\n",
        "        Y_transformed = torch.matmul(Y, torch.transpose(self.axes_learned, -2, -1)).to(**tkwargs)\n",
        "\n",
        "        # if Yvar is given, the variance of PCs is lower bounded by the linear combination of Yvar terms\n",
        "        # TODO: check correctness\n",
        "        if Yvar is not None:\n",
        "            Yvar_transformed = torch.matmul(Yvar, torch.square(torch.transpose(self.axes_learned, -2, -1))).to(\n",
        "                **tkwargs\n",
        "            )\n",
        "\n",
        "        # print('Y transformed shape', Y_transformed.shape)\n",
        "        # print(f\"PCs, transformed from Y: {Y_transformed}\")\n",
        "\n",
        "        return Y_transformed, Yvar_transformed if Yvar is not None else None\n",
        "\n",
        "    def untransform(\n",
        "        self, Y: torch.Tensor, Yvar: Optional[torch.Tensor] = None, **tkwargs\n",
        "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
        "        r\"\"\"\n",
        "        Transform PC back to metrics according to self.axes_learned.\n",
        "        Args:\n",
        "            Y: `num_samples x PC_dim` tensor of PC values\n",
        "            Yvar: `num_samples x PC_dim` tensor of PC variances\n",
        "        Returns:\n",
        "            Y_untransformed: `num_samples x output_dim` tensor of metric values\n",
        "            Yvar_untransformed: `num_samples x output_dim` tensor of metric variances\n",
        "        \"\"\"\n",
        "\n",
        "        Y_untransformed = torch.matmul(Y, self.axes_learned)\n",
        "        if Yvar is not None:\n",
        "            Yvar_untransformed = torch.matmul(Yvar, torch.square(self.axes_learned))\n",
        "\n",
        "        print(f\"Y, transformed from PCs: {Y_untransformed}\")\n",
        "\n",
        "        return (\n",
        "            Y_untransformed,\n",
        "            Yvar_untransformed if Yvar is not None else None,\n",
        "        )\n",
        "\n",
        "    def untransform_posterior(self, posterior):\n",
        "        r\"\"\"\n",
        "        Create posterior distribution in the space of metrics.\n",
        "        Args:\n",
        "            posterior: posterior in the space of PCs\n",
        "        Returns:\n",
        "            untransformed_posterior: posterior in the space of metrics\n",
        "        \"\"\"\n",
        "\n",
        "        untransformed_posterior = ModifiedTransformedPosterior(\n",
        "            posterior=posterior,\n",
        "            sample_transform=lambda x: x.matmul(self.axes_learned),\n",
        "            mean_transform=lambda x, v: x.matmul(self.axes_learned),\n",
        "            variance_transform=lambda x, v: x.matmul(self.axes_learned),\n",
        "        )\n",
        "\n",
        "        print('self.axes_learned.shape', self.axes_learned.shape)\n",
        "\n",
        "        print('untransformed_posterior.rsample().shape', untransformed_posterior.rsample().shape)\n",
        "\n",
        "        return untransformed_posterior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038125217,
        "executionStopTime": 1673038125278,
        "originalKey": "868e0dfd-d87a-47d8-8adf-f1e35d81e24c",
        "requestMsgId": "a8b39de1-9877-4bfa-95b7-955fe42f04c6",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# get PCAOutcomeTranform axes from\n",
        "# model.outcome_transform[\"pca\"].axes_learned\n",
        "# then plug into PCAInputTransform as argument\n",
        "\n",
        "from torch.nn import Module\n",
        "\n",
        "\n",
        "class PCAInputTransform(InputTransform, Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        axes: torch.Tensor,\n",
        "        transform_on_train: bool = True,\n",
        "        transform_on_eval: bool = True,\n",
        "        transform_on_fantasize: bool = True,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        Initialize PCAInputTransform() instance.\n",
        "        Args:\n",
        "            axes: `num_axes x input_dim` tensor with norm-1 orthogonal rows\n",
        "                (in the case of PE, these are the principal axes learned from the previous stage of fitting outcome model)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.axes = axes\n",
        "        self.transform_on_train = transform_on_train\n",
        "        self.transform_on_eval = transform_on_eval\n",
        "        self.transform_on_fantasize = transform_on_fantasize\n",
        "\n",
        "    def transform(self, X: torch.Tensor) -> torch.Tensor:\n",
        "        r\"\"\"\n",
        "        Transform the input X into latent representations using self.axes.\n",
        "        Args:\n",
        "            X: `num_samples x input_dim` tensor of input data\n",
        "        \"\"\"\n",
        "\n",
        "        transformed_X = torch.matmul(X, torch.transpose(self.axes, -2, -1))\n",
        "        # print('X shape, transformed_X shape', X.shape, transformed_X.shape)\n",
        "\n",
        "        return transformed_X\n",
        "\n",
        "    def untransform(self, X_tf: torch.Tensor) -> torch.Tensor:\n",
        "        r\"\"\"\n",
        "        Untransform a latent representation back to input space.\n",
        "        Args:\n",
        "            X_tf: `num_samples x num_axes` tensor of latent representations\n",
        "        \"\"\"\n",
        "\n",
        "        untransformed_X = torch.matmul(X_tf, self.axes)\n",
        "\n",
        "        return untransformed_X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "09ba5d3e-af32-470f-95e5-7feb63decde8",
        "showInput": false
      },
      "source": [
        "# Load QuickBO data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038127571,
        "executionStopTime": 1673038131304,
        "originalKey": "017618f1-95d1-463f-9a0a-621f26d09f92",
        "requestMsgId": "d429a665-d17c-43af-8435-cee9b39f5d44",
        "showInput": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0106 124848.764 db.py:50] DB ('xdb.metricdj', None, True): Connection bad, discarding: (2006, 'MySQL server has gone away')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0106 124848.772 db.py:61] DB ('xdb.metricdj', None, True): Constructing a new database connection\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0106 124849.290 mysql.py:61] 1 row(s) returned\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0106 124849.392 mysql.py:61] 1 row(s) returned\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0106 124849.413 mysql.py:61] 1 row(s) returned\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0106 124849.461 mysql.py:61] 1 row(s) returned\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0106 124849.489 mysql.py:61] 1 row(s) returned\n"
          ]
        }
      ],
      "source": [
        "experiment = load_experiment(\n",
        "    \"feed_integrity_control_panel_vm_tuning_quickbo\",\n",
        "    decoder=PTS_REGISTRY_BUNDLE.decoder,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038131408,
        "executionStopTime": 1673038131476,
        "originalKey": "ba317bbd-6d8a-4ffa-ba56-acc5ba0bbbc7",
        "requestMsgId": "20e1e8a1-c9e6-48ad-846a-d8b68364e19c",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: BatchTrial(experiment_name='feed_integrity_control_panel_vm_tuning_quickbo', index=0, status=TrialStatus.COMPLETED),\n",
              " 1: BatchTrial(experiment_name='feed_integrity_control_panel_vm_tuning_quickbo', index=1, status=TrialStatus.COMPLETED),\n",
              " 2: BatchTrial(experiment_name='feed_integrity_control_panel_vm_tuning_quickbo', index=2, status=TrialStatus.COMPLETED),\n",
              " 3: BatchTrial(experiment_name='feed_integrity_control_panel_vm_tuning_quickbo', index=3, status=TrialStatus.COMPLETED)}"
            ]
          },
          "execution_count": 58,
          "metadata": {
            "bento_obj_id": "140135548431936"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experiment.trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038131508,
        "executionStopTime": 1673038131581,
        "originalKey": "4f5ddc37-1ab4-468e-ac4b-83fd21fe849c",
        "requestMsgId": "97a3f229-b498-4da3-8e11-33f7501fd5eb",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# 15 metrics, {8, 7, 10, 10} arms each for trial {0, 1, 2, 3}\n",
        "# I should pivot table, then relativize, then use the Standardize() transform in GP on both the input and output ranges\n",
        "# with the caveat that aggregating together data from different trials may have some temporal heterogeneity effect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038131601,
        "executionStopTime": 1673038131625,
        "originalKey": "d056f6af-3e16-4b66-afad-df01e1b38e89",
        "requestMsgId": "b56f78e0-c564-4f54-aa04-fc2825ba31ac",
        "showInput": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038131656,
        "executionStopTime": 1673038131788,
        "originalKey": "5543d265-0a40-4c1e-ac58-922b5a62aa23",
        "requestMsgId": "c077e252-7a8e-4c34-aac9-c558f042476c",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "data0 = experiment.lookup_data(trial_indices=[0])\n",
        "data1 = experiment.lookup_data(trial_indices=[1])\n",
        "data2 = experiment.lookup_data(trial_indices=[2])\n",
        "data3 = experiment.lookup_data(trial_indices=[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038131931,
        "executionStopTime": 1673038132182,
        "originalKey": "2957b4b1-ca3c-4f2e-b344-75c9ec895c7f",
        "requestMsgId": "19882d5e-7b78-4d9f-aef1-be30c302b1b2",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.dataresource+json": {
              "data": [
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 0,
                  "mean": 0.0234742739,
                  "metric_name": "community_integrity:cep:viewer:holistic_prevalence_world__severity_weighted_prevalence__volume_CONDITIONAL_MEAN",
                  "n": 15283233,
                  "sem": 0.000018505,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5944250801,
                  "index": 1,
                  "mean": 42.9535200126,
                  "metric_name": "core_app:ecosystem:sessions:core_session_count_cap15:fb_major_apps_REGRESSION_ADJUSTED_MEAN",
                  "n": 15283233,
                  "sem": 0.0090154128,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.0860017642,
                  "index": 2,
                  "mean": 6.18791888,
                  "metric_name": "core_growth:visitation:dap:overall_facebook:us_ca_REGRESSION_ADJUSTED_NO_WINSORIZATION_CONDITIONAL_MEAN",
                  "n": 15283233,
                  "sem": 0.002690938,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.7233105718,
                  "index": 3,
                  "mean": 5.253059944,
                  "metric_name": "core_growth:visitation:dap:overall_facebook_REGRESSION_ADJUSTED_MEAN",
                  "n": 15283233,
                  "sem": 0.0008096148,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5230082536,
                  "index": 4,
                  "mean": 144.3511325338,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:friend_reshare",
                  "n": 15283233,
                  "sem": 0.0712516348,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.6007616975,
                  "index": 5,
                  "mean": 771.1197606522,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:overall",
                  "n": 15283233,
                  "sem": 0.278730593,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.468572978,
                  "index": 6,
                  "mean": 96.0093030236,
                  "metric_name": "news_feed:msi:given:feed:overall",
                  "n": 15283233,
                  "sem": 0.0767441331,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 7,
                  "mean": 0.4410132753,
                  "metric_name": "news_feed_integrity:misinfo_frx:viewer:frx_per_vpv:overall",
                  "n": 15283233,
                  "sem": 0.0002926007,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5524545101,
                  "index": 8,
                  "mean": 43.4409635813,
                  "metric_name": "news_feed_integrity:quality_sessions:discounted:survey_based",
                  "n": 15283233,
                  "sem": 0.0154373952,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105606355,
                  "index": 9,
                  "mean": 0.0526485724,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:civic_combined",
                  "n": 14993397,
                  "sem": 0.0000142092,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105606355,
                  "index": 10,
                  "mean": 0.0938198679,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:integrity_bucket",
                  "n": 14993397,
                  "sem": 0.0000237092,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105606355,
                  "index": 11,
                  "mean": 0.1120315664,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:tone_bucket",
                  "n": 14993397,
                  "sem": 0.0000297045,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1835764069,
                  "index": 12,
                  "mean": 0.601790801,
                  "metric_name": "sharing:post_production:original_broadcast_feed_post",
                  "n": 15283233,
                  "sem": 0.0007730537,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1855650568,
                  "index": 13,
                  "mean": 1.0828304521,
                  "metric_name": "sharing:post_production:original_broadcast_story_post",
                  "n": 15283233,
                  "sem": 0.0010167814,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1896384096,
                  "index": 14,
                  "mean": 1.8916542972,
                  "metric_name": "sharing:post_production:reshare_broadcast_post",
                  "n": 15283233,
                  "sem": 0.0025093767,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 15,
                  "mean": 0.0234631702,
                  "metric_name": "community_integrity:cep:viewer:holistic_prevalence_world__severity_weighted_prevalence__volume_CONDITIONAL_MEAN",
                  "n": 15289990,
                  "sem": 0.0000183635,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5943576157,
                  "index": 16,
                  "mean": 42.9460772923,
                  "metric_name": "core_app:ecosystem:sessions:core_session_count_cap15:fb_major_apps_REGRESSION_ADJUSTED_MEAN",
                  "n": 15289990,
                  "sem": 0.0090126549,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.0861003833,
                  "index": 17,
                  "mean": 6.1859679746,
                  "metric_name": "core_growth:visitation:dap:overall_facebook:us_ca_REGRESSION_ADJUSTED_NO_WINSORIZATION_CONDITIONAL_MEAN",
                  "n": 15289990,
                  "sem": 0.0026910448,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.7232989688,
                  "index": 18,
                  "mean": 5.2530734666,
                  "metric_name": "core_growth:visitation:dap:overall_facebook_REGRESSION_ADJUSTED_MEAN",
                  "n": 15289990,
                  "sem": 0.0008095639,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5203189799,
                  "index": 19,
                  "mean": 124.9564059447,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:friend_reshare",
                  "n": 15289990,
                  "sem": 0.0644851981,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.6007230221,
                  "index": 20,
                  "mean": 776.2340502565,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:overall",
                  "n": 15289990,
                  "sem": 0.2802559211,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.4688332039,
                  "index": 21,
                  "mean": 95.2948558407,
                  "metric_name": "news_feed:msi:given:feed:overall",
                  "n": 15289990,
                  "sem": 0.0763431035,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 22,
                  "mean": 0.4268038487,
                  "metric_name": "news_feed_integrity:misinfo_frx:viewer:frx_per_vpv:overall",
                  "n": 15289990,
                  "sem": 0.0002864609,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5523938865,
                  "index": 23,
                  "mean": 43.4368308249,
                  "metric_name": "news_feed_integrity:quality_sessions:discounted:survey_based",
                  "n": 15289990,
                  "sem": 0.0154338171,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105739177,
                  "index": 24,
                  "mean": 0.0526218804,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:civic_combined",
                  "n": 15000495,
                  "sem": 0.0000141969,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105739177,
                  "index": 25,
                  "mean": 0.0938625889,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:integrity_bucket",
                  "n": 15000495,
                  "sem": 0.0000237219,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105739177,
                  "index": 26,
                  "mean": 0.1120321145,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:tone_bucket",
                  "n": 15000495,
                  "sem": 0.000029704,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1837320364,
                  "index": 27,
                  "mean": 0.6042401867,
                  "metric_name": "sharing:post_production:original_broadcast_feed_post",
                  "n": 15289990,
                  "sem": 0.0007804788,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1856995328,
                  "index": 28,
                  "mean": 1.0857353483,
                  "metric_name": "sharing:post_production:original_broadcast_story_post",
                  "n": 15289990,
                  "sem": 0.0010210792,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1886899207,
                  "index": 29,
                  "mean": 1.8425556716,
                  "metric_name": "sharing:post_production:reshare_broadcast_post",
                  "n": 15289990,
                  "sem": 0.002472118,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 30,
                  "mean": 0.0234758659,
                  "metric_name": "community_integrity:cep:viewer:holistic_prevalence_world__severity_weighted_prevalence__volume_CONDITIONAL_MEAN",
                  "n": 15287970,
                  "sem": 0.0000183658,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5943156613,
                  "index": 31,
                  "mean": 42.9840239949,
                  "metric_name": "core_app:ecosystem:sessions:core_session_count_cap15:fb_major_apps_REGRESSION_ADJUSTED_MEAN",
                  "n": 15287970,
                  "sem": 0.0090161789,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.085925077,
                  "index": 32,
                  "mean": 6.1840324242,
                  "metric_name": "core_growth:visitation:dap:overall_facebook:us_ca_REGRESSION_ADJUSTED_NO_WINSORIZATION_CONDITIONAL_MEAN",
                  "n": 15287970,
                  "sem": 0.0026920247,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.7232903387,
                  "index": 33,
                  "mean": 5.2539176942,
                  "metric_name": "core_growth:visitation:dap:overall_facebook_REGRESSION_ADJUSTED_MEAN",
                  "n": 15287970,
                  "sem": 0.0008094936,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5224167107,
                  "index": 34,
                  "mean": 130.9793869507,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:friend_reshare",
                  "n": 15287970,
                  "sem": 0.0655340818,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.600656006,
                  "index": 35,
                  "mean": 773.9690557469,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:overall",
                  "n": 15287970,
                  "sem": 0.2798344807,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.4685789546,
                  "index": 36,
                  "mean": 95.4314814701,
                  "metric_name": "news_feed:msi:given:feed:overall",
                  "n": 15287970,
                  "sem": 0.0763904762,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 37,
                  "mean": 0.4415133165,
                  "metric_name": "news_feed_integrity:misinfo_frx:viewer:frx_per_vpv:overall",
                  "n": 15287970,
                  "sem": 0.0002947379,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.552376411,
                  "index": 38,
                  "mean": 43.4830552945,
                  "metric_name": "news_feed_integrity:quality_sessions:discounted:survey_based",
                  "n": 15287970,
                  "sem": 0.0154443208,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6104515161,
                  "index": 39,
                  "mean": 0.0526932045,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:civic_combined",
                  "n": 14998934,
                  "sem": 0.0000142249,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6104515161,
                  "index": 40,
                  "mean": 0.093902779,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:integrity_bucket",
                  "n": 14998934,
                  "sem": 0.0000237365,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6104515161,
                  "index": 41,
                  "mean": 0.11216702,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:tone_bucket",
                  "n": 14998934,
                  "sem": 0.0000297596,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1832859431,
                  "index": 42,
                  "mean": 0.6010995304,
                  "metric_name": "sharing:post_production:original_broadcast_feed_post",
                  "n": 15287970,
                  "sem": 0.0007760039,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1853943329,
                  "index": 43,
                  "mean": 1.0830092503,
                  "metric_name": "sharing:post_production:original_broadcast_story_post",
                  "n": 15287970,
                  "sem": 0.0010167832,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1893900237,
                  "index": 44,
                  "mean": 1.8972600673,
                  "metric_name": "sharing:post_production:reshare_broadcast_post",
                  "n": 15287970,
                  "sem": 0.0025283887,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 45,
                  "mean": 0.0234764266,
                  "metric_name": "community_integrity:cep:viewer:holistic_prevalence_world__severity_weighted_prevalence__volume_CONDITIONAL_MEAN",
                  "n": 15284115,
                  "sem": 0.0000184819,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5941572672,
                  "index": 46,
                  "mean": 42.9644921905,
                  "metric_name": "core_app:ecosystem:sessions:core_session_count_cap15:fb_major_apps_REGRESSION_ADJUSTED_MEAN",
                  "n": 15284115,
                  "sem": 0.0090143388,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.0860940264,
                  "index": 47,
                  "mean": 6.1833298083,
                  "metric_name": "core_growth:visitation:dap:overall_facebook:us_ca_REGRESSION_ADJUSTED_NO_WINSORIZATION_CONDITIONAL_MEAN",
                  "n": 15284115,
                  "sem": 0.0026918222,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.7231240409,
                  "index": 48,
                  "mean": 5.2532373516,
                  "metric_name": "core_growth:visitation:dap:overall_facebook_REGRESSION_ADJUSTED_MEAN",
                  "n": 15284115,
                  "sem": 0.0008095137,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5239163668,
                  "index": 49,
                  "mean": 135.917338799,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:friend_reshare",
                  "n": 15284115,
                  "sem": 0.0677924578,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.6005586846,
                  "index": 50,
                  "mean": 773.0315600572,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:overall",
                  "n": 15284115,
                  "sem": 0.2793378726,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.4683368975,
                  "index": 51,
                  "mean": 95.5753750194,
                  "metric_name": "news_feed:msi:given:feed:overall",
                  "n": 15284115,
                  "sem": 0.0764671795,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 52,
                  "mean": 0.4353381487,
                  "metric_name": "news_feed_integrity:misinfo_frx:viewer:frx_per_vpv:overall",
                  "n": 15284115,
                  "sem": 0.000290725,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5521461334,
                  "index": 53,
                  "mean": 43.4647469758,
                  "metric_name": "news_feed_integrity:quality_sessions:discounted:survey_based",
                  "n": 15284115,
                  "sem": 0.015444094,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6102438032,
                  "index": 54,
                  "mean": 0.0526560381,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:civic_combined",
                  "n": 14995251,
                  "sem": 0.0000142201,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6102438032,
                  "index": 55,
                  "mean": 0.0938310186,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:integrity_bucket",
                  "n": 14995251,
                  "sem": 0.0000237271,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6102438032,
                  "index": 56,
                  "mean": 0.1120714926,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:tone_bucket",
                  "n": 14995251,
                  "sem": 0.0000297418,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1834780751,
                  "index": 57,
                  "mean": 0.6025190496,
                  "metric_name": "sharing:post_production:original_broadcast_feed_post",
                  "n": 15284115,
                  "sem": 0.0007749319,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1853549257,
                  "index": 58,
                  "mean": 1.0838973392,
                  "metric_name": "sharing:post_production:original_broadcast_story_post",
                  "n": 15284115,
                  "sem": 0.0010180272,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1895265771,
                  "index": 59,
                  "mean": 1.8799604957,
                  "metric_name": "sharing:post_production:reshare_broadcast_post",
                  "n": 15284115,
                  "sem": 0.0025070415,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                }
              ],
              "schema": {
                "fields": [
                  {
                    "name": "index",
                    "type": "integer"
                  },
                  {
                    "name": "arm_name",
                    "type": "string"
                  },
                  {
                    "name": "metric_name",
                    "type": "string"
                  },
                  {
                    "name": "mean",
                    "type": "number"
                  },
                  {
                    "name": "sem",
                    "type": "number"
                  },
                  {
                    "name": "trial_index",
                    "type": "integer"
                  },
                  {
                    "name": "start_time",
                    "type": "datetime"
                  },
                  {
                    "name": "end_time",
                    "type": "datetime"
                  },
                  {
                    "name": "n",
                    "type": "integer"
                  },
                  {
                    "name": "frac_nonnull",
                    "type": "number"
                  }
                ],
                "pandas_version": "0.20.0",
                "primaryKey": [
                  "index"
                ]
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>arm_name</th>\n",
              "      <th>metric_name</th>\n",
              "      <th>mean</th>\n",
              "      <th>sem</th>\n",
              "      <th>trial_index</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>n</th>\n",
              "      <th>frac_nonnull</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0_0</td>\n",
              "      <td>community_integrity:cep:viewer:holistic_preval...</td>\n",
              "      <td>0.023474</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>15283233</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0_0</td>\n",
              "      <td>core_app:ecosystem:sessions:core_session_count...</td>\n",
              "      <td>42.953520</td>\n",
              "      <td>0.009015</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>15283233</td>\n",
              "      <td>0.594425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0_0</td>\n",
              "      <td>core_growth:visitation:dap:overall_facebook:us...</td>\n",
              "      <td>6.187919</td>\n",
              "      <td>0.002691</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>15283233</td>\n",
              "      <td>0.086002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0_0</td>\n",
              "      <td>core_growth:visitation:dap:overall_facebook_RE...</td>\n",
              "      <td>5.253060</td>\n",
              "      <td>0.000810</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>15283233</td>\n",
              "      <td>0.723311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0_0</td>\n",
              "      <td>news_feed:distinct_vpv:feed:num_vpv_given:frie...</td>\n",
              "      <td>144.351133</td>\n",
              "      <td>0.071252</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>15283233</td>\n",
              "      <td>0.523008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>status_quo</td>\n",
              "      <td>news_feed_integrity:responsible_ranking:upf_tr...</td>\n",
              "      <td>0.093951</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-08</td>\n",
              "      <td>39644461</td>\n",
              "      <td>0.610402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>status_quo</td>\n",
              "      <td>news_feed_integrity:responsible_ranking:upf_tr...</td>\n",
              "      <td>0.112255</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-08</td>\n",
              "      <td>39644461</td>\n",
              "      <td>0.610402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>status_quo</td>\n",
              "      <td>sharing:post_production:original_broadcast_fee...</td>\n",
              "      <td>0.600978</td>\n",
              "      <td>0.000580</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>40406206</td>\n",
              "      <td>0.183274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>status_quo</td>\n",
              "      <td>sharing:post_production:original_broadcast_sto...</td>\n",
              "      <td>1.083311</td>\n",
              "      <td>0.000768</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>40406206</td>\n",
              "      <td>0.185415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>status_quo</td>\n",
              "      <td>sharing:post_production:reshare_broadcast_post</td>\n",
              "      <td>1.898595</td>\n",
              "      <td>0.002042</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>40406206</td>\n",
              "      <td>0.189149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows  9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       arm_name  ... frac_nonnull\n",
              "0           0_0  ...     1.000000\n",
              "1           0_0  ...     0.594425\n",
              "2           0_0  ...     0.086002\n",
              "3           0_0  ...     0.723311\n",
              "4           0_0  ...     0.523008\n",
              "..          ...  ...          ...\n",
              "115  status_quo  ...     0.610402\n",
              "116  status_quo  ...     0.610402\n",
              "117  status_quo  ...     0.183274\n",
              "118  status_quo  ...     0.185415\n",
              "119  status_quo  ...     0.189149\n",
              "\n",
              "[120 rows x 9 columns]"
            ]
          },
          "execution_count": 61,
          "metadata": {
            "bento_obj_id": "140134931269712"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data0.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038132199,
        "executionStopTime": 1673038132236,
        "originalKey": "ad94aea0-4165-426a-a106-ef2d7033a0c4",
        "requestMsgId": "d2fb6604-ea0f-4028-9f18-c5a5d4c75251",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# TODO: understand code from Qing\n",
        "\n",
        "from ax.core.data import Data\n",
        "from ax.utils.stats.statstools import relativize_data\n",
        "\n",
        "\n",
        "def transform_batch_data_to_new_sq(data0, data1, sq_name):\n",
        "\n",
        "    # The idea is to use the status quo output in data1 as a \"new baseline\"\n",
        "    # almost like a coordinate transformation where you change the origin and axes scales\n",
        "    # the resulting data is not relativized, but can be relativized with respect to data1 status quo\n",
        "\n",
        "    # first relativize data0 wrt sq arm 0\n",
        "    rel_data = relativize_data(\n",
        "        data=data0,\n",
        "        status_quo_name=sq_name,\n",
        "        as_percent=False,\n",
        "        include_sq=True,  # it makes sense to keep it because after coord-transform the sq arm is unlike to be 0's\n",
        "    )\n",
        "    df0_t = rel_data.df.copy()\n",
        "    metric_names = data1.df[\"metric_name\"].unique()\n",
        "    df0_t = df0_t[df0_t[\"metric_name\"].isin(metric_names)]  # take the intersection of df0 and df1 metrics\n",
        "\n",
        "    for metric_name in data1.df[\"metric_name\"].unique():\n",
        "        # get metric value for data1 status quo arm\n",
        "        sq1 = data1.df[(data1.df[\"metric_name\"] == metric_name) & (data1.df[\"arm_name\"] == sq_name)][\"mean\"].item()\n",
        "        # get the row in df0_t corresponding to the current metric\n",
        "        indx = df0_t[\"metric_name\"] == metric_name\n",
        "        # scale the metric mean to a new value\n",
        "        # such that if we relativize this new value wrt sq1, we still get (m0-sq0)/sq0\n",
        "        df0_t.loc[indx, \"mean\"] = sq1 * (1 + df0_t.loc[indx, \"mean\"])\n",
        "        # scale the metric SEM by the mean of sq1\n",
        "        df0_t.loc[indx, \"sem\"] *= sq1\n",
        "\n",
        "    return Data(df0_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038133293,
        "executionStopTime": 1673038134077,
        "originalKey": "921c2d01-53ba-4e58-9b58-cffd84313f98",
        "requestMsgId": "92ec603b-c49b-46c7-b360-8ef67bce27cd",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "data1t = transform_batch_data_to_new_sq(data1, data0, \"status_quo\")\n",
        "data2t = transform_batch_data_to_new_sq(data2, data0, \"status_quo\")\n",
        "data3t = transform_batch_data_to_new_sq(data3, data0, \"status_quo\")\n",
        "\n",
        "\n",
        "all_data = Data.from_multiple_data([data0, data1t, data2t, data3t])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038134179,
        "executionStopTime": 1673038134287,
        "originalKey": "3fd984a5-72f7-4d91-a017-ff092f816213",
        "requestMsgId": "2603d2f0-3463-4ada-8714-58e12a5577ef",
        "showInput": false
      },
      "outputs": [
        {
          "data": {
            "application/vnd.dataresource+json": {
              "data": [
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 0,
                  "mean": 0.0234742739,
                  "metric_name": "community_integrity:cep:viewer:holistic_prevalence_world__severity_weighted_prevalence__volume_CONDITIONAL_MEAN",
                  "n": 15283233,
                  "sem": 0.000018505,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5944250801,
                  "index": 1,
                  "mean": 42.9535200126,
                  "metric_name": "core_app:ecosystem:sessions:core_session_count_cap15:fb_major_apps_REGRESSION_ADJUSTED_MEAN",
                  "n": 15283233,
                  "sem": 0.0090154128,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.0860017642,
                  "index": 2,
                  "mean": 6.18791888,
                  "metric_name": "core_growth:visitation:dap:overall_facebook:us_ca_REGRESSION_ADJUSTED_NO_WINSORIZATION_CONDITIONAL_MEAN",
                  "n": 15283233,
                  "sem": 0.002690938,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.7233105718,
                  "index": 3,
                  "mean": 5.253059944,
                  "metric_name": "core_growth:visitation:dap:overall_facebook_REGRESSION_ADJUSTED_MEAN",
                  "n": 15283233,
                  "sem": 0.0008096148,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5230082536,
                  "index": 4,
                  "mean": 144.3511325338,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:friend_reshare",
                  "n": 15283233,
                  "sem": 0.0712516348,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.6007616975,
                  "index": 5,
                  "mean": 771.1197606522,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:overall",
                  "n": 15283233,
                  "sem": 0.278730593,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.468572978,
                  "index": 6,
                  "mean": 96.0093030236,
                  "metric_name": "news_feed:msi:given:feed:overall",
                  "n": 15283233,
                  "sem": 0.0767441331,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 7,
                  "mean": 0.4410132753,
                  "metric_name": "news_feed_integrity:misinfo_frx:viewer:frx_per_vpv:overall",
                  "n": 15283233,
                  "sem": 0.0002926007,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5524545101,
                  "index": 8,
                  "mean": 43.4409635813,
                  "metric_name": "news_feed_integrity:quality_sessions:discounted:survey_based",
                  "n": 15283233,
                  "sem": 0.0154373952,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105606355,
                  "index": 9,
                  "mean": 0.0526485724,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:civic_combined",
                  "n": 14993397,
                  "sem": 0.0000142092,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105606355,
                  "index": 10,
                  "mean": 0.0938198679,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:integrity_bucket",
                  "n": 14993397,
                  "sem": 0.0000237092,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105606355,
                  "index": 11,
                  "mean": 0.1120315664,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:tone_bucket",
                  "n": 14993397,
                  "sem": 0.0000297045,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1835764069,
                  "index": 12,
                  "mean": 0.601790801,
                  "metric_name": "sharing:post_production:original_broadcast_feed_post",
                  "n": 15283233,
                  "sem": 0.0007730537,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1855650568,
                  "index": 13,
                  "mean": 1.0828304521,
                  "metric_name": "sharing:post_production:original_broadcast_story_post",
                  "n": 15283233,
                  "sem": 0.0010167814,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_0",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1896384096,
                  "index": 14,
                  "mean": 1.8916542972,
                  "metric_name": "sharing:post_production:reshare_broadcast_post",
                  "n": 15283233,
                  "sem": 0.0025093767,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 15,
                  "mean": 0.0234631702,
                  "metric_name": "community_integrity:cep:viewer:holistic_prevalence_world__severity_weighted_prevalence__volume_CONDITIONAL_MEAN",
                  "n": 15289990,
                  "sem": 0.0000183635,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5943576157,
                  "index": 16,
                  "mean": 42.9460772923,
                  "metric_name": "core_app:ecosystem:sessions:core_session_count_cap15:fb_major_apps_REGRESSION_ADJUSTED_MEAN",
                  "n": 15289990,
                  "sem": 0.0090126549,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.0861003833,
                  "index": 17,
                  "mean": 6.1859679746,
                  "metric_name": "core_growth:visitation:dap:overall_facebook:us_ca_REGRESSION_ADJUSTED_NO_WINSORIZATION_CONDITIONAL_MEAN",
                  "n": 15289990,
                  "sem": 0.0026910448,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.7232989688,
                  "index": 18,
                  "mean": 5.2530734666,
                  "metric_name": "core_growth:visitation:dap:overall_facebook_REGRESSION_ADJUSTED_MEAN",
                  "n": 15289990,
                  "sem": 0.0008095639,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5203189799,
                  "index": 19,
                  "mean": 124.9564059447,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:friend_reshare",
                  "n": 15289990,
                  "sem": 0.0644851981,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.6007230221,
                  "index": 20,
                  "mean": 776.2340502565,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:overall",
                  "n": 15289990,
                  "sem": 0.2802559211,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.4688332039,
                  "index": 21,
                  "mean": 95.2948558407,
                  "metric_name": "news_feed:msi:given:feed:overall",
                  "n": 15289990,
                  "sem": 0.0763431035,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 22,
                  "mean": 0.4268038487,
                  "metric_name": "news_feed_integrity:misinfo_frx:viewer:frx_per_vpv:overall",
                  "n": 15289990,
                  "sem": 0.0002864609,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5523938865,
                  "index": 23,
                  "mean": 43.4368308249,
                  "metric_name": "news_feed_integrity:quality_sessions:discounted:survey_based",
                  "n": 15289990,
                  "sem": 0.0154338171,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105739177,
                  "index": 24,
                  "mean": 0.0526218804,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:civic_combined",
                  "n": 15000495,
                  "sem": 0.0000141969,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105739177,
                  "index": 25,
                  "mean": 0.0938625889,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:integrity_bucket",
                  "n": 15000495,
                  "sem": 0.0000237219,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6105739177,
                  "index": 26,
                  "mean": 0.1120321145,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:tone_bucket",
                  "n": 15000495,
                  "sem": 0.000029704,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1837320364,
                  "index": 27,
                  "mean": 0.6042401867,
                  "metric_name": "sharing:post_production:original_broadcast_feed_post",
                  "n": 15289990,
                  "sem": 0.0007804788,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1856995328,
                  "index": 28,
                  "mean": 1.0857353483,
                  "metric_name": "sharing:post_production:original_broadcast_story_post",
                  "n": 15289990,
                  "sem": 0.0010210792,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_1",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1886899207,
                  "index": 29,
                  "mean": 1.8425556716,
                  "metric_name": "sharing:post_production:reshare_broadcast_post",
                  "n": 15289990,
                  "sem": 0.002472118,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 30,
                  "mean": 0.0234758659,
                  "metric_name": "community_integrity:cep:viewer:holistic_prevalence_world__severity_weighted_prevalence__volume_CONDITIONAL_MEAN",
                  "n": 15287970,
                  "sem": 0.0000183658,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5943156613,
                  "index": 31,
                  "mean": 42.9840239949,
                  "metric_name": "core_app:ecosystem:sessions:core_session_count_cap15:fb_major_apps_REGRESSION_ADJUSTED_MEAN",
                  "n": 15287970,
                  "sem": 0.0090161789,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.085925077,
                  "index": 32,
                  "mean": 6.1840324242,
                  "metric_name": "core_growth:visitation:dap:overall_facebook:us_ca_REGRESSION_ADJUSTED_NO_WINSORIZATION_CONDITIONAL_MEAN",
                  "n": 15287970,
                  "sem": 0.0026920247,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.7232903387,
                  "index": 33,
                  "mean": 5.2539176942,
                  "metric_name": "core_growth:visitation:dap:overall_facebook_REGRESSION_ADJUSTED_MEAN",
                  "n": 15287970,
                  "sem": 0.0008094936,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5224167107,
                  "index": 34,
                  "mean": 130.9793869507,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:friend_reshare",
                  "n": 15287970,
                  "sem": 0.0655340818,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.600656006,
                  "index": 35,
                  "mean": 773.9690557469,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:overall",
                  "n": 15287970,
                  "sem": 0.2798344807,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.4685789546,
                  "index": 36,
                  "mean": 95.4314814701,
                  "metric_name": "news_feed:msi:given:feed:overall",
                  "n": 15287970,
                  "sem": 0.0763904762,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 37,
                  "mean": 0.4415133165,
                  "metric_name": "news_feed_integrity:misinfo_frx:viewer:frx_per_vpv:overall",
                  "n": 15287970,
                  "sem": 0.0002947379,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.552376411,
                  "index": 38,
                  "mean": 43.4830552945,
                  "metric_name": "news_feed_integrity:quality_sessions:discounted:survey_based",
                  "n": 15287970,
                  "sem": 0.0154443208,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6104515161,
                  "index": 39,
                  "mean": 0.0526932045,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:civic_combined",
                  "n": 14998934,
                  "sem": 0.0000142249,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6104515161,
                  "index": 40,
                  "mean": 0.093902779,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:integrity_bucket",
                  "n": 14998934,
                  "sem": 0.0000237365,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6104515161,
                  "index": 41,
                  "mean": 0.11216702,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:tone_bucket",
                  "n": 14998934,
                  "sem": 0.0000297596,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1832859431,
                  "index": 42,
                  "mean": 0.6010995304,
                  "metric_name": "sharing:post_production:original_broadcast_feed_post",
                  "n": 15287970,
                  "sem": 0.0007760039,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1853943329,
                  "index": 43,
                  "mean": 1.0830092503,
                  "metric_name": "sharing:post_production:original_broadcast_story_post",
                  "n": 15287970,
                  "sem": 0.0010167832,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_2",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1893900237,
                  "index": 44,
                  "mean": 1.8972600673,
                  "metric_name": "sharing:post_production:reshare_broadcast_post",
                  "n": 15287970,
                  "sem": 0.0025283887,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 45,
                  "mean": 0.0234764266,
                  "metric_name": "community_integrity:cep:viewer:holistic_prevalence_world__severity_weighted_prevalence__volume_CONDITIONAL_MEAN",
                  "n": 15284115,
                  "sem": 0.0000184819,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5941572672,
                  "index": 46,
                  "mean": 42.9644921905,
                  "metric_name": "core_app:ecosystem:sessions:core_session_count_cap15:fb_major_apps_REGRESSION_ADJUSTED_MEAN",
                  "n": 15284115,
                  "sem": 0.0090143388,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.0860940264,
                  "index": 47,
                  "mean": 6.1833298083,
                  "metric_name": "core_growth:visitation:dap:overall_facebook:us_ca_REGRESSION_ADJUSTED_NO_WINSORIZATION_CONDITIONAL_MEAN",
                  "n": 15284115,
                  "sem": 0.0026918222,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.7231240409,
                  "index": 48,
                  "mean": 5.2532373516,
                  "metric_name": "core_growth:visitation:dap:overall_facebook_REGRESSION_ADJUSTED_MEAN",
                  "n": 15284115,
                  "sem": 0.0008095137,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5239163668,
                  "index": 49,
                  "mean": 135.917338799,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:friend_reshare",
                  "n": 15284115,
                  "sem": 0.0677924578,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.6005586846,
                  "index": 50,
                  "mean": 773.0315600572,
                  "metric_name": "news_feed:distinct_vpv:feed:num_vpv_given:overall",
                  "n": 15284115,
                  "sem": 0.2793378726,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.4683368975,
                  "index": 51,
                  "mean": 95.5753750194,
                  "metric_name": "news_feed:msi:given:feed:overall",
                  "n": 15284115,
                  "sem": 0.0764671795,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 1,
                  "index": 52,
                  "mean": 0.4353381487,
                  "metric_name": "news_feed_integrity:misinfo_frx:viewer:frx_per_vpv:overall",
                  "n": 15284115,
                  "sem": 0.000290725,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.5521461334,
                  "index": 53,
                  "mean": 43.4647469758,
                  "metric_name": "news_feed_integrity:quality_sessions:discounted:survey_based",
                  "n": 15284115,
                  "sem": 0.015444094,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6102438032,
                  "index": 54,
                  "mean": 0.0526560381,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:civic_combined",
                  "n": 14995251,
                  "sem": 0.0000142201,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6102438032,
                  "index": 55,
                  "mean": 0.0938310186,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:integrity_bucket",
                  "n": 14995251,
                  "sem": 0.0000237271,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-08T00:00:00.000Z",
                  "frac_nonnull": 0.6102438032,
                  "index": 56,
                  "mean": 0.1120714926,
                  "metric_name": "news_feed_integrity:responsible_ranking:upf_trips_proxy_metric:tone_bucket",
                  "n": 14995251,
                  "sem": 0.0000297418,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1834780751,
                  "index": 57,
                  "mean": 0.6025190496,
                  "metric_name": "sharing:post_production:original_broadcast_feed_post",
                  "n": 15284115,
                  "sem": 0.0007749319,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1853549257,
                  "index": 58,
                  "mean": 1.0838973392,
                  "metric_name": "sharing:post_production:original_broadcast_story_post",
                  "n": 15284115,
                  "sem": 0.0010180272,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                },
                {
                  "arm_name": "0_3",
                  "end_time": "2022-08-10T00:00:00.000Z",
                  "frac_nonnull": 0.1895265771,
                  "index": 59,
                  "mean": 1.8799604957,
                  "metric_name": "sharing:post_production:reshare_broadcast_post",
                  "n": 15284115,
                  "sem": 0.0025070415,
                  "start_time": "2022-07-28T00:00:00.000Z",
                  "trial_index": 0
                }
              ],
              "schema": {
                "fields": [
                  {
                    "name": "index",
                    "type": "integer"
                  },
                  {
                    "name": "arm_name",
                    "type": "string"
                  },
                  {
                    "name": "metric_name",
                    "type": "string"
                  },
                  {
                    "name": "mean",
                    "type": "number"
                  },
                  {
                    "name": "sem",
                    "type": "number"
                  },
                  {
                    "name": "trial_index",
                    "type": "integer"
                  },
                  {
                    "name": "start_time",
                    "type": "datetime"
                  },
                  {
                    "name": "end_time",
                    "type": "datetime"
                  },
                  {
                    "name": "n",
                    "type": "integer"
                  },
                  {
                    "name": "frac_nonnull",
                    "type": "number"
                  }
                ],
                "pandas_version": "0.20.0",
                "primaryKey": [
                  "index"
                ]
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>arm_name</th>\n",
              "      <th>metric_name</th>\n",
              "      <th>mean</th>\n",
              "      <th>sem</th>\n",
              "      <th>trial_index</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>n</th>\n",
              "      <th>frac_nonnull</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0_0</td>\n",
              "      <td>community_integrity:cep:viewer:holistic_preval...</td>\n",
              "      <td>0.023474</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>15283233</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0_0</td>\n",
              "      <td>core_app:ecosystem:sessions:core_session_count...</td>\n",
              "      <td>42.953520</td>\n",
              "      <td>0.009015</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>15283233</td>\n",
              "      <td>0.594425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0_0</td>\n",
              "      <td>core_growth:visitation:dap:overall_facebook:us...</td>\n",
              "      <td>6.187919</td>\n",
              "      <td>0.002691</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>15283233</td>\n",
              "      <td>0.086002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0_0</td>\n",
              "      <td>core_growth:visitation:dap:overall_facebook_RE...</td>\n",
              "      <td>5.253060</td>\n",
              "      <td>0.000810</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>15283233</td>\n",
              "      <td>0.723311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0_0</td>\n",
              "      <td>news_feed:distinct_vpv:feed:num_vpv_given:frie...</td>\n",
              "      <td>144.351133</td>\n",
              "      <td>0.071252</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-07-28</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>15283233</td>\n",
              "      <td>0.523008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>3_2</td>\n",
              "      <td>sharing:post_production:reshare_broadcast_post</td>\n",
              "      <td>1.876236</td>\n",
              "      <td>0.003962</td>\n",
              "      <td>3</td>\n",
              "      <td>2022-08-05</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>10300168</td>\n",
              "      <td>0.165203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>3_3</td>\n",
              "      <td>sharing:post_production:reshare_broadcast_post</td>\n",
              "      <td>1.853779</td>\n",
              "      <td>0.003916</td>\n",
              "      <td>3</td>\n",
              "      <td>2022-08-05</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>10288358</td>\n",
              "      <td>0.165134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>3_4</td>\n",
              "      <td>sharing:post_production:reshare_broadcast_post</td>\n",
              "      <td>1.873537</td>\n",
              "      <td>0.003966</td>\n",
              "      <td>3</td>\n",
              "      <td>2022-08-05</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>10290453</td>\n",
              "      <td>0.165329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>3_5</td>\n",
              "      <td>sharing:post_production:reshare_broadcast_post</td>\n",
              "      <td>1.874318</td>\n",
              "      <td>0.003980</td>\n",
              "      <td>3</td>\n",
              "      <td>2022-08-05</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>10288659</td>\n",
              "      <td>0.165298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>status_quo</td>\n",
              "      <td>sharing:post_production:reshare_broadcast_post</td>\n",
              "      <td>1.898595</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3</td>\n",
              "      <td>2022-08-05</td>\n",
              "      <td>2022-08-10</td>\n",
              "      <td>30869149</td>\n",
              "      <td>0.165441</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>525 rows  9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       arm_name  ... frac_nonnull\n",
              "0           0_0  ...     1.000000\n",
              "1           0_0  ...     0.594425\n",
              "2           0_0  ...     0.086002\n",
              "3           0_0  ...     0.723311\n",
              "4           0_0  ...     0.523008\n",
              "..          ...  ...          ...\n",
              "520         3_2  ...     0.165203\n",
              "521         3_3  ...     0.165134\n",
              "522         3_4  ...     0.165329\n",
              "523         3_5  ...     0.165298\n",
              "524  status_quo  ...     0.165441\n",
              "\n",
              "[525 rows x 9 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {
            "bento_obj_id": "140135444680368"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038135260,
        "executionStopTime": 1673038135329,
        "originalKey": "34878903-4fd4-48bf-a9b8-8d2b6c730442",
        "requestMsgId": "bf6ad7bf-9b7d-42c5-a8e4-a7b2585f3d51",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "df_rel = pd.pivot_table(all_data.df, values=[\"mean\"], index=[\"trial_index\", \"arm_name\"], columns=[\"metric_name\"])\n",
        "# df_rel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038135361,
        "executionStopTime": 1673038135476,
        "originalKey": "41b37503-f0fd-4f9f-93d8-dd18b7517271",
        "requestMsgId": "fd92aa9a-7538-40a4-b0ba-9125b88c3c11",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35, 15)"
            ]
          },
          "execution_count": 66,
          "metadata": {
            "bento_obj_id": "140135572163520"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_rel.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038136299,
        "executionStopTime": 1673038136311,
        "originalKey": "8b9c0dc6-48e9-47a4-983a-d805af101bfe",
        "requestMsgId": "0f344be0-1b5f-4554-943c-b5cf111de3d2",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# drop the 4 status-quo arms because they have NaN input\n",
        "df_rel = df_rel.reset_index(level=0, drop=True).drop(\"status_quo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038136398,
        "executionStopTime": 1673038136522,
        "originalKey": "6da6e458-dad6-473b-b0c9-1f0b31a4218f",
        "requestMsgId": "613043b8-5fe2-409e-b3a2-8c48efbd4179",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(31, 15)"
            ]
          },
          "execution_count": 68,
          "metadata": {
            "bento_obj_id": "140135467959744"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_rel.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038136611,
        "executionStopTime": 1673038136812,
        "originalKey": "5a3e4a67-483e-4ee9-8530-27920a317bb5",
        "requestMsgId": "64fb36c6-a10f-4311-91bb-0ee925524d4f",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# get design data\n",
        "X = pd.DataFrame(experiment.arms_by_name[arm_name].parameters for arm_name in [df_rel.index[i] for i in range(len(df_rel))])\n",
        "X = torch.tensor(X.values, dtype = torch.double)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038136887,
        "executionStopTime": 1673038136905,
        "originalKey": "956bea08-b61b-4b51-afe1-69ab76ce197f",
        "requestMsgId": "1a696007-02be-414d-9b75-909761e8835f",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "Y = torch.tensor(df_rel.values, dtype = torch.double)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038137008,
        "executionStopTime": 1673038137110,
        "originalKey": "ff8f077c-7c58-4b73-84b0-0a9264b86fff",
        "requestMsgId": "c8e15710-0b16-4acb-addf-c2d9a9c3c55f",
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([31, 3]) torch.Size([31, 15])\n"
          ]
        }
      ],
      "source": [
        "print(X.shape, Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038138601,
        "executionStopTime": 1673038141883,
        "originalKey": "2622d1d6-6944-4e15-b35b-dbf358842847",
        "requestMsgId": "2a363a2c-4efe-4b61-a6b3-95419c8c6db0",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 792x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "bento_obj_id": "140134947054400",
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot empirical correlation of generated metrics\n",
        "metric_corr = np.corrcoef(Y.numpy(), rowvar=False)\n",
        "\n",
        "mask = np.triu(np.ones_like(metric_corr, dtype=bool))\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "# cmap = sns.diverging_palette(250, 20, as_cmap=True)\n",
        "cmap = sns.diverging_palette(300, 145, s=60, as_cmap=True)\n",
        "\n",
        "sns.heatmap(\n",
        "    metric_corr,\n",
        "    mask=mask,\n",
        "    cmap=cmap,\n",
        "    annot=True,\n",
        "    center=0,\n",
        "    square=True,\n",
        "    linewidths=0.5,\n",
        "    cbar_kws={\"shrink\": 0.5},\n",
        "    annot_kws={\"fontsize\": 10},\n",
        ")\n",
        "plt.title(\"Correlation between metrics\")\n",
        "\n",
        "plt.savefig('A_exam_feed_integrity_control_panel_vm_tuning_heatmap.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038141906,
        "executionStopTime": 1673038142765,
        "originalKey": "5ded6f16-6f5b-4a42-8e92-5df0225664c5",
        "requestMsgId": "3655e5c3-7aff-4a8f-bac5-60df91a5f15b",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'PCA explained variance')"
            ]
          },
          "execution_count": 73,
          "metadata": {
            "bento_obj_id": "140134992978560"
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEpCAYAAABWTc9yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZhcRbnH8e8khCQgEEISwxZEVoULiqCCuKAUQiloXQEXiAjIooiXRRaVC1wVAiKbsiiIyI6ilggUSCGLigsQEYWwL1GMEcISIISQZe4feTucNN3Tp6d7Jj0zv8/zzDPdZ+uqc7rPe2o5dbq6u7sRERFpxbBlnQARERn4FExERKRlCiYiItIyBRMREWmZgomIiLRMwURERFq23LJOgEh/cz78HngP8GhOcf02b/vzwPn29r05xd+3c/v9ZbDkoyd9+T0YihRMRNprHjDbXi9YxmmRnr1ox+qFZZ2QwUDBpAfOh+OB4xosNh94HrgfuBm4IKf4ZMntjwJ2B7YHtgQmAKvYCWkmcB+Qgctzis82mfa1gceB4Tbpf3OK32pmG9K8nOIlwCXLOh3SWE5xp2WdhsFEbSblzbGrmOq/bmA88D7geOBB58MBjTbmfNgfeAK4CJgMvAVYzYLTisB6wC7A94B/Oh/+1/nQTPD/ggWSl+z9Ac6H4Q3WERHpFZVMyvt4TvGmWjOcD2vaif844I3A950PL+UUL6ux7DDgR8BeNulZ4AzgV8D9OcVXnQ8rAesDewJ7A6sC3wDe5XwIOcX5PSXU+TAS+Ly9PQY4BVjL0hjbsTNERIoUTNogp/gv4Fznw43AX4E3AKc6H36SU6yuNz+pEEh+C4TqKqyc4ovA3cDdzofvWqDZDPiIrX94gyR90kpL84AfWzXaR4EvKpiISF9QMGmjnOKjzodLrIrpjcA7gT9U5jsf3gUcYW+nATvmFOc22OZ058OHgQesPWV358M3coqze1jtS/b/6pzibOfDpRZMPuR82DCn+FA78ut8WAM4GPgwsK5Vzz0L3AtcA5yfU3y5ap1DgNPt7aE5xTPqbPvjhcB3fk5xf5t+OPAdm74B8CRwiLU9vQkYDfwLuAGYYoG+2XwtB3wG2A3Y3NqyuoBnLMhfClyZU3zdKKk99YJyPvwK2Bm4J6f4NufDG+3CYGdgbfuM6bbvTsopPtfOfV+1/rrA1wAHTLTG6Pvt4uPCZveZbXMtS/8w4Jqc4i4Nlv8qcKK93S2n+LPCvDHAAXYBtbGVzucDM4A/AufmFP9QZ7uXAnsU9vO+wKFW2r83p7glJXpztfg9+G/g5/b27cA9wOfs7y3AGGCW5eXbOcU/97CfVrBzysdt3VWA54C7gAtzilf1sO5ywGeBXS0dY4G5wD+BW4Cz2nU+UJtJ+/298PpNVfO+Xni9f6NAUpFTnGkny/cB6/QUSJwPWwJb2dvKSeFq+/J12ZeyZc6HTwKPAEfbl3Qlaz96I/Ahq7qb5nzYtGrVM62jAsC3nA/r1Nj2SsBZ9vYx4LDC7OIJcryV7qZYGkYDo6y96SDgXufDFk3mawzwe2vL+qid5Jezfbc64IHLgWucDyOa2XYx7c6HjYGpdnGxgX3GCnayOBL4o+2HWmns7b6vrP9eCzqfB9YBRlowei9wAXBVb84N1vHkt/Z2B+fDKg1W+ZT9f84CYCV9b7fAdpKlaTywsHBs9wR+73w4plGanA97AD8ENrHedYvK5KUN34Pi93QY8BOr3n6f7esRtp3/trz4OunY2C48vwNsa8Fgoe2TnYCfOh+utYBTve7a9h27wJadaOuuAmxqFyPTnA+HltknjSiYtF+xkXtJ24bzYUVgR3v7l5zi7c1sNKd4Y07xdznFRj+Gg+3/P4Ebbd1X7CoK4HO1vnjNcD5sD1xhJ+87gQ/aD30UMMlOci/Ziep658OqhXx029XZbPtRnVvjI6YAa9oXf3JO8aXCvGK14cnARsB+wJic4mhgHPBNmz8G+InzYfkmsncW8C57fZGd6Je3vG0IXGnzPgJ8tYntYvnBtvUT4CngA8DyOcVRwJst8GP5+p/qDbSy73ktUP/UAtd8+4yVc4orWAeQQy1vBzWZt4rK92yktdHVZCfJzeztlTnFeTZ9hF3RT7QT/xHABNs/o+2E+hc7qX/T+fC+HtIyDPiW7a/Vc4pvsPXLaPV7sLDw+ihb7kv2PV3RqsIPsuWWA850PnRV7aOV7Te8jn1XPgWsYPtiHQuSlTScXbXuCrbuZlbqPAhYzY7zGAsuf7Pz1WnOh91K7pe6VM3VflsVXt9feP0euxrBuvu2nfNhnLWXYMXfYuA53wLNGCu6/7DOZhp9xjDg+/Zjvgd4f1UJ65/Ayc6HO4HfWMP/4dYRABYHlH86Hw4GLgZ2cj58Oqd4Ba9VBVZKT9+uUZVRrFJ4L+BzitcXtv0McKzzYYJVk6wPBDt5N8rbyoWr5YeAvauqMB52PnwG+C+70t3XOkaUVdnWRlay2MLaxyppf9z5sJdV061oJ4kl3bnbse+BfexEjXUX/27h858FznA+PGPHpjd+ZifiSrf3et2kP114fVHhtbNqO6ybfaVKEws4tzsfdrbqtOWsdPVbatvU9tNnK22XOcVXG2WgTd+D4vK71/iezgHOcT5sbSWt9S1IPVhY76tWIgL4RLHKNKf4D2A/58Pq9j3Zy/lwYk7xYVvkCKseXGSfXVx3NnCD8+G3VnLZGPiO8+EXOcViEGyKSiZt5HzYvHAy/3tO8d7C7GJ1zr30jf3sinCRFamXyCn+HbjD3n6xhc/Y3qoaAE6oV1WXU7zZqgkodDgozr+kUKd8hvNhrNXvnmffy7+WuMfnjuIPtMpZhdc7N8zV4jS9YNUI61l71uvqwm3arfZ2kp14euOEYiApbH+2/cCxq+Giduz7j9v/hRaYarnU7lFqmqX/WnvbU1VX5XfyUFV7wfVWuty4qlq4+BkzCifdmlV5pgs4u0YnmEZ5aPf34LYevqc3F14vOd5WStnb3t7ZwwgEZ9g+u8yqvir2t/831FvX2tQqwXoS8P4e8tCQSiYtsm64bwI+Zl/+kdaL6sCqRVcrvG7qBsSS6Rhe+MybcorTayx2vnUKeLvz4d05xT/14qM+UHh9Rw/LYT+2bYG1nA9r1mgMP9BKbBPtS/2QFctfAfZs1AUaqNlVm8U/lHudDy9ae8Jm9Zarsd4LJe6Ifr7weqVe3kHdU+n0qcK2i9qx799m/++t1/aWU+x2PtxkFye9cak1+C5vv4ulSjnWJrKRvS2WSion6WfsryeVY1CzXangd02nvv3fgzLHmqq8bGBtYAB1q8TtdoWlfgfOhw2BNextme9JxdZVwa0pCiblZedDmeX+bcXq6uqZYn1oX+z3ne3qgh6qsK60nlRvsNJJb4LJRoXXf3M+9PTc52JbxSSrvlkipzjLej9da1dhlSqIr+UU7yuRlvsbzP+HVUOsWWJbS1jD5WetGm09YGW7SKgYVXjdVWMTjXTb96Seefa/+ibTlva9NSqPsWm1LjaKHmkwvyfJgsFqVsVTXWVWqUJaVK8azDqS7GEjQ6xlJ9ri7+YN9r/R/m+Uz7ra+D2Y0cO8eYXXxeO9YeF1s3kofk+ObqKBfVKJZepSMClvTp2xlhZYb5Rp1h31kqoG44piaWRcH6Sv0h14jt2Fv3Gd5W62htHdnQ+H5RRnNfk5Ywqvm6niqVndkVO8zrpTT7YT4B1WdC/j+QbzK8eh0dXrEtZmca419vaVRSU6UtTS6r4vrvO6KrYqvR6vKqc43/lwlZU8nfNhlapS0O72/5ac4j+L61r1zvda6ABQtMg6nzStzd+DRiXsWorHutb5pOy6o6qCXk8a9b7rkYJJeXXvgC/pgcLrd1S3abTCAseH7O2K1ujYyEhrODy5yY8rngRHlmnQ7In1ctu6MGkT69X0aInVG9WFV9oEy3YH3dKOyzDb9unWTfZh4IVKAHA+fKtefX4fa3XfN1OKavXccKkFk+WtneYiFu+7rQtd5ms18h9aCCRPAycAv7ZS7UuV9ovCPSI96ankVlcHfg+aLf0WvycH5BTPa3N6alIw6T93WFvAKMA7H4Y1e3XqfBhep7fFl2pMK+MA58MpTaajWBpYrUF1TRmnWE+W5+0mrvWBS5wP7y3Rs6RRiaNSFdLoKrziy4UA9MWc4vl1luvLUktPWt33xSvcN/SwHFVXt03LKd7ufHjMLgx2K7SNVKq45hQ6YBRVukMvAD6QU5xW5yP68hh0wvegeKybPRbV35N+oWDST3KKc50Pv7Qf05usqH9liVVhcSB5t92g9B27u3kur9038Flb7Lac4gd63hI4Hw4DTrUumDsB1zWRleKPe/NWgonzYYdCN+DD7crvNiupHFW4O7qe9erNsOqSSh1w2Z5JlRsc5zW4C7ynHkR9qdV9/6zdTLdCifrxjRrML+Ny65bsrFfXi9YwD/Az6x67hHVtr6TrtnqBxDq9VPd0a6dO+B4Uuwg3eyyqvyf9Ql2D+9dJhZuZvmtDYjRkN55dYn3OT6k6EXy2cIVe7wqq2sWFxu5muwkX+/Tv2sNyOB92cD68r9ZoxZanSlXfTTnFH+UUf1e4ifF46/XTkw/1MG9zq/LDhr4oo3Iz5+x63Umtp8z2JbfXbi3te6siqozQsKnzoWbpxNZpRx4rjevL2/0j2xZ6GV1UY/nizbQ99eaa3Ew7WC90wvfgEXsMBcD21Tc0FtLxHufDLPs7CLtfye45AtjRqpJrcj6s4XzY0/kwttUEK5j0o5ziPXZ3N9Yn/DbnQ49PeLPxjm6y6h+Ao3OKxauWSjB4rk61Qa10zAJ+aW93dD68uYls3Fxoz/hsveFKrCfMZVbSqHV1d5b1sppT1QX1aOuFNcKqu0bWWLfiQ3aTYy1fLrz+ZZ1lqlV+gBNqBXq7ur6iqnG6pUbLJrVj31fuARlRGFm62oGFGxt7zcZ8usve7mQ3j2LH99Yaq/yncJGzWa0TqA0Rc2qhKqcv9v8y/x5Y4K8cu3UKtQ/VDrCqrNWq9mmlR+cq9W6stf37HQv6j1tvv15TMOl/xwI/sNfr2/hRZzgftraHZeF8GOZ82NT58E17QFblpHFiTrEySCLOhw8Bb7W3FzfZc6VSihlW456YuuxL/gVr3BwB/Nr58LnKVa7zYYzzYU+7aW6cnRyWeiiX82FXuwsf4Ks5xScK23/RfiBYY3xPVV3TbGykPStXX86Hcc6HEws3fP3FetmVcU3h9aWVIOt8WNnueJ5qV9bFscL2sOPVmy7CTWnHvrfvXuUkeJLz4QtV++4oa3D+Y5uSXRle5cOFm0cvqXMj4LzCPRkbA6dXTnB2BX2kpevOQql2nPNhR147ObZDp3wPTi4EtnOdDwdVxmtzPkxyPpxtpTTsAXrF7vSV+7YADnM+nGODe+J8WN758E4buqcyEsFpOcVGvSN7pGDSz3KK3TnFA218qqesV9X/2OjCc50Pc+wk8Herb17ZruRCTrG650ix4b3Z4VF+Y4MoAuxTCWQl85BtCIhX7KR1IfCi82GulZAusaq454AdiqOSOh8mFu68vr16TCHb/g2FKpJDnQ/12oG+an34LwFesn33dGGspJnAp2qduOo42+68B9gOeNT58IqNI3aZNYTubG1MlcD9VRuF9dslP6Mlrex7W/9pu8qdb9+9c2z9yr47ye4T+U5htVbaVq+wxvQ1C21cPQ3V8pXCY4//B3jOjsG/7OT6kN09f1thnettmY+0kM6ijvgeWHfqD9vvf7SV5l+wtEwv1ErcUH2Dqd3dvkOhWvMLwGO27ivAnwvB/dQmhwWqScFkGckpXmTF1z3tB/eA9bYZZV/K++2qbndgvZziUlU1VpVR+TL8sWroljKf322jiVK4uayZ9S+3k8MUu1J7zr5PT1pgPBLYKKd4W9Wq59vnvQLs20NPskOs2qML+HGd4Sqes8b6o60E8qpt92HgNOC/CmMVlcnTXBtS4iQ7ac2z7f3Nfmyb5hTvyik+ZVeED1Y9YrlftLDvK+tfbaXdS+0kPd++c7dbKTVU3RfV64FBbV8V7wD/U09DnucUH7AbFS+xC4X5dhL/vZ0Qt7Hx166xUte/7Bg8Un1TbAtp7pjvQU7xfhtJ+gg7Ps/azY2zLIh8ysbeet3jBmwUjC1sPLZkHTa67Ptyrw1d9M6c4leauOCqq6u7u+VtiPSbnp4XIiLLjkomIiLSMgUTERFpmYKJiIi0TMFERERaNpSDSfdA/Hv26ZnLPA3LMh+HfvmLS+7yP/2UE363rPMxmI6J8tKZfx2Yj5o0NtcAs2hhb0Yu7zy9zYff0eF3dG1PTysGyzFBeelIAyUfQ7lkIiIibaJgIiIiLVMwERGRlimYiIhIyxRMRESkZf3em8uGQb7QBlJbtzj8eI1lR9vDoHaz0XPvA47MKd5cZr6IiPSPfg0mzodgw4+Xfb7EOTYq7HY25PKBwHXOh81sNNhG8zvezBcWceP9C3h5HixY1M2CRbBwESywv4WLulmw8LVpc+aMZLmRc5debqEtV5hWZvzOEou8tmwzC5cwf/5oRox43UCnA5Ly0pkGS14q+TjxYyN56+qve2hpx+jvkslY4H32+Nl6Tw6DxYFnrA3PvmvhWdCnOh/2AA50PpzQ03x7pnhHu/jPr/L1q+exoKlu5Mvb4yEGuuUKTzAe6JSXzjRY8rI4Hy/Oa/MVXZv1azDJKV7Aa8/iaGQLS9+dVdPvAN5dYn6Pnn165jK7GWjhIjjt9yO5+C/LL5PPF5GBZ/YzzzBr1LIPjuMmvu5JxtDhd8BPsP/PVE2fZc+nbjS/R2PHt/yI616ZM6+bg658hV/fPxhKFyLSX1ZZbTXGTezcU3bnpqy+rgbV/Y3mLzMzZi9irx/P5d5/L10iGj0CPrPVCEaN6GL4MFhuGEv+LzfstWnLDYe5L85mzKpjCvMryy5ebslf2SdRN/HE6nY+3Hr2s8+wytjV2rjFZUd56UyDJS+VfLxlYue2l9DhwWSm/R9vjyOtmGDzGs3vKPc8uZDPXTyXmS8sHecmrtzFRXuNZrM1y31RZs2cz7iJI/oolf1n1goLO/oqqxnKS2caLHkZKPno5PtMptozvbeumr6NPQu50fyOcf198wk/ePl1gWTTNYaRDlqhdCAREelUHRXunA9TgEk5xT1yirOdDxcAU5wP06zr7+HAOsA5jeYv67wAdHd38/3fzeeb1897XdfaD79lOc7+1ChWHNnOyiMRkWWjv+8zedBO9pUS0YPOh27gkpzifsDqNr/iUOBk4BZgJeCvwA45xekl5y8z8xd2c/Qv53H5nfNfN+/A947gmJ1GMnyYAomIDA5d3e2+G23g6LOMP/9yN/tfPpffPbJ0N77hw2DKx0Yy+V297xI8a+aMul3zBpLBkg+Ul441WPLSgfmoeRXcUdVcg8ETzyxizx/P5dGnl+6xtfIoOG+P0bx/A+1yERl8dGZroz89voB9LnmF515eutAzaWwXl3xuNBtOUEO7iAxOCiZt8rO753P4z17h1aobVLdaZzg/mjyKcW/o5I5zIiKtUTBpUXd3N6fkVzn95ldfNy+8bTlO+8QoRo1QQ7uIDG4KJi2YO7+bQ696hav/9vqhUY7YfnkO/dDydHUpkIjI4Kdg0ktPv7iIvS+Zy9R/LN3QPnI5OH3XUYS3Dfy71EVEylIw6YUH/7OQPS+cy5PPL93QvtqKXVz42dFstY4a2kVkaFEwadItDy3ggMvm8uK8padvOGEYl3xuNJPGqqFdRIYeBZMmXPSnV/n6r+ZR/RiU920wnPP3GM3Ko9Q+IiJDk4JJSZfd8SpH/3Le66ZPftcITthlJCNKj/kuIjL4qE6mpF02G8HGb3xtd3V1wfEfGcnJH1cgERFRMClppVFdXPy50Yx7QxcrLA8/njyaA96rrr8iIqiaqzlrrzqMi/cazYjhsOka6rElIlKhYNKkt6+tICIiUk3VXCIi0jIFExERaZmCiYiItEzBREREWqZgIiIiLVMwERGRlimYiIhIyxRMRESkZQomIiLSMgUTERFpmYKJiIi0TMFERERapmAiIiItUzAREZGW9esQ9M6H0cApwG7AysB9wJE5xZvrLL8WcBLwQWAV4G7gkJziXTZ/Y+DbwDbACOAB4Bs5xev6M18iIkNdf5dMzgG2B7YDxgFXANc5HzaoXtD5MBy4Flgd2BIYD9wCZOfDBOdDF/Br4EVgPdveZcAvLciIiEg/qVsycT6cV3IbI3KKezdayPkwFtgT2DWnOM0mn+p82AM4EDi8apUNgc2BbXKKM2wbxwKTgb2Ai4FJwOU5xdk2/wLgTFvvgZLpFxGRFvVUzfVfVe83BRYC04HhwDrAIuD2kp+1hX3enVXT7wDeXWP5ysPVl5SecordzoengK1yiqc4H24D9nE+/NlKKAcAzwC3lkyTiIi0Qd1gklPcuvLa+XAY8Fvgf3OKr/Ja+8cJwMySnzXB/j9TNX0WMLHG8g8C04ATnA+TgReAfYFNgDm2zO7A9cDTQLdta9ec4n8aJebZp2eyaOGikknvHAsWzGfWzBnLOhktGyz5QHnpWIMlL52Wj3ET16g5vWwD/KHARpVAwuJgM9f5cJxVJ327hbR1WSBYSk5xofNhF+AM4B4LIBdaqWOE82F5azN5ANgJeMmqv65xPmydU7y3pw8dO75W/Op8s2bOqHswB5LBkg+Ul441WPIyUPJRNpisCKwGvFw1fRWbV0alBDMeeLIwfUK90k1O8VFg5+I058PdwFRryH8bsFNO8Smbfa7z4QvAPsBhJdMlIiItKhtMfgNc73w4C3jCShJvAr5oPazKmAq8CmwNXFWYvo312nod58OuwH05xfvt/SRrXD+lsFhX1WrL1SrpiIhI3ykbTPazXlKnAaNs2gLgBpvXUE5xtvW2muJ8mGYN+YdbQ/45LA4WU4BJOcU9bLV9gJWcD8Ea+8+1dpSrrEQ0EzjJ+XCIVYPtCWxkDfEiItJPSgWTnOLz1h6xl/NhAjASmJlTnN/k5x0KnGylmZWAvwI75BSn2/zVLbhU7A38AHjESiA32vLzgeedDx8GTgQeApa3/7vlFH/XZLpERKQFXd3d5WqEnA8rAgFYJ6d4gk1bo3IPyAA0IKvCBkpjXCODJR8oLx1rsOSlA/NR3bQAZe+Adz5sCjxmVV3H2rR1gYedD9u2O6UiIjKwlB1O5TvWLXe8tV2QU3wcONLGzhIRkSGsbDDZAvi/nOKiquqh82rcKS8iIkNM2WAyss6yY9ucHhERGYDKBpNbgRNtJF9Y3GayNnCBxsESEZGy95kcYjcWvgSMdD7MAla1oUx2LrG+iIgMYmXvM3nc+bAZ4G1o+EV2T8cNOcWFfZ9MERHpZKWftGhB45q+TY6IiAxEpYKJ3VPyLRv+fYXq+TnFDfskdSIiMiCULZlcZKMGZ2BuH6dJREQGmLLBZAtgLRujS0REZClluwb/G5jXx2kREZEBqmwwOQY4xfkwqsSyIiIyxJSt5joYeAuwn/Ph35XxuSpyim/um+SJiMhAUDaY/L6JJyqKiMgQU/amxaP7PikiIjJQ1Q0mzoev5RRPtNfH9rCN7pziN/skdSIiMiD0VDLZ2x6JS4PnvHcDCiYiIkNY3WCSU9yg8Hrtess5H97UFwkTEZGBo2zX4JqcDxOBO9qXHBERGYjKjs21DvBD4F1A8V6T4cCDfZc8EREZCMqWTM6yZY+x9/8DXAz8GXhvH6ZPREQGgLLBZGsg5BS/CyzIKZ6bU/w8cAVweB+nUUREOlzZYDIcmGOvX3U+jLTX37deXyIiMoSVDSb3AlOcDyOAJ4DP2/RNqtpQRERkCCobTI4G9gVGAt8FvmdjdP0Z+EUfp1FERDpcqWCSU7wdWCOn+FJO8UfAdsAZwF4NbmgUEZEhoJlnwM8rvL4NuK3PUiUiIgNKT2NzPW5DpTSkIehFRIa2nkoml5UNJmU5H0YDpwC7ASsD9wFH5hRvrrP8WsBJwAeBVYC7gUNyincVltkHOApYB5gBfC+neHo70y0iIj3raWyuY+rNa8E5ds/KdsB04EDgOufDZjnFh4sLOh+GA9cCzwBbAs8DXwWy82GjnOJTzodPAscCnwT+CmwPnOZ8+H1O8c4+SL+IiNRQus3E+bAfEIBJwFwLBpflFGPJ9ccCewK75hSn2eRTnQ97WFCpvvlxQ2BzYJuc4gxeGwp/sjX8nwIcBxyRU/yzrXOd/YmISD8qOzbX8dY9+EbgN0AXsB5whfPh+JziSSU2s4V9XnWJ4Q7g3TWW77L/S3qc5RS7nQ9PAVs5H1a3RwkPdz7cBWwEPAackFP8aaPEPPv0TBYtXNRosY6zYMF8Zs2csayT0bLBkg+Ul441WPLSafkYN3GNmtPLlkw+B3wkp/ib4kTnw47Audau0cgE+/9M1fRZwMQayz8ITANOcD5MBl6we102sbvxJ9lyBwKftvaSzwM/cT78x3qc1TV2fK2P7HyzZs6oezAHksGSD5SXjjVY8jJQ8lH2psXVgFqN5DcB41tMQ1ethv6c4kJgF+BF4B67C38McCswvxAI/y+n+HBOcU5O8Uwr+WiIFxGRflS2ZHIb8E67471omybuN5lp/8cDTxamTyjMW0pO8VFg5+I058PdwFQr0QA8V7XaY8DqJdMkIiJtUDaYXAtc6Xz4GXC/lWg2BnYHznQ+fKayYE7x8jrbmAq8ar25ripM38a2/zrOh12B+3KK99v7SdYofwrwiAWUd1lPror1gbtqbU9ERPpG2WByvFUtfarGvEMKr7uBmsEkpzjb+XCBDRg5zXqDHW73h5zD4mAxBZiUU9zDVtsHWMn5EIBF1j4zDbgqp7jQ+XAacJyVVv5mQ7u8XUO8iIj0r1LBJKfYrtbqQ4GTgVuAlaxEsUNOcbrNX92CS8XewA+sFNJlvcl2yCnOt/knWSnpZ9au8wCwc07x7jalV0RESujq7m58k7vz4Us5xbNqTF8BOD2neEBfJbAPtfXu/v4yUHp2NDJY8oHy0rEGS146MB9dtSaW7c11nPPh13ZvBywOJFtb1dI725ZEEREZkMq2mWwMnAnc63w4GHhrocrqxD5Oo4iIdLiybSbPAHs6H3s9k2UAABpSSURBVD4B/NTu/dgmp3hP3ydRREQ6XdlqLqxH1RnA1dYgfqHzYfO+TZ6IiAwEpYKJ8yECFwBfyyn+t42ldS3wR+fDt/o+mSIi0snKlkxWBjbPKV7C4mqvBTnFY4H3A//dt0kUEZFOV7bN5EN1pt/pfHh721MlIiIDSjPPM9kd2B9YO6e4kfNheeBLOcXT+jaJIiLS6cq2mewHnG8j91aGfh8HHOx8+GrfJlFERDpd2TaTL9kwJUvG4bKnHwZ7hoiIiAxhZYPJm4Hf2eviMCR/03DvIiJSNpg8Z89kr7Zt4bkiIiIyRJVtgL8I+IXz4SRgmPPhI/ZM94OB7/dxGkVEpMOVDSbHAa8ApwHLA9fYs9zPKPn8dxERGcTK3meyCDgBOMH5sBqwKKdY/bhcEREZokrfZ1Jhgz6KiIgsUXqgRxERkXoUTEREpGUKJiIi0rJmnmfS5XzY1vmwZ2Ha6D5LmYiIDBhlx+aaZHe732bPNcH5sA7wmPPhrX2eShER6WhlSyanAncDE4BFNu0fwIXA6X2YPhERGQDKBpNtgC9bt+BuFncR7rZ7T97Vt0kUEZFOVzaYrAK8XGP6CGB4m9MkIiIDTNlgcgdwSHGCNb6fYvNERGQIK3sH/FeAG5wPBwAjnQ93ARsA84Ad+ziNIiLS4UqVTHKKfwHWt8b2c4Dbga8B69s8EREZwpoZm2sBcGlO8XkWV3OtXfWgLBERGaJKBRPnw9uBX9vzS35ik3cHjnI+fDineHfJ7VTaWXYDVgbuA47MKd5cZ/m1bIj7D1ongLuBQ3KKd9VY9j3Ab4Fv5hSPL5MeERFpj7IN8KfbPSXXFKadBZxtzzQp6xxge2A7YBxwBXCd82GD6gWdD8OBa+2xwFsC44FbgOx8mFC17GhL30tNpEVERNqkbDDZAvh6TnFJ9+Cc4jy7z+TtZTbgfBgL7AkclVOcllOck1M8FbgfOLDGKhsCmwPH5BRn2GcfC8wG9qpa9kTgASu5iIhIPysbTOYAk2pM3xCYW3IbW1i12p1V0+8A3l1j+a7qNNqNkk8BW1WmOR+2BSYDB5RMh4iItFnZBvgrgGudD98DHrcT/cbWhnJ5yW1UqqaqH641C5hYY/kHgWn2dMfJwAvAvsAmFtxwPqxg1VuH5BT/7XwomRR49umZLFq4qMSSnWXBgvnMmjljWSejZYMlHygvHWuw5KXT8jFu4ho1p5cNJkdZe8S3gFVt2vPWZvLNFtPWVatXWE5xofNhF2uTuccCyIXArXbnPVa9NS2neGmzHzp2fK341flmzZxR92AOJIMlHygvHWuw5GWg5KPsM+DnW3vFsfYM+N48vnem/R8PPFmYPqEwr/pzHwV2Lk5zPtwNTLXqrc8AmzWZDhERabPS95k4H1YC1gNWsPdL5uUU/1BiE1OBV4GtgasK07exXlu1PnNX4L6c4v28NhT+5ta9eF/rXnxvIS2rAO90PuySU9yibN5ERKQ1Ze8zmQx8HxhVaBiv6C4z2GNOcbbz4QJgivNhGjAdOBxYx7oM43yYAkzKKe5hq+0DrOR8CDb0/bnWjnIVcD3wv1UfcxXwR+DbZXeAiIi0rmzJ5JvWdnFVE723ajkUONnuF1kJ+CuwQ05xus1f3YJLxd7AD4BHLIjdaMvPB56zvyWcD/OAF3KKNavNRESkb3R1dzceEcX58FJO8Q39kqL+MyCHghkojXGNDJZ8oLx0rMGSlw7MR3XtFDRxn8mfnA8btTc9IiIyWJSt5poC/Mj58CPg0cKje2Fxe8hv+yZ5IiIyEJQNJtn+b11jXqkGeBERGbzKBpO3AvP7OC0iIjJAlb1p8YFa050Pw2xsrS3bnjIRERkwyt5nsjxwBPAuu9ekYo3CmFsiIjJENfM8k4Otqms7u79jko2X9fE+TqOIiHS4ssHkY8A2OcVPAAtyip+0dpRpVTcZiojIEFQ2mIzJKT5mrxc6H7pyiouAw4D/68P0iYjIAFA2mEx3PnzMXv8b+IC97rIhUEREZAgr2zX4NOAXNvz8L4CfOR9uBN5W48mJIiIyxJQqmeQULwC2zik+DxwDfBcYA9xmj8wVEZEhrPTzTHKKd/Dag7LUTiIiIkvUDSbOhx/kFA+w1z/qaSM5xX36InEiIjIw9FQyWa/wesMehmwfkEO5i4hI+9QNJjnF7Quvt+23FImIyIDTsM3E+bAc8BIwOqeoUoiIiLxOw95cOcUFwO8B3z9JEhGRgaZsb657gR86Hx4HHgNeLc5UA7yIyNBWNpi8A3jEXlePxaWqLxGRIa7s80zeW2+e82GbtqZIREQGnNI3LbI4cIytep7JJOBaYGz7kyYiIgNF2YdjbQ78HFi3xuw/tj9ZIiIykJQdNfhMCxoBWAB8FDjOennt1MdpFBGRDlc2mGwOfD6n+CtgYU7x+pzit4Czge/0cRpFRKTDlQ0mi+zZJQBznQ8r2uufAZ/oo7SJiMgAUTaY3Alc4HwYBTwEHON8GGk3MqprsIjIEFc2mBxqD8LqAqbY43pfBq4GzuvjNIqISIcre5/J/cAm9vZXzoe3AlsC03OKf+rbJIqISKfrMZg4H64HzsopXlecnlN8FHi02Q9zPowGTgF2A1YG7gOOzCneXGf5tYCTgA8CqwB3A4fkFO+y+W8ETgZ2BEbb9r6WU7y12bSJiEjvNarmGmElkcecD19xPqza4uedA2wPbAeMA64ArnM+bFC9oPNhuN0QubqVgsYDtwDZ+TDBFrsaeKNVwb3RHiN8rfNhjRbTKSIiTegxmNgzTTayGxaPBJ50PvzQ+fD2Zj/I7p7fEzgqpzgtpzgnp3gqcD9wYI1VNrQuycfkFGfkFF8GjgVmA3s5Hyolm0NzijNziq9YKWVF4N3Npk9ERHqvYZtJTvER4Ajnw9eBXYEDgKnOhz/ZfSY/tefCN7KFfd6dVdPvqHPyr3RFXhLwcordzoengK1yiqcA+1at82b7P6NRYp59eiaLFi4qkezOsmDBfGbNbJi9jjdY8oHy0rEGS146LR/jJtau+Ck9NldO8VXgcuBy58NbgL2Ab9hNi6uX2ESlauqZqumzgIk1ln8QmAac4HyYDLxgwWMTYE71wlZSuRC4rkyngLHja31k55s1c0bdgzmQDJZ8oLx0rMGSl4GSj7Jdg6t1WXvKyDakoavWvSo5xYXALsCLwD32TJUxwK3AUiUh58M6wO0WmD7dhjSJiEgTSpdMnA/LWy+sA4FtgD9ZO8pVJTcx0/6PB54sTJ9QmLcU6zW2c1U67gamFt5vZQ31ETi4ZJWbiIi0UZlnwG9g7SR7WeP2lcCXc4p3N/lZU+0JjVtXBaBtLBjU+uxdgfvsPhecD5OsUf4Ue78pcAPwjZzimU2mR0RE2qTRfSY3A+8HptsJ/Ic5xWd780E5xdnOhwuAKc6HabbNw+3JjefY500BJuUU97DV9gFWcj4EGx/sXGtHucq6Dl8EnKNAIiKybDUqmSywYeevySm2YwyuQ6377i3ASsBfgR1yitNt/upVjwXeG/iBPTK4C7jRlp/vfNjWeoht6nw4oupzLskp7teG9IqISAld3d1DdpzGAZnxgdKzo5HBkg+Ul441WPLSgfnoqjWxt725REREllAwERGRlimYiIhIyxRMRESkZQomIiLSMgUTERFpmYKJiIi0TMFERERapmAiIiItUzAREZGWKZiIiEjLFExERKRlCiYiItIyBRMREWmZgomIiLRMwURERFqmYCIiIi1TMBERkZYpmIiISMsUTEREpGUKJiIi0jIFExERaZmCiYiItEzBREREWqZgIiIiLVMwERGRlimYiIhIyxRMRESkZcv154c5H0YDpwC7ASsD9wFH5hRvrrP8WsBJwAeBVYC7gUNyinf1ZnsiItI3+rtkcg6wPbAdMA64ArjO+bBB9YLOh+HAtcDqwJbAeOAWIDsfJjS7PRER6Tv9FkycD2OBPYGjcorTcopzcoqnAvcDB9ZYZUNgc+CYnOKMnOLLwLHAbGCvXmyvbbq6unr19453vKPuNt/xjneU2sb41dd83bR69t9//16nderUqTW3ed555/V6m+edd17NbU6dOrXX29x///2X+XGqdUxq/Q2E4zR+9TUHzXEqe1w6/TjVy0crx6kv9GfJZAurVruzavodwLtrLF/J8ZI05hS7gaeArXqxPRER6SP92WZSqZp6pmr6LGBijeUfBKYBJzgfJgMvAPsCmwBzerG9pTz79EwWLVzUu5z00oL585k1c0bdeb1Vb5uvvPxyr7f5/Kyna273pdnP93qbL81+fsk2Fyx4bV88P+vpXm/zlZdfrpv/3tJxer7mNnWcBs9xauVYjJu4Rs3p/doAX0cX0F09Mae40PmwC3AGcI8FkAuBW4ERzW6v2tjxDeNN2y03YkT9AzGipyz1rN42R62wQq+3OWbc+JrbfcMqY3q9zTesMmbJNmfNnLHk9Zh//bvX2xy1wgp1899bOk5jam5Tx2nwHKd2HwuAru7uhufdtnA+fBD4DbB2TvHJwvTzgbfkFLctuZ27ganA5S1ur38y3mbFk/BANljygfLSsQZLXjowHzUbXfqzzWQq8CqwddX0bYDba63gfNjV+fCWwvtJ1ih/c2+2JyIifaPfqrlyirOdDxcAU5wP04DpwOHAOtbFF+fDFGBSTnEPW20fYCXnQwAWAedaO8pVOcX5jbYnIiL9o7/vMznU7h25BXga2BHYIac43eavbsGgYm9rYH8EeBx42ZafX3J7IiLSD/qtzaQDDciMd2D9aa8MlnygvHSswZKXDszHMm8zERGRQUrBREREWqZgIiIiLRvKbSYiItImKpmIiEjLFExERKRlCiYiItIyBRMREWmZgomIiLRMwURERFqmYCIiIi3rhIdjyeIRk98InGyDVY4G7gO+llO8tc7yTwBrAgurZm2WU3yof1JdW7Npcz6MBk4BdgNWtrwfmVO8uf9S/XrOh/cBN9aYNQK4OKe4d411Oua4OB/WtQfKvR9YN6f4RGFeU/t8WR+jBnkZUL+dBnkZsL8dBZPOcTXwHPA24HngOOBa58OGOcV6z9jcL6f4435OZ1nNpO0cey7NdvYogQOB65wPm+UUH+7jdNaVU/wtMKo4zfmwBvA3oKe8LfPjYo9t+D5wQ51Fmt3ny+wYlcjLgPntlMgLA/W3o2quDuB8qFxRHJpTnJlTfMWutFYE3r2s09eXnA9jgT2Bo3KK03KKc3KKpwL32w+j05xnz9O5bVknpIGxwPuAS6pnNLvPO+AY9ZSXgfbbqZuXZnXAcVmKSiYdIKf4ArBv1eQ32/96V1YAuzkfjgLWAB4Gjs8pXtuHSW1G2bRtYd/DO6um39FpJwO7qnyn/YB7ssyPS07xAhanee0as5vd58v0GPWUl4H222lwXJpNW0f9dlQy6UB2tXUhcF1O8U91Fvsb8BCwPbA28CvgV86H6scYLwvNpG2C/X+mavosYGI/pLUU58NywEnAN3KKz/ewaCcfl4pm9/mAOEbot1OxTI6LSiYdxvmwjj098ing0/WWyynuUjXpG86HjwH7A3/s+5TW16a0dXXYA8w+AYwDftTTQp18XEpodp931DHSb2eJZXJcVDLpIM6HrayIejuwY07xxSY38Yg9+rgT1UvbTPs/vmr6hMK8TvBZ4Kc5xZd7sW6nHZdm93nHHyP9dpayTI6LSiYdwvmwqfXw+EZO8cwGy64LHAl8tarKZRPglr5PbX29SNtU4FXrkXJVYfo2dpW5zDkfVgQ+CHyqwXIde1yqNLvPO/oY6bfTGcdFwaQDOB+GAxcB59T7MTgfpgCTcop72FXHzsDKzoeD7Qv1FWADq45ZlhqmrZiXnOJs58MFwBTnwzTr3ng4sI51e+wEm1oX4XuqZwyg47JEmX0+UI6Rfjudc1wUTDrD1tYzY1PnwxFV8y7JKe5nxdx1WHwymOt82N66QD5sdaR/Az6QU3xw2WRhsZJpW5IXc6gtfwuwEvBXYIec4vRllI1qa9r/p2vM68jj4nx40NJVqcp+0PnQXfg+NdrnHXOMesqLBZIB89tpdFwG8m9HT1oUEZGWqQFeRERapmAiIiItUzAREZGWKZiIiEjLFExERKRlCiYiItIy3Wcifc758AHglpxiVwekZSPg58B6wCdyiqkN26w8ROutOcXH2rC9V4AD2/W8DbuPYb+c4g/bsT2RWhRMhgjnw632HIX35hRvr5r3Yxbf0PW5ZZbA/rMfsIoN2tibcbZep9ZDtFrcXtu2Jb3nfNgT+EM7LhCGAlVzDS2zgPOcD8sv64S0wvnQZcNo9MZqwHR7kFDLd+w6H0a0ug3pPM6HLuD0wrNRpAGVTIaWHwIfA74K/F+tBZwPbwIeB1xO8Sabtr4N77BdTvFW58PtNhz2KBtNdy7wNeBBeyTpusBfgE/nFJ8sbHt74EzgTfbMhkMqTyy0Z1l/255lvaJ93gk5xZ/b/OOBjwIZ+LLl46Ya6X8fMMUGx5sD3AYcllOc6XxIwIeBLqtK2i2neE3V+pcBL9m6k4Hh9plfyCk+W6myA/YCTgW+73z4jU3bIKf4iPPhX/Zc7o2B3W048CuBL1UCmPNhbzsOawNPAN/KKV5GVbVUo/TY8h8Fjgc2Al4BfgMcnFOsNfxLrWPeU1pWA74DfMieMf4gcGxO8deF/TXChv04xNJ3qlUl/tjGNXsYmJxT/LvzYQM79h8FvmVpng4cl1P8Ka89O+ZoewjZWsA/gPOBM3OKi5wP+9m6uwNnWZXlw7bP7iik+wzgI3bRXHku/G2FdC8H/A44ClgV+L19n+cAzwLLA8n5cENOcRfnw6fse74uMB+41Y5pTw/hGjJUMhlaXrVqnqOdD29pYTvz7Uf3O7vS/54FiUPsWdRr24nnK1XrHWwn8wm27nXOh3E27zTgHfaEuFXtZHGl82HbwvqVMY1WBW6uTpQFvd8Av7Cn1L3DhufOzoeunKK38Zz+kFMcVR1ICnn7VGHY763s2eI/qFpuZxuA77g62/gKcJ19/ieBLwKe1wLeucCXbDylI4GLbHpT6XE+TLT8XgmMAf4LeKsFgIZKpOXndvJ8jz1w6WLgeufDuwrp+4BdUKxhgf4bdjw/afn/D/DNwvLY53zcjuUFwBXOh/+yeccAX7Dv2Kq2746zQQwr2xhjj6bdzr6D/wHOLmTtUsvPxsAbgcuAG50Pby5sYztL34a23NuAI3KKcyzIAXgLJGvaNo+y7/YGdpFQaj8PBSqZDDE5xT84Hy4Eznc+vLeFqp5Hcoo/YfEJ6Rd2sji7cjXsfPi1ndiKTqiUVJwPx9kJ7MPOh19ZkPtwTvEJW/YXNn1/u2LEnp99Qk7x1TppOhB41J6DDfCy8+HrwJ+BLWs83rSef+QUK6OuPup8OAc42a6YKy6qDBPufKi1jT8UgtVNzodnrbR0nQXVG3KKN9r8a5wPn7CHOjWVHitxTQBezCkuBGY6H24Aqh+yVE/dtNjQ7u8Hts4p/tPmn+18OMhO9H+2afOB03KK3c6Hn1vA+WnlWDofrrbPKTqzMhih8+F0K4l8DPi7fS++UyllALc6Hy4HPmclPqzU8M2c4izbxjU24CF2obQjsH5OsbJPz3E+7GvbONamLQT+L6e4CHjSStyb1NlP463UNdd+M884H3ZtR1XpYKFgMjQdDdxvJ99ze7mNJwqvKw3Z06umja5a5/7Ki5zic86H54FJVk0x3KoUij/OYVVPl3vGnvldz/rFzzCV0VbXayKY3Ff1/nFgZOExqQCNGmUfqXo/F1jBXm9QXbLKKV7dy/TMAD4P7ON8mGS/6eWAJ+tsq1rdtDgfPm6Tau3T9Qrvp1dOqjnFly24NvouTCt83kLnwz+ASc6HVaykUesz96maVtzHcwufUSlV3FcV6IcB9xbeP26BpLiN1aghp/hXC3o3OR/utSrWqwoBdchTMBmCcoovOB++BPzYrv4bqVUduqjktKKFVe+7rI6/st7WOcW/9LB+vRJJ9TaLKmlv5gqyOr+Vbc5tIi2N9kUz3aTrpsf5sIc9m34y8POc4qvOhxOBzzSx/UZpqbVPi/uzN9+FWnmaW/W+p8/s6TMq09eotCs1WK6UnOJhzodTrKp2R+C3zoeTc4rHllh90FObyRCVU4x2RXpW1azKD7rY42tSmz52STuNNZCOscbVxyzQvL24sPNhUlXVUiMPWntBrc98qIntbFz1fj2rRnquiW305OHqz3A+TK7TZtIoPVsD9+QUryhU/23RprRUSnXVVT8bN7k/a1nymXaM17ESzmyr7qv+zLc08ZmV5aq/T+taL62mOR+GOR/G5hT/nVP8cU7xU1Y1++XebG8wUslkaDvIqhNeLPSMegp4BtjJqp1WtOXa4etWIpptjbTPWX39HOfDD4FjnA9/sZ5B7wGiffaVJbf/feBQ58NXrDF2NeBE4I6c4t1NpHM9S+cF1pvoi8DlvcxzLedYY3AArrGG4B/a1W6z6ZkO7Gm98J4Cvm5BeqzzYUVrTO5VWnKK9zsfbgJOdD58xo7XF6y77I9a3AeHOx/+ZtVxh1ljeeXRs98FDnI+3GgPe9oO+LQ1fjeUU3zA2uxOcT7sbtWCu9g++2BV1Wk9lf22sfNhqvUK+7ZV/d1pVZbvtGAsKpkMbdal8ejCkwSxuu99gZ2cD09Y76jv2ezeXnyMsBLP+VYaetp6bX20cLI7zBqnb7Af8vnWBbVsICGn+Lg14n7aunb+EXi00ouqCb+wtoR/An+yevEjm9xGT+m8xU7K37ZAfpZ1a633DPKe0nOudUu+10oSzwN72P9Hrct1K2mZbI+Tvc/aZz5uXcRf9wjjJn3Pgsezlt5PFBr5T7ZG/KvtwuNU697dzKNoJ1u7zB2Wr+OBz+YUywQSrCPJZdbgf7W9PtsC0hxrM1zTeqyJnrQosrROGw2g09LTqsJ9TOsWeu7JIKCSiYiItEzBREREWqZqLhERaZlKJiIi0jIFExERaZmCiYiItEzBREREWqZgIiIiLft/iUd4bJNRZ+IAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "bento_obj_id": "140135023335984",
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "U, S, V = torch.svd(Y - torch.mean(Y, axis = 0))\n",
        "\n",
        "plt.plot(list(range(1, 16)), torch.cumsum(torch.square(S) / torch.sum(torch.square(S)), dim=0))\n",
        "plt.hlines(0.9, 1, 16, linestyles = '--')\n",
        "plt.xlabel('Number of principal components')\n",
        "plt.ylabel('Variance explained')\n",
        "plt.title('PCA explained variance')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "11a1d798-349f-4741-954a-bd8e98cf91ee",
        "showInput": false
      },
      "source": [
        "# Fit outcome model using different methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038678424,
        "executionStopTime": 1673038679200,
        "originalKey": "d350750b-f458-4bd2-b9f3-04d202adbd89",
        "requestMsgId": "26c8d1c0-d3a8-4e41-90ce-3eaaf4be2c81",
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_axes = 2, explains 0.9998339199495703 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7516796588897705 seconds\n"
          ]
        }
      ],
      "source": [
        "pca_transform = PCAOutcomeTransform(variance_explained_threshold = 0.999)\n",
        "\n",
        "pca_model = SingleTaskGP(\n",
        "    X,\n",
        "    Y,\n",
        "    likelihood=GaussianLikelihood(\n",
        "        noise_prior=GammaPrior(3, 6)\n",
        "    ),  # TODO: GammaPrior(3,6) could be better for Ax experiments, QIng has a note\n",
        "    input_transform=Normalize(3),\n",
        "    outcome_transform=ChainedOutcomeTransform(\n",
        "        **{\"standardize\": Standardize(Y.shape[-1], min_stdv = 100000), \"pca\": pca_transform}\n",
        "    ),\n",
        ")\n",
        "\n",
        "# NOTE\n",
        "# relativize -- sq also has variance, brings further noise into GP modeling\n",
        "# absolute values -- just dealing with the observed standard errors of the arms\n",
        "\n",
        "start = time.time()\n",
        "pca_model_mll = ExactMarginalLogLikelihood(pca_model.likelihood, pca_model)\n",
        "fit_gpytorch_scipy(pca_model_mll)\n",
        "print(f\"{time.time() - start} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038691439,
        "executionStopTime": 1673038701237,
        "originalKey": "b4a2b3f2-5b92-41d4-ac58-9c1b64857cd6",
        "requestMsgId": "485daaa6-88cf-43ab-bb9b-1ce31c177459",
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.725991487503052 seconds\n"
          ]
        }
      ],
      "source": [
        "st_model = SingleTaskGP(\n",
        "    X,\n",
        "    Y,\n",
        "    likelihood=GaussianLikelihood(noise_prior=GammaPrior(3, 6)), # TODO: GammaPrior(3,6) could be better for Ax experiments, QIng has a note\n",
        "    input_transform=Normalize(3),\n",
        "    outcome_transform=Standardize(Y.shape[-1], min_stdv = 100000),\n",
        ")\n",
        "\n",
        "# NOTE\n",
        "# relativize -- sq also has variance, brings further noise into GP modeling\n",
        "# absolute values -- just dealing with the observed standard errors of the arms\n",
        "\n",
        "start = time.time()\n",
        "st_model_mll = ExactMarginalLogLikelihood(st_model.likelihood, st_model)\n",
        "fit_gpytorch_scipy(st_model_mll)\n",
        "print(f\"{time.time() - start} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "customInput": null,
        "originalKey": "8d1455f0-39b1-482d-92c7-9eec4ff85a81",
        "showInput": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1671575273772,
        "executionStopTime": 1671575276665,
        "originalKey": "c1e810c5-a9c4-4868-80a9-4ed2f8a54e05",
        "requestMsgId": "c1e810c5-a9c4-4868-80a9-4ed2f8a54e05",
        "showInput": true
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-6b5d2ddcc052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0micm_model_mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExactMarginalLogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0micm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0micm_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfit_gpytorch_scipy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0micm_model_mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{time.time() - start} seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/botorch/optim/fit.py\u001b[0m in \u001b[0;36mfit_gpytorch_scipy\u001b[0;34m(mll, bounds, method, options, track_iterations, approx_mll, scipy_objective, module_to_array_func, module_from_array_func, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m         )\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     result = minimize(\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                   **options)\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/botorch/optim/fit.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfast_computations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapprox_mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mscipy_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproperty_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/botorch/optim/numpy_converter.py\u001b[0m in \u001b[0;36m_scipy_objective_and_grad\u001b[0;34m(x, mll, property_dict)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mmll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# catch linear algebra errors in gpytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_get_extra_mll_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/gpytorch/models/exact_gp.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You must train on the training inputs!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/botorch/models/multitask.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mmean_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0mcovar_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovar_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMultitaskMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovar_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/gpytorch/means/mean.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/mnt/xarfuse/uid-558512/45f3ae7b-seed-nspid4026531836_cgpid71974536-ns-4026531840/gpytorch/means/multitask_mean.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mEvaluate\u001b[0m \u001b[0meach\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_means\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0man\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mn\u001b[0m \u001b[0mx\u001b[0m \u001b[0mt\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \"\"\"\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msub_mean\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_means\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# MTGP with ICM kernel\n",
        "# took more than 12 minutes\n",
        "from botorch.models.multitask import KroneckerMultiTaskGP\n",
        "\n",
        "icm_model = KroneckerMultiTaskGP(\n",
        "    X,\n",
        "    Y,\n",
        "    outcome_transform=Standardize(Y.shape[-1], min_stdv = 1),\n",
        "    rank=1,\n",
        ")\n",
        "icm_mll = ExactMarginalLogLikelihood(icm_model.likelihood, icm_model)\n",
        "\n",
        "start = time.time()\n",
        "icm_model_mll = ExactMarginalLogLikelihood(icm_model.likelihood, icm_model)\n",
        "fit_gpytorch_scipy(icm_model_mll)\n",
        "print(f\"{time.time() - start} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1668098139063,
        "executionStopTime": 1668098254606,
        "originalKey": "f06ef21d-ef18-4f08-a586-913e2836f745",
        "requestMsgId": "f06ef21d-ef18-4f08-a586-913e2836f745",
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "115.4352285861969 seconds\n"
          ]
        }
      ],
      "source": [
        "# MTGP with LMC kernel\n",
        "from gpytorch.models import ExactGP\n",
        "from torch import Tensor\n",
        "from gpytorch.kernels import Kernel, LCMKernel, MaternKernel\n",
        "import gpytorch\n",
        "\n",
        "class MultitaskGPModel(GPyTorchModel, ExactGP):\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_X: Tensor,\n",
        "        train_Y: Tensor,\n",
        "        likelihood: Likelihood,\n",
        "        num_tasks: int,\n",
        "        multitask_kernel: Kernel,\n",
        "        outcome_transform: OutcomeTransform = None,\n",
        "        input_transform: InputTransform = None,\n",
        "    ):\n",
        "\n",
        "        r\"\"\"\n",
        "        Initialize model class for multi-output GP models.\n",
        "\n",
        "        Args:\n",
        "            train_X: `num_samples x input_dim` tensor\n",
        "            train_Y: `num_samples x outcome_dim` tensor\n",
        "            likelihood: Gpytorch likelihood\n",
        "            num_tasks: number of outcomes\n",
        "            multitask_kernel: a multi-output kernel\n",
        "            outcome_transform: OutcomeTransform\n",
        "            input_transform: InputTransform\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        with torch.no_grad():\n",
        "            transformed_X = self.transform_inputs(\n",
        "                X=train_X, input_transform=input_transform\n",
        "            )\n",
        "        if outcome_transform is not None:\n",
        "            train_Y, _ = outcome_transform(train_Y)\n",
        "        self._validate_tensor_args(X=transformed_X, Y=train_Y)\n",
        "        self._num_outputs = num_tasks\n",
        "\n",
        "        super().__init__(\n",
        "            train_inputs=train_X, train_targets=train_Y, likelihood=likelihood\n",
        "        )\n",
        "\n",
        "        self.mean_module = gpytorch.means.MultitaskMean(\n",
        "            gpytorch.means.ConstantMean(), num_tasks=num_tasks\n",
        "        )\n",
        "        self.covar_module = multitask_kernel\n",
        "\n",
        "    def forward(self, x: Tensor):\n",
        "        r\"\"\"\n",
        "        Return posterior distribution at new point x\n",
        "        \"\"\"\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "\n",
        "def fit_LCM_model(\n",
        "    train_X: Tensor,\n",
        "    train_Y: Tensor,\n",
        "    num_tasks: int,\n",
        "    num_basis_kernels: int,\n",
        "    rank: int = 1,\n",
        "):\n",
        "    r\"\"\"\n",
        "    Fit LCM model with specified number of basis kernels and rank.\n",
        "    Args:\n",
        "        train_X: `num_samples x input_dim` tensor\n",
        "        train_Y: `num_samples x outcome_dim` tensor\n",
        "        num_tasks: number of outcomes\n",
        "        num_basis_kernels: number of basis kernels in LCM kernel\n",
        "        rank: rank of basis kernels, default to 1\n",
        "    Returns:\n",
        "        fitted model\n",
        "    \"\"\"\n",
        "    lcm_kernel = LCMKernel(\n",
        "        base_kernels=[MaternKernel()] * num_basis_kernels, num_tasks=num_tasks, rank=1\n",
        "    )\n",
        "    likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=num_tasks)\n",
        "    lcm_model = MultitaskGPModel(\n",
        "        train_X, train_Y, likelihood, num_tasks=num_tasks, multitask_kernel=lcm_kernel\n",
        "    )\n",
        "\n",
        "    mll_lcm = ExactMarginalLogLikelihood(lcm_model.likelihood, lcm_model)\n",
        "    fit_gpytorch_model(mll_lcm)\n",
        "\n",
        "    return lcm_model\n",
        "\n",
        "\n",
        "lcm_kernel = LCMKernel(\n",
        "    base_kernels=[MaternKernel()],\n",
        "    num_tasks=Y.shape[-1],\n",
        "    rank=1,\n",
        ")\n",
        "lcm_likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(\n",
        "    num_tasks=Y.shape[-1]\n",
        ")\n",
        "lcm_model = MultitaskGPModel(\n",
        "    X,\n",
        "    Y,\n",
        "    lcm_likelihood,\n",
        "    num_tasks=Y.shape[-1],\n",
        "    multitask_kernel=lcm_kernel,\n",
        "    outcome_transform=Standardize(Y.shape[-1], min_stdv=1),\n",
        ")\n",
        "lcm_model.to(torch.double)\n",
        "lcm_mll = ExactMarginalLogLikelihood(lcm_model.likelihood, lcm_model)\n",
        "\n",
        "start = time.time()\n",
        "lcm_model_mll = ExactMarginalLogLikelihood(lcm_model.likelihood, lcm_model)\n",
        "fit_gpytorch_scipy(lcm_model_mll)\n",
        "print(f\"{time.time() - start} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "collapsed": true,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1668098376515,
        "executionStopTime": 1668098376555,
        "originalKey": "bfe74e7e-da24-444e-8aa7-df3273294f89",
        "requestMsgId": "bfe74e7e-da24-444e-8aa7-df3273294f89",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('likelihood.raw_task_noises',\n",
              "              tensor([-15.1214, -14.3346, -16.5043, -16.4910,  -4.9332,  -3.2826,  -3.7722,\n",
              "                      -18.6045, -19.7381, -18.4397, -14.9829, -15.8647, -15.1115, -15.0365,\n",
              "                      -14.2762], dtype=torch.float64)),\n",
              "             ('likelihood.raw_noise', tensor([-36.9617], dtype=torch.float64)),\n",
              "             ('likelihood.raw_task_noises_constraint.lower_bound',\n",
              "              tensor(1.0000e-04, dtype=torch.float64)),\n",
              "             ('likelihood.raw_task_noises_constraint.upper_bound',\n",
              "              tensor(inf, dtype=torch.float64)),\n",
              "             ('likelihood.raw_noise_constraint.lower_bound',\n",
              "              tensor(1.0000e-04, dtype=torch.float64)),\n",
              "             ('likelihood.raw_noise_constraint.upper_bound',\n",
              "              tensor(inf, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.0.raw_constant',\n",
              "              tensor(1.0977e-06, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.1.raw_constant',\n",
              "              tensor(-2.4848e-05, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.2.raw_constant',\n",
              "              tensor(-3.5774e-05, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.3.raw_constant',\n",
              "              tensor(-2.3262e-08, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.4.raw_constant',\n",
              "              tensor(-0.0674, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.5.raw_constant',\n",
              "              tensor(0.2129, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.6.raw_constant',\n",
              "              tensor(-0.0291, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.7.raw_constant',\n",
              "              tensor(-0.0003, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.8.raw_constant',\n",
              "              tensor(-0.0034, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.9.raw_constant',\n",
              "              tensor(-5.2432e-06, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.10.raw_constant',\n",
              "              tensor(1.6059e-06, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.11.raw_constant',\n",
              "              tensor(2.1565e-06, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.12.raw_constant',\n",
              "              tensor(4.5534e-05, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.13.raw_constant',\n",
              "              tensor(8.4699e-06, dtype=torch.float64)),\n",
              "             ('mean_module.base_means.14.raw_constant',\n",
              "              tensor(-0.0035, dtype=torch.float64)),\n",
              "             ('covar_module.covar_module_list.0.task_covar_module.covar_factor',\n",
              "              tensor([[-7.9577e-06],\n",
              "                      [ 6.6578e-06],\n",
              "                      [ 6.4910e-04],\n",
              "                      [ 1.5269e-05],\n",
              "                      [ 1.1793e+00],\n",
              "                      [-1.2146e+00],\n",
              "                      [ 4.7161e-01],\n",
              "                      [ 5.6338e-03],\n",
              "                      [ 1.7571e-03],\n",
              "                      [ 1.1386e-05],\n",
              "                      [-2.2901e-05],\n",
              "                      [-8.7948e-06],\n",
              "                      [-7.9133e-04],\n",
              "                      [-1.2524e-04],\n",
              "                      [ 1.8534e-02]], dtype=torch.float64)),\n",
              "             ('covar_module.covar_module_list.0.task_covar_module.raw_var',\n",
              "              tensor([-14.9795, -13.6438, -14.9939, -14.9983,  -7.6090,  -1.4113,  -7.1525,\n",
              "                      -14.8298,  -8.5573, -15.0391, -15.0010, -14.9749, -15.2493, -15.0405,\n",
              "                       -9.0540], dtype=torch.float64)),\n",
              "             ('covar_module.covar_module_list.0.task_covar_module.raw_var_constraint.lower_bound',\n",
              "              tensor(0., dtype=torch.float64)),\n",
              "             ('covar_module.covar_module_list.0.task_covar_module.raw_var_constraint.upper_bound',\n",
              "              tensor(inf, dtype=torch.float64)),\n",
              "             ('covar_module.covar_module_list.0.data_covar_module.raw_lengthscale',\n",
              "              tensor([[18.6654]], dtype=torch.float64)),\n",
              "             ('covar_module.covar_module_list.0.data_covar_module.raw_lengthscale_constraint.lower_bound',\n",
              "              tensor(0., dtype=torch.float64)),\n",
              "             ('covar_module.covar_module_list.0.data_covar_module.raw_lengthscale_constraint.upper_bound',\n",
              "              tensor(inf, dtype=torch.float64))])"
            ]
          },
          "execution_count": 88,
          "metadata": {
            "bento_obj_id": "140464765834944"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lcm_model.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "customInput": null,
        "originalKey": "3511e3f7-55e7-474b-903e-da11f26e6cca",
        "showInput": false
      },
      "source": [
        "# TODO: evaluate model fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1668096272444,
        "executionStopTime": 1668096272454,
        "originalKey": "34b481ce-ebde-40b4-a336-438b9f08e5f1",
        "requestMsgId": "34b481ce-ebde-40b4-a336-438b9f08e5f1",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# now check model fit, compute LOOCV\n",
        "# have a loop, vary the number of principal axes kept, and compute LOOCV for each\n",
        "# what is the relationship between explaining variance in the metrics vs having good model fit?\n",
        "# this is what the plot is trying to get at"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038746132,
        "executionStopTime": 1673038746141,
        "originalKey": "725e1f40-1d69-4e19-999b-05240e87397b",
        "requestMsgId": "a7bfaa9a-fc6c-45fc-baa8-9efd588265f5",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# loocv() function that takes model_class and input / output transforms as arguments\n",
        "\n",
        "\n",
        "def loocv_new(\n",
        "    X_all: torch.Tensor,\n",
        "    Y_all: torch.Tensor,\n",
        "    model_cls,  # TODO: add type = Model\n",
        "    infer_noise: bool = True,\n",
        "    Y_var_all: torch.Tensor or float = None,\n",
        "    input_transform=None,  # TODO: add type\n",
        "    outcome_transform=None,\n",
        "    likelihood=None,\n",
        "    **tkwargs\n",
        "):\n",
        "\n",
        "    print(\"Full input data shape {}, output data shape {}\".format(X_all.shape, Y_all.shape))\n",
        "\n",
        "    predicted_Y_means = torch.Tensor()\n",
        "    predicted_Y_vars = torch.Tensor()\n",
        "\n",
        "    explained_var = []\n",
        "    num_axes = []\n",
        "\n",
        "    for i in range(X_all.shape[0]):\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            print(\"loocv round {}\".format(i))\n",
        "\n",
        "        X_train = torch.cat((X_all[:i], X_all[i + 1 :])).detach()\n",
        "        Y_train = torch.cat((Y_all[:i], Y_all[i + 1 :])).detach()\n",
        "\n",
        "        if Y_var_all is not None:\n",
        "            if torch.is_tensor(Y_var_all):\n",
        "                Y_var_train = torch.cat((Y_var_all[:i], Y_var_all[i + 1 :]))\n",
        "            else:\n",
        "                Y_var_train = Y_var_all\n",
        "        else:\n",
        "            Y_var_train = None\n",
        "\n",
        "        X_test = X_all[i].unsqueeze(0)\n",
        "        print(X_train.shape, Y_train.shape, X_test.shape)\n",
        "\n",
        "                                        # TODO: PCA outcome transform only takes place once; self.training becomes False after first round. How to fix that?\n",
        "\n",
        "        model = model_cls(\n",
        "            X_train,\n",
        "            Y_train,\n",
        "                                                                                                                        # Yvar?\n",
        "            likelihood=likelihood,\n",
        "            input_transform=copy.deepcopy(input_transform),\n",
        "            outcome_transform=copy.deepcopy(outcome_transform),\n",
        "        )\n",
        "\n",
        "        if 'pca' in model.outcome_transform:\n",
        "\n",
        "            explained_var.append(model.outcome_transform[\"pca\"].PCA_explained_variance)\n",
        "            num_axes.append(model.outcome_transform[\"pca\"].num_axes)\n",
        "\n",
        "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "        fit_gpytorch_model(mll)\n",
        "\n",
        "        # print(\"model.posterior.event_shape\", model.posterior(X_test).event_shape)\n",
        "\n",
        "        Y_posterior_mean = model.posterior(X_test).mean\n",
        "        Y_posterior_variance = model.posterior(X_test).variance\n",
        "\n",
        "        # weird -- X_test is 1x3, posterior event shape is 1x15, but posterior mean shape is num_axes x 1 x 15\n",
        "\n",
        "        # print(\"Y_posterior_mean.shape\", Y_posterior_mean.shape)\n",
        "        # print(\"predicted_Y_means.shape\", predicted_Y_means.shape)\n",
        "\n",
        "        # use loo-fitted model to compute the posterior mean on held-out datapoint\n",
        "        predicted_Y_means = torch.cat((predicted_Y_means, Y_posterior_mean))\n",
        "        predicted_Y_vars = torch.cat((predicted_Y_vars, Y_posterior_variance))\n",
        "\n",
        "        # print(\"predicted_Y_means.shape afer torch.cat() new\", predicted_Y_means.shape)\n",
        "\n",
        "        # print(explained_var)\n",
        "        del model\n",
        "\n",
        "    # mean_explained_var = np.mean(explained_var)\n",
        "\n",
        "    # print(\"predicted_Y_means.shape\", predicted_Y_means.shape)\n",
        "\n",
        "    return predicted_Y_means, predicted_Y_vars, explained_var, num_axes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "collapsed": true,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673038755517,
        "executionStopTime": 1673038766330,
        "originalKey": "dbbc1969-acfc-4bda-86af-3a9c8028faae",
        "requestMsgId": "a453a926-b806-4f7c-9597-66c2777010eb",
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9907098129257047 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9911037806218304 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9912566040091274 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9911178106431776 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9914076328398865 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9901297655703366 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9899620194288086 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9931468524345713 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9909480904195321 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9931076243098138 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9912187408800959 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9916933165297313 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9903404175281139 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9907535870479977 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9912089584611258 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9901633394825647 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9913131715894591 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9910805801516805 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9912337133275989 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9914993003578246 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9913639137284819 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9911928771790817 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9905008629478707 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9911210371162095 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9899151564619358 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9906791652345659 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9914213521419656 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9912680225135205 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9911449219515085 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9911169228937485 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 1, explains 0.9911933187268865 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([1, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n"
          ]
        }
      ],
      "source": [
        "loocv_outcome_mean, loocv_outcome_variance, explained_var, num_axes = loocv_new(\n",
        "    X,\n",
        "    Y,\n",
        "    SingleTaskGP,\n",
        "    input_transform=InputStandardize(3),\n",
        "    outcome_transform=ChainedOutcomeTransform(\n",
        "        **{\"standardize\": Standardize(Y.shape[-1], min_stdv=100000), \"pca\": PCAOutcomeTransform()}\n",
        "    ),\n",
        "    # likelihood=GaussianLikelihood(noise_prior=GammaPrior(0.9, 10)),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "executionStartTime": 1673040932190,
        "executionStopTime": 1673040932288,
        "originalKey": "bba967d1-cc79-425f-b7d3-b0ca6c1cdb0d",
        "requestMsgId": "ab76980a-d1cd-47d2-9a7b-4a5675702553",
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([6.5022e-10, 1.1728e-04, 7.2367e-06, 7.8902e-07, 6.8729e+00, 1.5691e+00,\n",
            "        3.4260e-02, 2.1566e-05, 4.2109e-04, 8.8598e-10, 1.9673e-09, 4.7682e-09,\n",
            "        1.5507e-06, 2.4094e-06, 2.4444e-04], dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# PCA\n",
        "mse_pca = torch.mean(torch.square(loocv_outcome_mean - Y), dim = 0)\n",
        "print(mse_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "executionStartTime": 1673040933466,
        "executionStopTime": 1673040933475,
        "originalKey": "9eb10b79-4d27-464f-b742-9d47bbb298cc",
        "requestMsgId": "7182ecf3-7f96-472f-a0ef-21c2362183ca",
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([6.6854e-10, 8.9802e-05, 7.2111e-06, 7.3455e-07, 3.1503e+01, 2.7789e+00,\n",
            "        7.9485e-02, 3.5101e-05, 3.4196e-04, 8.3741e-10, 2.0275e-09, 4.2656e-09,\n",
            "        1.7585e-06, 2.2265e-06, 6.8536e-05], dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# Indep\n",
        "mse_indep = torch.mean(torch.square(loocv_outcome_mean_st - Y), dim = 0)\n",
        "print(mse_indep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "executionStartTime": 1673040934199,
        "executionStopTime": 1673040934260,
        "originalKey": "6e26ab7c-9c14-4c17-a344-3ac9df2f94dd",
        "requestMsgId": "b704cdce-ce5d-4cf8-9be4-b2c5dda9ab9d",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ True, False, False, False,  True,  True,  True,  True, False, False,\n",
              "         True, False,  True, False, False])"
            ]
          },
          "execution_count": 99,
          "metadata": {
            "bento_obj_id": "140134946556160"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mean(torch.square(loocv_outcome_mean - Y), dim = 0) < torch.mean(torch.square(loocv_outcome_mean_st - Y), dim = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "executionStartTime": 1673040934354,
        "executionStopTime": 1673040934452,
        "originalKey": "8b8604f1-4c90-4264-9805-2bef25092b52",
        "requestMsgId": "4614b167-8956-4b50-a7c8-6973b015153a",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.9726, 1.3060, 1.0035, 1.0741, 0.2182, 0.5647, 0.4310, 0.6144, 1.2314,\n",
              "        1.0580, 0.9703, 1.1178, 0.8818, 1.0821, 3.5665], dtype=torch.float64,\n",
              "       grad_fn=<DivBackward0>)"
            ]
          },
          "execution_count": 100,
          "metadata": {
            "bento_obj_id": "140134969572224"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mse_pca / mse_indep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1673024370092,
        "executionStopTime": 1673024370185,
        "originalKey": "f639edef-80f8-4475-8e02-ae66ffabe696",
        "requestMsgId": "f639edef-80f8-4475-8e02-ae66ffabe696",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.477056341416837"
            ]
          },
          "execution_count": 50,
          "metadata": {
            "bento_obj_id": "140135483221104"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(torch.mean(torch.square(loocv_outcome_mean - Y), dim = 0)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "executionStartTime": 1673024402938,
        "executionStopTime": 1673024403735,
        "originalKey": "aee61338-8829-4778-8ad1-f0e95b5a5516",
        "requestMsgId": "aee61338-8829-4778-8ad1-f0e95b5a5516",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7517560039186845"
            ]
          },
          "execution_count": 52,
          "metadata": {
            "bento_obj_id": "140136814310960"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(torch.sqrt(torch.mean(torch.square(loocv_outcome_mean - Y))), dim = 0).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "customInput": null,
        "originalKey": "e428e5cc-aa87-41ea-8334-17f09258979f",
        "showInput": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "customInput": null,
        "executionStartTime": 1671597001342,
        "executionStopTime": 1671597001357,
        "originalKey": "345ae4b9-8315-41a8-baa0-3bd783d21384",
        "requestMsgId": "345ae4b9-8315-41a8-baa0-3bd783d21384",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.9158499456282487,\n",
              " 0.91315337953457,\n",
              " 0.9182127620450766,\n",
              " 0.9169798904496302,\n",
              " 0.9179392604460208,\n",
              " 0.9146492232424648,\n",
              " 0.9187640582040272,\n",
              " 0.9157203868902666,\n",
              " 0.9187682674017915,\n",
              " 0.920712547592058,\n",
              " 0.9243828771345184,\n",
              " 0.9154005814896449,\n",
              " 0.9133714025426254,\n",
              " 0.92193309097677,\n",
              " 0.9166385530771779,\n",
              " 0.9150014384713844,\n",
              " 0.9109195859990044,\n",
              " 0.9243410555611314,\n",
              " 0.9152023918650345,\n",
              " 0.9200581722030551,\n",
              " 0.9151951095175082,\n",
              " 0.9145898960425456,\n",
              " 0.9204339265915606,\n",
              " 0.919995953130135,\n",
              " 0.9138342606454363,\n",
              " 0.9180942368520791,\n",
              " 0.9192153728911955,\n",
              " 0.9184799688071913,\n",
              " 0.9180049825415025,\n",
              " 0.9166000471655898,\n",
              " 0.9170595873646257]"
            ]
          },
          "execution_count": 42,
          "metadata": {
            "bento_obj_id": "140137274227968"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explained_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "collapsed": true,
        "customInput": null,
        "executionStartTime": 1673019247951,
        "executionStopTime": 1673019248052,
        "originalKey": "96a968ff-d50f-4e8b-9226-bb1cbc600fca",
        "requestMsgId": "96a968ff-d50f-4e8b-9226-bb1cbc600fca",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1]"
            ]
          },
          "execution_count": 46,
          "metadata": {
            "bento_obj_id": "140135385084416"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_axes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "executionStartTime": 1673038788212,
        "executionStopTime": 1673040845110,
        "originalKey": "634c9ecc-7579-4cbd-9c19-4a46ed8c617f",
        "requestMsgId": "7c679f46-2a85-4441-b3e6-c621bb87d91b",
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n"
          ]
        }
      ],
      "source": [
        "loocv_outcome_mean_st, loocv_outcome_variance_st, mean_explained_var_st, _ = loocv_new(\n",
        "    X,\n",
        "    Y,\n",
        "    SingleTaskGP,\n",
        "    input_transform=InputStandardize(3),\n",
        "    outcome_transform=ChainedOutcomeTransform(\n",
        "        **{\"standardize\": Standardize(Y.shape[-1], min_stdv = 100000)}\n",
        "    ),\n",
        "    # likelihood=GaussianLikelihood(noise_prior=GammaPrior(0.9, 10)),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "executionStartTime": 1673040880569,
        "executionStopTime": 1673040880600,
        "originalKey": "8de6ee91-0b66-4b9b-a7a5-17ab31bbcfc0",
        "requestMsgId": "3b87619a-ebb1-4885-ad67-e5510aadbb74",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([6.6854e-10, 8.9802e-05, 7.2111e-06, 7.3455e-07, 3.1503e+01, 2.7789e+00,\n",
              "        7.9485e-02, 3.5101e-05, 3.4196e-04, 8.3741e-10, 2.0275e-09, 4.2656e-09,\n",
              "        1.7585e-06, 2.2265e-06, 6.8536e-05], dtype=torch.float64,\n",
              "       grad_fn=<MeanBackward1>)"
            ]
          },
          "execution_count": 92,
          "metadata": {
            "bento_obj_id": "140134992944480"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mean(torch.square(loocv_outcome_mean_st - Y), dim = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "executionStartTime": 1673024338371,
        "executionStopTime": 1673024338470,
        "originalKey": "878c23b0-da5d-48f5-96a9-cd7e86e17ab8",
        "requestMsgId": "878c23b0-da5d-48f5-96a9-cd7e86e17ab8",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "34.361849040600816"
            ]
          },
          "execution_count": 49,
          "metadata": {
            "bento_obj_id": "140135445507824"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(torch.mean(torch.square(loocv_outcome_mean_st - Y), dim = 0)).item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "executionStartTime": 1673024411387,
        "executionStopTime": 1673024411520,
        "originalKey": "c2af3a9e-96cd-4d5d-a7fb-28d334f650aa",
        "requestMsgId": "c2af3a9e-96cd-4d5d-a7fb-28d334f650aa",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.513535574752062"
            ]
          },
          "execution_count": 53,
          "metadata": {
            "bento_obj_id": "140136814616016"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(torch.sqrt(torch.mean(torch.square(loocv_outcome_mean_st - Y))), dim = 0).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "executionStartTime": 1671598509470,
        "executionStopTime": 1671598509563,
        "originalKey": "1219cda0-ecb4-4ee5-91cf-462f4ff2e3f9",
        "requestMsgId": "1219cda0-ecb4-4ee5-91cf-462f4ff2e3f9",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.4298, dtype=torch.float64, grad_fn=<MeanBackward0>)"
            ]
          },
          "execution_count": 54,
          "metadata": {
            "bento_obj_id": "140136682899232"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mean(torch.square(loocv_outcome_mean_st - Y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "executionStartTime": 1671598244085,
        "executionStopTime": 1671598244092,
        "originalKey": "e16df856-c573-4477-a3e1-789cf39db194",
        "requestMsgId": "e16df856-c573-4477-a3e1-789cf39db194",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.42977626486503195"
            ]
          },
          "execution_count": 51,
          "metadata": {
            "bento_obj_id": "140137203000560"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mean(torch.square(loocv_outcome_mean_st - Y)).item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "customInput": null,
        "customOutput": null,
        "originalKey": "5039ab11-b199-40ed-89d2-161f32c1bfe8",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# also otuput var explained for different number of axes kept?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "collapsed": true,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1671597918360,
        "executionStopTime": 1671598156989,
        "originalKey": "17be810e-335f-4ed0-a558-58c61e74d2be",
        "requestMsgId": "17be810e-335f-4ed0-a558-58c61e74d2be",
        "showInput": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA transform with 2 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6223068848578779 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6191985867588905 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6256941757053145 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6293256527324057 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6292648228688607 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6257260328152745 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6248822665899069 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6268885900055903 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6290390038806343 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.634757209202826 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6330703139095091 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6262559716725699 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6224282458472185 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.635111910286942 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6299949856008984 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6386558438433277 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.601678686237831 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6379045137998502 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6240095208194538 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6345245846676479 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.628422995650979 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6208296880595892 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6432764577200026 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6346283635866894 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6195144243574353 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6238318953013595 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6436773422824966 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6330520837023146 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6298943363681875 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.629360956772073 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 2, explains 0.6373337635869889 variance\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([2, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(3.1610, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 3 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7424928548093062 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7420744226742355 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7450248830425981 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7475103364650539 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7475630221626339 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7464046318729054 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7453443914763995 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7451606942622226 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7481582056822771 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7558432539523553 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7526338461158026 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7495722824457033 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.741781443674784 variance\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7504598312700523 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7472046862861519 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7354763393000308 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7272175281074843 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7585566513670344 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7418208264414835 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7550171379331202 variance\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7416016166141985 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.740838376080714 variance\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7578023110206188 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7535760738064399 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7420982120946833 variance\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7472095002675018 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7474736930436563 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7517003453191151 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7479707749510679 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7467858417458505 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 3, explains 0.7514445047962293 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([3, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(3.0257, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 4 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8304812791622971 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8253977423565286 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8328899791594206 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8337871009283956 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8336883466032978 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.828836060859758 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8317677211909102 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8322250801767282 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.833864869194786 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8427625436280173 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8403994974362411 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8309036040603328 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8271353688004073 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8366656664822707 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8340711984495957 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8228065989901141 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8190831847843099 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8448128978766651 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.828358753277986 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8406356595507131 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.829310615483853 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8280923002480096 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8445551295566529 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8413411487178885 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.827404743449491 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8345417727920627 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8342419198664913 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8370762677968056 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8347992807635342 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8324424672639055 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 4, explains 0.8343083240987752 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([4, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(2.9485, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 5 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8816088700998342 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.87766266711813 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8837418764355983 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8844408320773518 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8843043280815543 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8803393350829479 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8836761743680766 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.883224429961804 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8848408040883149 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.888648600319794 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8906580643627924 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8836793512733202 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8790741737972095 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8873204296719464 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8830506965703718 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8791884368757712 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8739868012458971 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8908879191069398 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8799911871430631 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8855254253464779 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8826552429978758 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8797674797039495 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8878697766625532 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8925136810864583 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8789614651523099 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8849109812382394 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.886053274048231 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8864574266299601 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8827250308534774 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8834342779412094 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 5, explains 0.8838562720795133 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([5, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(2.9463, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 6 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9158499456282487 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.91315337953457 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9182127620450766 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9169798904496302 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9179392604460208 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9146492232424648 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9187640582040272 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9157203868902666 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9187682674017915 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.920712547592058 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9243828771345184 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9154005814896449 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9133714025426254 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.92193309097677 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9166385530771779 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9150014384713844 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9109195859990044 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9243410555611314 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9152023918650345 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9200581722030551 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9151951095175082 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9145898960425456 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9204339265915606 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.919995953130135 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9138342606454363 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9180942368520791 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9192153728911955 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9184799688071913 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9180049825415025 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9166000471655898 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 6, explains 0.9170595873646257 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([6, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(2.9352, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 7 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9435893657488119 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.941372016030929 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9440047838659349 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9432856480363491 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9440087713105336 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9420359649725903 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9457904039574074 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9423367465048628 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9428734754436572 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9460232544425605 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9497858412445083 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9407483804110086 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9411352071505615 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9461032902587626 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9425275495227378 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9419745397000865 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9373764088283872 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9459086570238276 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9426849718788914 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9448593073124804 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9415598401554168 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9414861571897851 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9470084745788928 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.944045646668201 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9412691900511997 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9448358726373803 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9451554569190517 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9448266499380656 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9448825081262539 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9429016097370028 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 7, explains 0.9429882587989643 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([7, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(2.9253, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 8 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9607550802903334 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9591489405643532 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.960162858370811 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9597693567456915 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9610889430832463 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9594565877877994 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9630212103362635 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9589739974426598 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9603694530605841 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9632012374605106 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9649491210375686 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9590625659638707 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9594528225035848 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9628679884116584 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9597120485736506 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9597200730070061 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9572903512498468 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9617238360044995 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9606199588153225 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9626250820662057 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9590935053161999 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9594603235116251 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9626289628384574 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9615811578402607 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9590853607989916 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.96299466651209 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9623193529923023 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9619783909285247 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.963262725328545 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.9600780932262182 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 8, explains 0.960261210903546 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([8, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(2.8784, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 9 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9743221616381691 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9740191108116307 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9747718735869833 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9744146355528235 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9748619240256964 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9745026022329799 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9763543659423586 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9736022800840567 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9754276016110921 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9766845627755512 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9777040446033572 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9744981713203142 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9739073969245416 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9760118297269628 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9744027421601622 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9747939931572293 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9727995546103566 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9763805053968169 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9753167531125195 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9763704032601551 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9738015155000594 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9743431759862932 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9758875268971926 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9757605932176584 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9745552869864714 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9777113279938636 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9772388720990483 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.976592358134901 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9772750427403126 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9746631515891095 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 9, explains 0.9750824963994067 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([9, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(2.8681, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 10 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9869777951569743 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9867480422129953 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9865487030695922 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9869062867823568 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9872891774985135 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9870398295322661 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9867919842517785 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9866714415008079 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.987380669184762 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9871538835443978 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9869772933778614 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9873859426030951 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9862818644814884 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.987113555018308 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9870439599557788 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9872358362227348 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9857153795906669 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9883185426898441 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.98739008991622 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9869825032762665 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9868840121512623 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9869379662322655 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9870587331875045 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9883439146516959 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9877924740468885 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9877258060029895 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9870850770551242 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9878988636216234 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9871414841807684 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.9872455194213656 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 10, explains 0.987745706968149 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([10, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(2.8076, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 11 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9935690858348576 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9934546376356946 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9935981480283124 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9937202690317343 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9940544845688846 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9939330848969435 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9934845247078182 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9937321917688832 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9939647344074171 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9935802967443584 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9934466381302406 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9936761955591892 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9930582892148229 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9938375004436978 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9938450404065536 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9943201504689051 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9932445948161187 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9935521140410535 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9937482426669425 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9938682969612581 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9938038428518137 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9939107914517492 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9938477084401477 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9936459380452405 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9944012892588773 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9936119763071568 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9938606640945775 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9938023111207678 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9939125067604726 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9937672888964417 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 11, explains 0.9937777111463324 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([11, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(2.8088, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 12 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9970263731206231 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9969193287070861 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9970233577640866 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9971432100637734 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9970533560973187 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9970292792297664 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9967644264453476 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.997159317231361 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9972959804745816 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9969749530308739 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9969521233951969 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9971848171390127 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9967816765734703 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9970197393802895 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9972267677572617 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9967545024552081 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9969682402055065 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9969955446492315 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9972180073398234 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9971274853428812 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.997020671040229 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9973033987872068 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.996882293667058 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9970259081402691 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.996898409713051 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9971051112632477 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9971986376624051 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9971656913259833 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9971464710336788 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.997145094548474 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 12, explains 0.9970778940692454 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([12, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(2.8113, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 13 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9986615473125688 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9986738537655983 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987267407050657 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987178208471446 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987148615050565 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9988012505208164 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9986201321770655 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9990047280231625 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9988111161525882 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987529651531823 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987156756878321 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9989516426507958 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9986616624555767 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.998718471002873 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987993704223505 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9986099894935314 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9985909385679574 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987200962604618 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987387590967175 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9988837242135671 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987699924926872 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987161542023274 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9986179217382254 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987611300020404 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987346345419642 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987140045521906 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9988381241825156 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9988542153297735 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987484203663504 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987789578207057 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 13, explains 0.9987410075060572 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([13, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(2.8097, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "PCA transform with 14 principal axes\n",
            "Full input data shape torch.Size([31, 3]), output data shape torch.Size([31, 15])\n",
            "loocv round 0\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996343994359845 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996066308002105 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996257414741674 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996180436437003 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996224853116797 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 5\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996671692944307 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.999627971073963 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996726165843305 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996248227502674 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996208269942163 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 10\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996194162445745 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9997230256883324 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996598860658429 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996237909601237 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996597198613957 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 15\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996048485007059 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9995572383558474 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996403154422348 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996244978771472 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9997783216506922 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 20\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996211712843639 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996355590923307 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.999592217140854 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996231550544038 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996084150305619 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 25\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996506619837635 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.99965405398018 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996482476318079 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996249523937915 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.999665688184186 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv round 30\n",
            "torch.Size([30, 3]) torch.Size([30, 15]) torch.Size([1, 3])\n",
            "num_axes = 14, explains 0.9996008644848227 variance\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "self.axes_learned.shape torch.Size([14, 15])\n",
            "untransformed_posterior.rsample().shape torch.Size([1, 1, 15])\n",
            "loocv_outcome_mean.shape, Y.shape torch.Size([31, 15]) torch.Size([31, 15])\n",
            "torch.mean(torch.square(loocv_outcome_mean - Y)) tensor(2.7806, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "MSE = []\n",
        "explained_vars = []\n",
        "\n",
        "for num_axes in range(2, Y.shape[-1]):\n",
        "\n",
        "    print(f\"PCA transform with {num_axes} principal axes\")\n",
        "\n",
        "    loocv_outcome_mean, loocv_outcome_variance, explained_var, _  = loocv_new(\n",
        "        X,\n",
        "        Y,\n",
        "        SingleTaskGP,\n",
        "        input_transform=InputStandardize(3),\n",
        "        outcome_transform=ChainedOutcomeTransform(\n",
        "            **{\"standardize\": Standardize(Y.shape[-1]), \"pca\": PCAOutcomeTransform(num_axes=num_axes)}\n",
        "        ),\n",
        "        likelihood=GaussianLikelihood(noise_prior=GammaPrior(3, 6), batch_shape=torch.Size([num_axes])), # TODO: change prior\n",
        "    )\n",
        "\n",
        "    print(\"loocv_outcome_mean.shape, Y.shape\", loocv_outcome_mean.shape, Y.shape)\n",
        "    print(\"torch.mean(torch.square(loocv_outcome_mean - Y))\", torch.mean(torch.square(loocv_outcome_mean - Y)))\n",
        "\n",
        "    MSE.append(torch.mean(torch.square(loocv_outcome_mean - Y)).item())\n",
        "\n",
        "    mean_explained_var = np.mean(explained_var)\n",
        "    explained_vars.append(mean_explained_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1671598217515,
        "executionStopTime": 1671598218020,
        "originalKey": "e8509cc3-bd04-4585-aef9-166f93690bf1",
        "requestMsgId": "e8509cc3-bd04-4585-aef9-166f93690bf1",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7f741d3218e0>,\n",
              "  <matplotlib.axis.XTick at 0x7f741d320d00>,\n",
              "  <matplotlib.axis.XTick at 0x7f741d320880>,\n",
              "  <matplotlib.axis.XTick at 0x7f741d32f640>,\n",
              "  <matplotlib.axis.XTick at 0x7f74200af2b0>,\n",
              "  <matplotlib.axis.XTick at 0x7f74200afc40>,\n",
              "  <matplotlib.axis.XTick at 0x7f74200af7c0>,\n",
              "  <matplotlib.axis.XTick at 0x7f741d2c7d90>,\n",
              "  <matplotlib.axis.XTick at 0x7f741d2c78e0>,\n",
              "  <matplotlib.axis.XTick at 0x7f741d2c7af0>,\n",
              "  <matplotlib.axis.XTick at 0x7f741d2dd190>,\n",
              "  <matplotlib.axis.XTick at 0x7f741d2ddbe0>,\n",
              "  <matplotlib.axis.XTick at 0x7f741d2dd1c0>,\n",
              "  <matplotlib.axis.XTick at 0x7f743c3ef700>],\n",
              " <a list of 14 Text xticklabel objects>)"
            ]
          },
          "execution_count": 49,
          "metadata": {
            "bento_obj_id": "140137274862144"
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "bento_obj_id": "140136730253248",
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(range(2, Y.shape[-1]), MSE, \"-o\")\n",
        "plt.title(\"LOOCV MSE vs # axes\")\n",
        "plt.xlabel(\"number of principal axes\")\n",
        "plt.ylabel(\"LOOCV MSE\")\n",
        "plt.xticks(range(1, Y.shape[-1]))\n",
        "\n",
        "# TODO: plot MSE per metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1662128719216,
        "executionStopTime": 1662128719321,
        "originalKey": "6ec625bc-a2b4-4929-9dab-4c6e12accabd",
        "requestMsgId": "6ec625bc-a2b4-4929-9dab-4c6e12accabd",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.628856132564224,\n",
              " 0.7468973715832808,\n",
              " 0.8331834555808467,\n",
              " 0.8837114616587409,\n",
              " 0.9174032971710926,\n",
              " 0.9435285241433904,\n",
              " 0.9608617826765234,\n",
              " 0.9752921890347764,\n",
              " 0.987155236689882,\n",
              " 0.9937429209260408,\n",
              " 0.9970512279888242,\n",
              " 0.9987467712499597,\n",
              " 0.9996366694926102]"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "bento_obj_id": "140416882395072"
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explained_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1662128720106,
        "executionStopTime": 1662128720491,
        "originalKey": "c351d5f6-97df-424d-8297-132fbf1cd24c",
        "requestMsgId": "c351d5f6-97df-424d-8297-132fbf1cd24c",
        "showInput": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'LOOCV MSE')"
            ]
          },
          "execution_count": 39,
          "metadata": {
            "bento_obj_id": "140417099573904"
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAEpCAYAAAC3JtojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5wTZf7A8c9sz1JFqigq9l7OiuVsI+cg6oCACIKACOrpWc/zGur9VE7PwtlRFEXEgswpMpaxnYIFRazoKSI2pErdzfb8/uAbmYQkm91Nssnu9/167SttMjt5MpnvPM/zfZ4xQqEQSimllMo+ec29AUoppZSKTYO0UkoplaU0SCullFJZSoO0UkoplaU0SCullFJZSoO0UkoplaUKmnsDlFItn2nZ1wIT5OHOnussTeG6dwK+lYfXea5zbarWnUkt5XMkks79oKXSIK2UynV1wHq5X9HM26ISq/B9V3XNvC05IakgHXX2Y3qu80pT/7Fp2T2As4DfAvsC2wLtgDLgR+Aj4EVgpuc6wQauOwAMBo4HDgW6ANsAVcAKYBHwKjDDc53lDVy3AfQFLOAoYDugk+xwa4D/Af8FnvBc56sY738HOEIe7uW5zpcN/P/nAQ/Iw5s917k6yfcdB7zue+pOz3UuacD/LQJ+AjrLU995rrNTguU7A0OBk4G95Tsole/gF2AJMA+Y7rnOZ3HW4a9ZNMYkz3UubcL7VQ7wXOd7oGNzb4eqn+c6E4GJzb0duSTjNWnTstsCtwCjgSLfS3VyltVeDup7A2cDd5iWPQG423OdhNOjSQD9A/AXXzAJKwcCwM7y1w/4p2nZ9wN/8VxnQxLbfixwJ7B/1EsVQDHQU/5OAK41LXsG8AfPdVb7lr3LF6THAw0NIuPltg64t4Hv9TvHtOyrG3ACZMco05hMyx4n33E739O1Uk5tfOV0DPAn07LvAS7xXKc2wWqr5TtsiAad3CmlVLbJaJA2Lbs3MAfYU55aKEHvNeBHz3VqTcsuBvYDTgMukVrqncBJpmUP8VynMs66S4An5X0APwOTgBeALz3XqTItuwDYSWp3lwG7Ar+Xdf/Oc53vEmz7OAmwBUAN8BDwBDDfc50y2e4dgDOAcbLus4HDTcs+3nOdH2RVTwO3At2AEaZlX5NsoDQt+2DgN/JwThP6czZKzWMQ8GiS7znP99528RYyLXsMcJ88/BG4Sb6DpZ7rhKRGvr2U01VAd+BCCcKJTlie8lxnePIfUSmlcl/GgrRp2e2B2RKgQ8CfgFuia8cShD8APjAt+9+AAxwNnA48CJwT51884AvQTwPneq4TUfPyXKcGWAwsNi17MnC7BOk9gRdNyz7Uc51NMbb9VOAeyYb/Cejnuc7HMbZ7MfAv07LvliB+FrAL8Ixp2Ud6rlMrJwsPAH+VJvghwNQki/EC3/27knxPLC9Id8D5yQRpaXY+UU5OXveVc/RyBcAN8nAlcIjnOiv8y3iuUyVN3beZlj0TeFtq1Rebln2v5zr/a8LnUkqpFiWTNen/kyZsgL95rnNzfW/wXGe1adknS9DeGxhuWvbTnus851/OtOwBQLiW9TIwpL6mcQnYF0vz+7kSqK8HLo9adxsJuHnS3Gp6rvNFPesOmpZ9ttTaj5Bt7wO8JYvcJycpBdJ8XW+QNi27nfTxAnwFePW9J4FnJEgfZVr2XvV9HmAMYMj2r02w3J7SQoDkEqxIsCye63wv+Q7nS55Ap4Z/lKaTVpDl0rrwhec6e9ez/CDgKXl4jfSzhV8zZX86VPIVSqT1YbHsm/d6rvNjE7a1RMrrdMnl2AbYJCc+rwB3Ra/ftOyDgPeAQmmBOTXOunvK99Ae+AI42HOdCtOyD5AcEYALPNe5z7TsIcBY3zb8IjkGt3qu804jP9tvgVHym9lBupDWA18CzwH3eK6zMcb74mZFm5Z9ibSoIXkR64CLpJVrV6Ct5Kn8F7jJc51FqSz7qPe3kdajAUBv6QL6DpgF3NaYMpP1LgL2ks/WTU6E4y17KDBfHt7vuc5432v5cowZDBwIdJXf/Rr5/qcDj8c6tpqWfS7wsDzsAuwhx/yDZX/axnOddclkdzdhP2jvS0q7ynOdf0kX5SWyri5yDP8EeMBzncfqKdczpVJ4qORMVcjv4xnZhrjdb6ZlnyCf4ShpLQzJfvYOMNVznaSP3xkZJ21adnf5QSMf8qZk3ytNwef5nvpbjMX+LrfVwHn1BegoF8sBBmC8JDz5jZMvF+DGJAJaeLtDEtwGAF0813nL99pPwLPy8HDTsg9MYpXnSH8uyfTP12M+EP5xnJ9oQdOy8yTo4AtM8bT13U9q3/Jc50HPdQ7zXOfcxh7cm0paQWbKw71My963nrecJbd1wK8/dGkheVkCwG6+RLmOwCHAn4FFcuLZYKZl7y3Bc5LkPXSVA/020g1yNfC1adlD/e/zXGchcJ087CcBNpY75YBaDQz3XCecKe0/GLUxLfsO6eo5UT5bgRyIBgLzTMseH2f9iT7bXcAbwEg5wJfKdnSSE9yJwCemZe/YwFX7t71EgukdcuANSF7MDnKS/75p2YfE2b5Glb3v/V2BBRKg9pPfcqEE+wnA+0CPBn62sOly21G68hI5y3f/Ed/2dZCT8GlAfymTAgnSPYBTZF93pcsqkd7AS8Bx8hlrkv0gTdwPyqPWdZG0/A2UIFsgZXQsMM207JgVRdOy25qW/aK0yJ4mn79OfhtHSL7NJ6Zl7xbjvUWmZU+TxOThkv9kyL63sxwbXjYt+0k56atXpiYz6S8biQSYBqXey8H7fXl4iL9w5P4B8vA/vr7fZNe9CZgiDwOSIOV3ptxW+/pak133Is91nDh9zv7m6mQOauPktsz/42qCGXI7QmqS8ZwifciVSQTpxb5hFUNMy941BduZKf6z6kHxFpIWDUsevhquOUngC59MPg8cBBR5rlMqP+6zpKukHTBDDopJMy27i+Ru7CRdCSOA9p7rBOQkcpDU6EqAx0zLPjpqFRPlLB5gkmnZ20St/3Tfvn+d5zof+l72H2RPl+TMW4FenuuUyIF0mNTkDOBOCWrJfrZzpXaLtJodJWUXkGD4ZwmIO0kQaQh/MuKtEhRHAG3lu9nGd5JfCvwrxvY1teyR7rg95P4UKbtSOeacIbXFBh1ffB6Tmhr17LuG7/Wvo06KJwFHyv1pwO5yAlMiJ5zhE4HfSVddIn+V8jjQ9xnX1/OeVOwH/u/6SDkZuw/YSdZRBJiSrwRwpWnZO8dYzyMygqdOPksXef82UiuvlG7M52Ukkd99vlbdO4Fd5L2lckx4Rl4b7GvhSShTQfo43/1XG7kO/7CvYzOxbtOyS+WMG+BDz3XWNHL9W/Fc5w0gPPRomBz8YzIt+0hfRvk0z3Xq3eGTMEV+2J18JyKxhAOP47nOLwmWQ7LYn5aH2wALTMu+zrTsPRO9L0u8CXwv9wcnWO4M3wmn/2QpHOCqgMGe63wkXSp4rrPRc50n5YSnTk74+jRw+26UroRy4Lee60wLN/l5rrPac52Zcpa/Un7XEcFGMudHyEleN//rsu+FTxrfiTFExt9qcwxwm+c6V4ZPiD3XqfRc53Ffa1mBJGYmy9+ac6bnOm97rlMt617luc5NkhMCcIxp2bs3YN3+bbeBk6XsymX96zzX+YfU3gCOjfFbbFLZm5a9jy+Pw/Nc57yosntWaudb1cySIQmv8+Th6QlqukdLDZmoWnRbqeEBfCP5PF97rlMnf4ulJe8TWWZMPZtkAv3DeTue69Qk2fLXpP0g6n8MAP7tuc5F4YRgyQl6BbhGljF8J9zhsjhR3gtwvec6N4RH58i+cqfv/bvLbyr83qOkiRtgguc6l3ius4Qt3/NHnuuc6esWON+07L3qK5RMBenweNoa6U9tjE999/1fjn+s7ucpXndPX799zLG8TXS33LaVmkg843z3m5Iw9ivPdb6R2gG+g2sE07K7AeH+yymxlonhAjkLRmqQfwe+MC37J9OynzIt+zLTsg83LbuwgZs8zLTsUAP+/tOQlcsP/HF5uGeCJu9wc+FGSWoMC9eMgxKEY/2PT4GA5zrdPdd5Idltk4NoeP94LN7Yes91VvkOYofHOIgtBq6Uh6Nl7DwShLaXAD6inqFwVbJ8LM/4aikxkwvjOAHoBeyXYITFa7779XVHxPNUVAtBrPUbUkuC1JX9Gb77dxODHMynx3otSeGWoA4JmrzD+27I33IkrYmd5XObsVo65fcRnmdhO9OyE+WPPJtopEwCqdwPyn1dPInWEX1iNFpua6UmHMtUyQl6MqqVKXyc3gD8M8G2+bcrXiL0rzIVpLeV27VN6Ev11+L8TXXbxlkmW9adyDRfM1DMJm9plgzX7N7wXKexJyKxhCdF+a1p2XvEeP1cOUlZmmwrhec6a6WZ6kpp3g3bTprabgPeBdaYlj3LtOzTpd+7PtVSVsn+lSVXBBH8TWhb1ablwGTKw5lRiSPhk7gOwGTTsmNOrpEoqSeBw6TJEF/STzxv+O4fGf2i5zr3SXY/sp3HyhA4gCskkCfyUbwWJfltvysPu0o/bL0816nwXOeHeJPaiHW++3Fbner7VwleWxln/ako+4N89+cRX1OSQZ+SEyji7Lv5vhazN6KDoOc6GzzXWeK5TqLJg5L9Dt5K8FpcKd4P5ieY+yLed420FCEJpDGP+Z7rrPVc52TPdc7yXMdfeQmf9H4Sb6gwW1o+wjlBW/1Go2Uqu9tIwf/L9933n+kbvvuNXX861x2XjK9+RPo5DpBhWtHJUyN8B4mU1KJ9HGC1nEWP9dWywsJnlQ815ORKAtGtpmXfLjuhKc27h/lqnO2k+dEGPpMx8HEzazMxTtpznUWmZX8kma2DfH2VYQMlEYYYeQF3SI2rhzR5DTUt+3U5a38dWNjQXAwf/wnUv03LvjXBsv4Tnl5xlhkjJxW7SaJbHuB6rnN/EttSX+Lk9777PaMOiHFJ5vNQ6fPcS06WA3GOHUac1dRnWYLX/AdV//EgFWUfbu0rj5rYKFp9J0hxea6z1rRsV2rtp5mWXRwVKMLJbsTLaTEte3s53hwjme/tpa88zJ/olOg7aEwtOrwNqdoP4n7XnutUmtavqUe/ftfSvxzuDmjQZ4h67xGmZa+r5y3hJNt4v9FfZaomHT7z7iBjaRvD37yyJs59f803Fev2n0klNdtWI9zt6zeLVZsON6H86MsITwkJpuEf7Eh/X5YMg9hd+lAfjr+WhOuv81xnnuc613quc7L84PaVmttzvmbhfYH3kumfyYBwM+CepmXvF/VauLlwqfRh/0oy9o8AXHmqRPqgb5Hm/+WmZd/XyP55f628VE504v35awYxk9M81/nZ12dcLENL6utnDKvv4OOfZyCpGq+MblgkLTsDZchiD/nc4c/VJolV1SdmN0Q9UlH27eV2q2FDUeqd9bAeiZq8w/tumS956VemZQ+XKY1vkAC5qwR1/+dLlGDq15hWrFTvB435rv3f2VbzZdTDv58U1LOfdPCdHNSbQJqpmvQXUqPKk0zsBY1Yh38qTn+Ny39mf3DU/NRNXfcS+bILfTN9pZTnOl+Zlu3Jj2qwadmXSpNxeBrScOC6P5yIlGKTgSvkJMSWfhZ8CWMvNWVcr5/Uxj+Xv3tNy95BThKOlzPLf9STxJYJjwM3y746OJyvIP3zv5VlpsVqWZA5pPuZlr2LHGR+J/t9iWQBjwPGmJZ9pec6SWV2Cn8NvJ/nOm6CZZNl+u6XACdFZbjHU98+6D/xr7flQJIzZ0ufOHLydpeMy10XThyKMfd8pqSi7JOt+Tf1ePy8nER1lH13NpvLrtCX2DgresImGUc/VQJHjWQdPyX5QxvDOQpRY5wTaXCXZhbuBw1trfHvJ097rpMo+bRBMlWT9vfVWAmWS+REuQ1FfUmpWPdJvvu/9r3KjhFuft5LDr4NIn1B9Qk3Y5f4xiTjq1lXSTBNObkISLhWeD5bxkwOlOceTMf/lf/9gzTPhWsQJ9bzlrSTWmY4scQ/nGWw7+w34Sxtnut847nOzZ7rnCAHzBNlQpxaORDfYVr28Q3YLH/ttbGtRb+KmvwnnOR3l5w01ae+2rF/rHx9NUfkpCx8YH7Kc53TPdfxJJvXXxuKHuqSKako+3BQbFvPck26SEjUeP/TfEMrf+fLtYnV1H2xb9++RDL350s2s7/7L53fQTbsB/7vuqHfRUp/o36ZCtLP+X6wF8hZU9Iktf1gefiyHEhhy4E+HGROkLPChqy7rS8w/iJno37hjF9DZgtqyLrbA1+Zln2rXPUrnjm+RIJRbAmU4aEAT3uuk1TfXiOFTwCOk4lnhsqPYWX4bDwZpmXnm5a9t2nZ0RcgiUuSO8KtIfUdxDIlXKPcw9fkHZ4AZF4SyVW/kqEXr3muMyYqy3dkA7bH37pzQILl6iXJXOHxuDN840Y7AA/LWNpE6jtR9Y+2SGZu+YN99xNdMKaxGd1NlYqyD7dEtaknKzpW8mZDhffd9r4m7/C++0OcWmj4O6iu56Q8nd9Bs+8HMnlPOKeiQd+FnCAtkYf7JfE7SlpGgrSM6w037/WQJJukyKws4YNKXZzmlut996cmO5OLuMN3ljnRc53o/pRHZedGxrUlNVuUfElTZPady2VwfEySUBTeMfeTiSBsXx9QqhPGos2UE5Q8GToTrkE+GnUWG5ccfNZLU/aTSbYghGc0CydPNGgimjR6xjd7UT+ZLjM8rjle0s02pmUfl2homec6z/umVW3I7FILfP18dqKyNS17T9OyB8rJZywPSNP7aqk1rfNNIHGiJDEmcmSMCRzC/zvPd4W3JUmO5/efsMfMGpdciZjDBDMgFWXvn+f/COL7XdM2FaLG+/eT2nR/eTwtTvJi+DvYGO/3Lq2IcY9hKZAt+8Fcud0x3nh8mVXsO9OyV5uW7Z/gKVxZ7OLrGov1fsO07PPkglP1ylRNGklIWCj3x5qWPam+JDI58L/oO3v6p+c670Uv57nOq75Avj/wkmnZCZscpNZ3my9h5i254Eb0usPTktZKbXqWadn96ll3ifTxhPtXn01ilrAHfZdWPMs3T/eHnuu8m+B9TSZngeHhR4N9E7okOzYaGa4QHkKyJ3BLkmeTV/gCVn0zmmWE9NmF54c/RWrAhiRYbbWNpmUfLic5r0dNYRu9XHdfM1rSVzCToV7hFp3e8QKpHMTukZOuz6JPGEzLHuUbv3yxb5IGx9dMOrGeBL7SBFcrO8s3hW6y49T9J2ZbTY8r+9Ak33pJJtkmVVJU9v7WuQtjvB0Zl9/kfIyo8f6nSFdeOHEtXjdN+DvoFKvLQ1oEn4jqvkj1d5At+4H/mBc9uiNsqFQstvUFdXxDWgFuTjCT4xhZ9ptkKn0Zu8CGTNTfT4Lu/rKz/06G6bwEfO+7VOW+cjC52FfLvUeuEx3PxfKlDZUgs9i07EkSID+Xq0/ly/ypphxowmdK84DT4yVmea7zslyC8UHJLnxeJsuYArwVrjHIDt5PmsXDZ0kvA8OSuODHL6ZlPyHN3efKuGIyUIsOmyzTPYb7hefFm7ghgYslwW4HyR4+Qq4I9qZcijTE5nLqDBwuAS3cBPyl7wpa2eAxCTp9fL+TZ+PUDufL32EyTKe7nPR8K/t0kcxcd4cE+8ZkzP9VpuTsKlda21Ym+V8mNdvDZZKE8AnWP/y1IpnrONyC9ZznOk9Erf/3Mkynk8xrfESc38PnwP/J7/R+z3V+lvuDfBN1BBvQWjbb1xJ2o2nZ38mBr1BqnX+RffJ0X9fLQJknPdjEOeyT1aSy91znXdOy58qMX/3k+un/J+8vkQmDJsnUx/WOm03CNLmATy9fF917Ca4wN1u+e+S7H+O5zjcy89qp8tk6yG86vN+ebVr2p0AoRd9BVuwHnuu8Zlr2LOlqHGZa9kbgBs91fpQuyOGSWIo0b0/xvfdtGVI7Un7vnmnZV/mmtN5JkkfDQ13neq7zcn3b1Jgg/R/TspPJMp4bfbUd+UH3kSzeCyVIhpt560zLrohq9kD6c66KcVCJ4LlOjWnZwySR7AbJVp4Qbh43LbtM1u2v3ZXJFH431jfJhOc6j5iW/T+psR8gweUMWXelrNc/Hd8muZDIzQ3Iyr5LgnT4bHaNb47ttJIxwm/7mnWTrkX71vGj5A88KP1hR/oOOjWmZQelCT962sJngPNjXdnGZ7BcMrSh9pes64Z6CVglZ+4Jm7rlOtmD5QR0TzkD/7vs0+Wy34VbraqlFtug1hHPdVaaln2SHKB2lIPWX+Q34+/eCQF/9E+yILWQh6VGtT7qkqfh9a8wLfsy+Yy/8X2GaDNl/5wATPB9p+HPVyPTSibVdeG5zkcStC6UxKH/ShmFL+5QC1zkuc7zpmW/Lwe/Y+RzfCwXLkmrppS9z0g5We0p5X+B7BvhMcDfyDLhGRkbXYGKGu8fbnZN1JIXnm/6N7L8YjmmhWuCv0hS7jfSDVQK/FEqOvc0cArYeNucTfvBSEmQNCV5d3yM7/pb4JQY3aPj5Pg2VLbvXflNhHxzLCCfL/o6ETE1prm7TRJjwDrESwLyXKfMc53LZWe/zJc0Vem7rN9n0jQzGOhdX4D2rTvkuc5kOYicI80+X8g6A3KGv0Rq1xcBO8gY3qRmgfJc513PdQ6UL+8e4EPJ6iuQ2tF38kO+SCbQv7Ehw6ZkykL/ZCZTfFciyoRwAtnGxjY9y4xBfeVHc5OcNP0oGeptZIf9UbLo/yFTAJ5Z37zgsoMns99F/zWqS0e+N/9+t1xaReIt/53MLDVOxkr/IAeZgGSvfyBjpvdKctKQWP/jUxmSd4mU30rJyl0tB6o7gH0914m+SMQfZJgbMqtYzIkePNd5VE40AP4szfixlhsjrQyvyGerkeSzGcChnus0dN/5vYwsmC8ntzXyO31Q1hfuyholtasyOTi/X896U6YJZR9+/xJpQbxZWo2CcsxYJNOsHiKTmYSPFw1Kro3BP3telW9oZaxtq5D940YZK10pXTufyuUm9/Vc5z3pHhku218pl15M5XTJWbEfSHdXX98wtuXyXW+UbbtaTv63muJaEkXPlpaJxySYV8nf1xJ7BgAnhYfa1scIhTLRWqSUylWJrteslEqvTCaOKaWUUqoBNEgrpZRSWUqDtFJKKZWlNEgrpZRSWUqDdOOE9K/+v19WLW/2bWgJf81djtMevv/Xawyfc/aQCc1dHrlaji3lr4nlqBooY5OZqNanrraxl09Wfs1djt27dcVznWbdhlRo7nJsKbQcM0tr0koppVSW0iCtlFJKZSkN0koppVSW0iCtlFJKZSkN0koppVSW0uzuDJq5oIoJcypZWw49Oxpc07eIAQdFXxBKKaWU2kyDdIbMWljFZc9UUiOjF35cF+LKWZUAGqiVUkrFpM3dGfLX2VsCdFiwGm56KamrZCqllGqFNEhnQEV1iLXlsV/7aZ1OwqOUUio2DdIZUFJo0L29Eff1lxbVxH1NKaVU65VzfdKmZY8GrgZ2BJYBd3quc7u8tj0wETgB6AAsBC71XOeDOOsKALcAg4D2wOfAHz3XeS3V2/23U4q4YlYlFdWRz4eAUdOC/PV3xVxwbCGGET+YK6WUal1yqiZtWvYQ4O/ACAnCFwPjTcs+1LTsfOB5oAdwCNAFeB3wTMvuGmeV9wAnAccDnYEZwBzTsndL9bYPOKiIWwcU07Pj1kE4FIJ/vFDJ5TMrqKrR5m+llFKb5VpNegJwlec678njOfKHadl7AQcAfTzXWSbP/R04BxgpNeZfmZbdCRgOnOm5ziJ5+lbTsocB44ErUr3xAw7aMuRq6jtV/HV2Jf656p9YUMPSX4I8OLyEbdvk1PmTUkqpNMiZSGBadg9gLyDftOwPTMveaFr2x6ZlD5ZFwlXUXz+T5zohYCVwaIxVHiwnKe9HPT8fOCJ9n2Szc48sYvqoAO1LIp9/99ta+t1dzlcra9O9CUoppbJcLtWke8nteGCo9EefBzxpWvYKYC6wCLjBtOxzgA3AGGAfoCzG+sJN4Guinl8NdE+0Ib+sWp6Sy7Xt0w6mDc7j988G+GH9lvOl734JcepdZfyrX5A+O+ZusK6pqWb18mXNvRk5T8sxNbQcU6Mp5di5+3Yp356WLpeCdHhbr/Nc52u5P0map0d5rvNf07JPA+4APpbA/DDwBlDYgP9j1Hdx8k5dEsbwBuncHV7cMcR5jwV559stAXljlcGFz5Zy/anFjO6Tm5OdrF6+TH+UKaDlmBpajqmh5ZhZuRSkV8vt2qjnl0iyGJ7rfAP0979oWvZCYEGM9S2X2y7Aj77nu/pey4hObQyeGBPgmv9U8vgHW9K/a+vgL89V8vXKOv7Rv5iCfM38Vkqp1iRn+qSBxRKoD496flfgWzYH5DMlgQx53EuSyWINqVoAVAFHRj3fB5iXlk+QQFGBwb8GFjPBKiZ6FNbUd6sZNjXI+qBmfiulVGuSMzVpz3VqTcu+DZggteNPgLHAQXILMBpoZ1q2DdQB90o/9dNsDto3Ab081xnmuc5607KnADeZlr0I+E4yuneUoVkZZxgG448tonfnPC58IkiZb8bQN7+u5dR7ynl0ZICdO+fSuZVSSqnGyrWj/UTgbmCmJHydC/T3XGehvD5Knl8stety4GTPdcJtyD0kCIddJmOrXwdWAb+T5b9rhs/2q5P3LuC5C0q3GlO9eFUd/e4p4+0lOkOZUkq1BkYopE2ojZCRQlu1sY5R04Is+D4yk7wwH/55RglDD21IPlzmaYJJamg5poaWY2o0sRw1saaBcq0m3ap0aZfHzLGl2AdG9kpU18Llz1RwvVtBbZ2eZCmlVEulQTrLlRQa3D2khD+aWw/DuvfNakZPC7KpUgO1Ukq1RBqkc4BhGFx2YjGTzy6hJKqF++Uvajn93nJ+WNv0yVWUUkplFw3SOaT//oU440rp1i6yW2fR8jqsu8tZ8H3uzk6mlFJqaxqkc8yB2+fj/r6UfbeL/OpWbwoxcHI5sz6qjvtepZRSuUWDdA7arkMez44vxdonMqGssgYueqKCm1+upE4TypRSKudpkM5RpUUGDwwr4ZLjt04ou/21KsbPqKC8SgO1UkrlMg3SOSwvz+CavsX8e3AJRfmRr83+tIYBk3zjVHQAACAASURBVMtZvkETypRSKldpkG4BBh1cyNNjA2zbJjKh7OMf67DuKueTnzShTCmlcpEG6RbisJ0KeOGiUvboFvmV/rwhxBn3lTPnM00oU0qpXKNBugXZoVMesy8o5cQ9Itu+g9Vw3mMV/Pv1SnQaWKWUyh0apFuYdiUGj4wMMPaoref1vumlKv7wdAWVNRqolVIqF2iQboHy8wyu71/CzXYxBVHf8NMf1jDogSCrN2lCmVJKZTsN0i3YOYcXMWN0gI6ByOff/64W6+5yvlyuCWVKKZXNNEi3cEfvWsDzF7Zhl86Rmd8/rA3R/95yXv1Sr02tlFLZSoN0K7BLlzyev7ANR+8SmVC2qRJGPBJk8twqTShTSqkspEG6lehYavD46ADnHB6ZUFYXggnPV/JHp5LqWg3USimVTTRItyKF+Qb/PKOY608tJi+y9ZvH5ldz9kNB1pZroFZKqWyhQbqVMQyDsUcX8ei5AdoWR74295taTr2njG9Waea3UkplAw3SrdSJexTw/IWl7LBNZJV6yeoQp95TxtzFmlCmlFLNTYN0K7ZHt3zci0o5dMfIhLJ1QRj6UJBp71U127YppZTSIN3qdW6bx9NjAww6OPLa1DV18Eenkr/NrqBWr02tlFLNQoO0orjAYNKgEv7yuyKMqISyB+dVM+KRIBsrNFArpVSmaZBWIAllvz+umCnDSwhETfv92v9q6X9vOd//ogllSimVSRqkVYRT9ink2fGlbNchskr9vxV1nHJ3OfOXakKZUkpligZptZX9em5OKDtw+8jd45eyEIMeCPL0h3ptaqWUygQN0iqmbu3zmDWulNP2j0woq6qFS56q4MYXK6nThDKllEorDdIqrkChwX1DS7jixKKtXrvzjSrOm15BeZUGaqWUShcN0iohwzC40izm3qElFEdWqnnh8xpOv6+cZes1oUwppdJBg7RKyhkHFDLr/FK6tI1MKPtsWR3WXeV89INem1oppVJNg7RK2sG98nF/X8o+PSJ3mxUbQ9j3lzP7E00oU0qpVNIgrRpk+455PDu+lL57RbZ9V9TA+Y9XcNurlXptaqWUShEN0qrB2hQbTDmnhAuPLdzqtVu8Ki56soKKag3USinVVBqkVaPk5xn8zSrh9jNLKIy8PgfORzUMnFzO6jIj3tuVUkoloSCJZbKKadmjgauBHYFlwJ2e69wur+0J3Az0AQqBL4HrPdeZE2ddS4GeQHTW0/6e63yVkQ+U4846pJAdOxmMeayCteVbas8f/lDH0CdKmT66lr175Cdch1JKqdiMXOo/NC17CPBPYAjwEXAScBswHPgAWArMBS4EyoELgFuB/TzX+TLG+pYC13quM7WBm5I7hZYhS9fUMeKRIF+vjByOVVoE954V4OS9c+58MGusXr6Mzt23a+7NyHlajqnRxHLU5rUGyrUj5wTgKs913pPHc+QP07K7Ab2Axz3XWS/PTQEmAQdIrVqlyU7b5vH8haWcPz3If7/e0jBRXgXnTgvyt1OKGX9MIUb0ZbaUUkrFlTM1adOye0jz9lDgSmAPYAlwg+c6T8kybwBrgHHARuAi4M/APp7rrIixzqXA50BvYDvga6lZP1/P5uRGoTWDmtoQE56v5KF3th6ONfSQQiaeUUxRgQbqhtAaYGpoOaaG1qQzK5dq0r3kdrwE6mXAecCTpmWv8Fznv8Bg4AVglQTS1cCZsQK0+AT4BjhfgvqlwHOmZR/luc478Tbkl1XLqavVWbbiuexw6FFSyMQ3iqkNbflNzvigmq9/DnL7qUE6Bpp1E3NKTU01q5cva+7NyHlajqnRlHLUk6SGy6Wa9FHS33yC5zqv+56fDyySQPueNGv/AdgEjJREsiM91/ksyf+zAPjEc51RCRbLjUJrZs+9t4KrXihlQ0Xk8ztta/DoyAC7ddWEsmRoDTA1tBxTQ2vSmZVLQ7BWy+3aqOeXAD0kiexA4DLPdVZ6rlPuuc69wLfA6Ab8n8WyPtVEfXas5fkLS9lp28jf5dI1IU69p5w3vtJrUyulVCK5FKQXS6A+POr5XSUQh0WfqRXEqvmalr2zadn3mpbdMeqlfaRvWqXAbl3zmXNhG47cObLWvKEChk8N8vA7Vc22bUople1ypk/ac51a07JvAyaYlr1Q+pPHAgfJ7bfAcmCiadmXAmUyNGsPSSTDtOybgF6e6wyTZfsD7U3LvhiokoS03YCBzf15W5JObQyeGBPgmv9U8vgHWxLKauvgz89W8vXKOq4/tZiCfG0JU0opv1yqSQNMBO4GZkoW97lAf891Fnqusw7oC2wLfCXJYxcAgzzXeUve30MmQcFznaA0kbeVmvP3wHHAcZ7r/K95P2bLU1Rg8K+BxUywiokehfXwO9UMnxpkfVC7+pVSyi+tiWOmZfeLN9uXb5n7PdcZl7aNSA+NJkmIl2Dy8qIaLnwiSFlUS/euXfKYdm6AnbbNtXPH9NKEp9TQckwNTRzLrHQfDZ/2PzAt+4sYy5yT5m1QWebkvQt47oJSenaM/L0uXlWHdXc57yzRhDKllCIDQTr6rGmnJJZRrcDePfJ54aJSftMrchdcWx5iyJQgM97Xa1MrpVS6g3R0s3CsZmJtOm6lurTLY+bYUuwDI/MXq2vh8mcquN6toLZOdw+lVOulnX+qWZUUGtw9pIQ/mkVbvXbvm9WMnhZkU6UGaqVU66RBWjU7wzC47MRiJp9dQklh5Gsvf1HL6feW88NanYZVKdX6aJBWWaP//oU440rp1i4yTWHR8s0JZQu+j77st1JKtWzpnsykxLTs7xM8BihO8zaoHHLg9vm4vy9l5CNBPlu2pfa8elOIgZPLue3MEgYcWJhwHUop1VKkO0hfl+b1qxZouw55PDu+lIufrMD9fMtwrMoauOiJChavrOPKk4rIy9OBAUqpli1nroKVZbTQktDUySPq6kL806vi369vPb93//0KuGNQCaVFLT9Q6yQcqaHlmBo6mUlmpX3ubtOyC4Biz3XK5HEhMAzoCjzjuc436d4GlZvy8gyu6VvMrl3yuPKZCqp8XdKzP63h+7XlTB0RoHt7Ta1QSrVMaT26mZa9o8yj3d/39PPAQ8CfgY9Ny94nndugct+ggwt5emyAbdtEnoR//GMd1l3lfPKTJpQppVqmdFdBbpKLV7zO5qDdBzDlIhYdgQeAq9K8DaoFOGynAl64qJQ9ukXusj9vCHHGfeXM+UxnKFNKtTzpDtLHABd5rrNCHp8GzPdc5015/C/g2DRvg2ohduiUx+wLSjlxj8hrUwer4bzHKvj365VojoVSqiVJd5DexnOdxb7HfYBXww881/kJ6JLmbVAtSLsSg0dGBhh71NbDsG56qYo/PF1BZY0GaqVUy5DuIF1mWnaAzU3dxcAhwNzwi/KatlOqBsnPM7i+fwk328UURO3BT39Yw6AHgqzepDOUKaVyX7qD9BfAmXJ/lNy+6Xv9JECzu1WjnHN4ETNGB+gYiHz+/e9qse4u58vlmlCmlMpt6Q7SdwJTTMv+EJgE3O8bivU74D5gRpq3QbVgR+9awPMXtmGXzpGZ3z+sDdH/3nJe/VKvTa2Uyl1pDdKe6zwDDAXeBS4BLve9fCzwCnBHOrdBtXy7dMnj+QvbcMyukQllmyphxCNBJs+t0oQypVROarYZx0zLzvNcJ1c7DvWIn4RMz/BUXRvir89V8uh7W6c5DD+skBtPL6YwP/cmPNKZslJDyzE1dMaxzGq2qZpyOECrLFWYbzDxjGL+0b+Y6Gm9H5tfzdkPBVlbrudXSqnckdZpQU3LTipzx3Od/CQWU6pehmFw3lFF7Nw5j/GPB9lUueW1ud/Ucuo9ZTw6spRduuhUokqp7JfuubuDwEbgOeBZoCzN/08pAE7co4DnLyxlxCNBvv9lS+15yeoQx9xWBiHo2dHgmr5FDDioqFm3VSml4kl3kO4GnAWMltuZwBTPdd5O8/9Vij265TPnwlLGPFbB/KVbGnXCaRg/rgtx5azNVW0N1EqpbJSxxDHTsveQYH0OsAF4GHjEc53lGdmA1NKOzSRkS6JOZU2IP86q4KkPYw/H2r6jwft/apvx7UpWtpRjrtNyTA1NHMusjHXMea7zP891rgZ2AK4EDgI+Ny37uUxtg2qdigsM7hhUEvf1n9bpOZdSKjs1R/ZMAOgh15MulFq1UmllGAbbd4x9Em8YsGS1DjZQSmWfjAVp07KPMC37IWA5cCHgAL081xmeqW1Qrds1fYsIbH1dDupCMOTBcn5er4FaKZVd0j0EqxMwAhgDbA88ARzvuc776fy/SsUSTg678aWqrZq4f1wX4qwpQZxxpXRqo91mSqnskO7s7p+AX2T41XNAORAwLTviGtK+60srlVYDDto85CoUCnHZzAqeXLAlmeyrlXWcM7Wcp84rpU2xBmqlVPNLd5Aulv7n8fIXSwjQyUxURhmGwb8GlLA+WMGLi7YE6g9/qGP0tCCPnhuguEADtVKqeTXb3N05TgstCbkw5KWiOsTwh4PMWxI5Od6p+xVw39AS8qPnF20GuVCOuUDLMTV0CFZm6dyIqlUrKTR4eESA/XtG/hSe/7SGq/9TqVfPUko1Kw3SqtVrV2IwfVRgq/m8p8+v5saXqpptu5RSSoO0UkDntnk8MSbAdh0iW+PueqOKe9/UQK2Uah7pThxLOdOyRwNXAzsCy4A7Pde5XV7bE7gZ6CMTpXwJXO+5zpw46woAtwCDgPbA58AfPdd5LeMfTDW77TtuDtRn3B/kl7ItzdzXu5V0DBgMPTTGIGullEqjtNakTcseYlp2yk4ETMseAvxdxl53AC4GxpuWfahp2Qbwklx1axegMzAd+I8E71juAU4CjpflZwBzTMveLVXbrHLLbl3zmT4qQJuo621cOasC97Pq5tospVQrle6a9HTgdtOy7wcme67zcxPXNwG4ynOd9+TxHPnDtOxuQC/gcc911stzU4BJwAFSq/6VTLQyHDjTc51F8vStpmUPk+FiVzRxW1WOOnD7fB4ZGeDsh4JUSdJ3XQgumFHB9FEGR++acw1QSqkcle4+6Z2Bh4DzgaWmZT9pWvbRjVmRadk9gL2AfNOyPzAte6Np2R+blj2YzROirAD+C4w2LbuzadnFwDhgDfBGjFUeLCcp0bOfzQeOaNSnVS3GUbsUcN/ZJfhHYFXVwrmPBvnoh9pEb1VKqZRJa5XAc50fgL+alj0BOEOC9X9Ny/4MuAuY7rlOeZKr6yW344Gh0h99HvCkadkrPNf5LzAYeAFYJWOZV0tNeUWM9XWV2zVRz68GuifakF9WLaeuVud5rk9NTTWrly9r7s1otEO3hWtPKuDvXuDX58qqYOiUTTwyOEjvTpnZB3K9HLOFlmNqNKUcdZx6w2Wk3c5znVrgGeAZ07J3kWB9LXCzadkPe65zeRKrCW/rdZ7rfC33J0nz9CjTst+RPukvgVOATcBIYLZp2Ud6rvNZkptr1DdZSacuCWO4Ei1h8oix3aG2sIrr3Mpfn1tXkccFz7bl2QtK2b5j+gdItIRyzAZajqmh5ZhZGR+C5bnON3JdaUuyqf+Q5FtXy+3aqOeXyNSjJwEHApd5rrPSc51yz3XuBb4FRsdY33K57RL1fFffa0ox/tgiLj4uMpNs2foQZz1YzupN2qKilEqfjAZp07IDpmWPMS17PrBALrhxRpJvXyyB+vCo53eVQBwWPe1cQZya8QKgCjgy6vk+wLwkt0m1Etf0LWL4YZFDsL5ZHeLsh4NsrNBZyZRS6ZGRubtNy95X+pKHSRB9FLjLc52vGriea2TY1RnAJ8BY4A7gEAnUXwAvA5cCZZK9/QBwnOc6b5mWfZNcw3qYrO8e4GTgdOA7yei+CtjHc53vEmyKHpWT0NKaxWrrQlwwo4LZn9ZEPN+n9+ZhWyWF6ZmWuKWVY3PRckwNnbs7s9J9PelzJDgfIQH0L8AjnuuUNXKVE6X2PxPYVvqf+3uus1D+X1/gRuAroEhuB3mu85a8v4dMghJ2GfBP4HWgHfARcHI9AVq1Uvl5BncOKWF9RZA3v96S4f32klrGP17Bg8NLKMjXY5BSKnXSWpM2LbsamC215pY0i5fWpJPQUmsuZZUhhkwpZ8H3kf3Rgw8u4PYzS8hL8ZWzWmo5ZpqWY2poTTqz0p3d3VuGYSnVYrQpNph2bin2/eX8b8WWQP3UhzVsU1rJhH7FGIYei5RSTZfWxDHPdX4wLft807Kvin7NtOyXTMselM7/r1S6bFNqMGN0gB22iQzG98+t5t9v6AU5lFKpke65u03gTmBDjJdnA1NNyz44ndugVLr06JDHE2NK6dw2MlBPfKmKR97VQK2Uarp0D8G6FLjWc537o1/wXOcuSfK6Os3boFTa9O6cx4zRAdoVRz5/zbOVPPuxXpBDKdU06Q7SB8sQqHjuBxo1l7dS2WLf7fJ59NwAJb4Mj1AILn6qgte/qkn0VqWUSijdQbq95zqr470or3VI8zYolXZH7FzAA8MD5Pt+UdW1MGZakA++0wtyKKUaJ91B+hfTsneM96Jp2bvLxTCUynkn7VnApEElEc8Fq+GcqeV8uVwDtVKq4dIdpF8Frknw+nXAi2neBqUyZuBBhfxf/8gO6nVBOGtKkO/W6DzfSqmGSfc46RuABaZldwdukVnHCoD9gL8CB8hFMZRqMcYcVcTa8hC3vrolw3vFxhBnPVTOs+NL6dou49e1UUrlqHSPk/4a6AvsAbwlTds/Ax7QETjBc53v07kNSjWHK04qYvSRkRfkWLomxNkPBVkf1AnrlFLJSfspvec67wB7A4cCQ4Ezgf081znIc52P0v3/lWoOhmHwj/7F2AdGNlZ9/nMd50wNUl6lgVopVb+MtLt5rhPyXGeBXKHqNc91Ps/E/1WqOeXlGUwaVMKJe+RHPP/+d7WcPz1Ida0GaqVUYmm/VKVp2W2AfwDnAJ3k6RXAQ8A/PNepTOsGpIceXZOgFzTYrLwqxNCHgsxfGpnhbR9YwF2D678gh5Zjamg5poZeYCOz0j0taDEwFzhbpgcdIvcfAM4DXjctO93Ja0o1q9Iig0dHBtinR+TPzfmohr/NriQT13RXSuWmdAfIy4AgsJvnOhv9L5iWfSvwAvAH4NY0b4dSzapDwODx0QFOv6+cpWu2BOWH3qlmm1KDK83ihO9XSrVO6e6THgxcER2g2dxPvQG4SmrWSrV4Xdvl8eSYUrq1i2zxu/XVKh6cpxfkUEptLd1BemfgvQSvvwf0TvM2KJU1enXK44kxAToGIp//2+xKZi7UC3IopSKlO0gn05yuiQSqVdmzez7Tzi0lEDmMmkufrsD7Qi/IoZTaIt1B+lvgsASv9wGWpnkblMo6h+yYz0PnBCj0jc6qrYPzpwd591sN1EqpzdIdpGcBt5iWXRr9gmnZHYHbgCfTvA1KZaXjdi/griElGL62pIoaGDE1yGfL9IIcSqn0Z3ffIjOMfW1a9t3Al/I/9wUuAL7XzG7Vmp22fyHrgiGu9k0XsLEShj4U5NnxpfTurPN8K9WapXvu7jLgaOA54EpgJvAEMA54BDjGcx1Na1Wt2ojDi/hT36KI51ZvCjHkwXJ+Xq9XzlKqNUv7jGNhpmUbQBeg2nOdtRn5p+mjs08kQWd4Sl4oFOK6OZXcPzcyw3v3rnk8NGA9u+yk5dhUuj+mhs44llmZbEvbWxLFjjUte7cM/l+lsp5hGEzoV8yQ30T2QH21so4L/1NKWaWeFyrVGmVi7u79pGn7AN9ZVAh4Bxgll7PMNXrETILWXBqupjbE2OkVvLgoMsP72N3yeXRkgOICrYg0lu6PqaE16cxK99zdPYE3gOXA8UBXoAdwErAJeMu07G7p3AalcklBvsG9Q0vo0zvyyllvfl3LxU9WUFun54dKtSbpzu6+GnjWc53RUc+vkItrPAz8Seb4VkoBJYUGU0cEOPOBcj75aUvi2OxPa2gfqOQWuxjD0AqJUq1BuvukTwFuSPD6jUC/NG+DUjmnXYnB9FEBdukS+ROdPr+am17SARFKtRbpDtLdPdf5Jt6L0h/dI83boFRO6tx28zzf3dpGDsO6840q7ntTA7VSrUG6g3StadmBeC/KTGSV8V5XqrXbvmMekwcE2aY0snn7OreSJz7QC3Io1dKlO0h/Ik3e8ZwGfJrmbVAqp/XuVMfjowO0iZzvhCueqcD9TAO1Ui1ZuoP0Q8Ak07J/E/2CadnHAncAD6R5G5TKeQdun8/UEQGKfEnfdSG4YEYF877RC3Io1VJlYpz0Y8BZwOvAF765u48CHvRcZ1xaNyA9dBxMEnRcamr4y/GFz6s577EK/COx2hTBzPNLOXD7/PgrUbo/poiOk86stM845rnOcGAYUC7jo4+ScdOn52iAVqrZnLJPIbcOLIl4rqwKhj0c5OuVeuUspVqajM3dnSqmZY+W8dc7AsuAOz3XuV2az1+O8ZZC4FHPdUbFWNdSoCcQfXTb33OdrxJsRm4VWjPRmktqxCrH+96s4jo3Mudyuw4Gz15QyvYd9cpZsej+mBpak86sdE9mUi/Tshd6rnNQkssOAf4ODAE+kpr5baZlz/Vc502gJGr57SR5bWqC1Y71XCfR60plnfHHFrGmPMRdb2wZirVsfYizpgT5z7gAndtqoFaqJWj2IA3s2YBlJwBXea7znjyeI3/xTAae9lznv03cRqWyzp/7FrGuPMRj87dkeH+zqo5hDweZObaUdiVaaVEq12VDkE6q6di07B7AXkC+adkfAHsAS4AbPNd5KsbyNnAYMLyeVQ8yLftqYDvga+Baz3Web/SnUSpDDMNg4hnFrA+GmP3plgzvT36qY9SjQR4bFaCkUAO1UrksG4J0snrJ7XhgqPRHnwc8aVr2Cn9t2bTsAmAicL3nOusSrPMT4BvgfGAjcCnwnGnZR3mu8068N/2yajl1tXXxXlaipqaa1cuXNfdm5Lz6yvHa38Lq9QHe+X7Lz3neklpGP7yW206toEBbvkH3x5RpSjlqTkDD5VKQDm/rdb7LW04yLXsYMArwN2kPBDrLOO24PNc5Leqp603LPl2Cdtwg3alL90Z/iNZEE3VSI5lynDYmxOAHy/nwhy0nj68vKWTivAC3DSwhL09r1Lo/poaWY2alNUiblv1oEosVJrm61XK7Nur5JTHm/x4BPOW5TnmS6/ZbrPOJq1zTpthg2rml2PeX89XKLYH6yQU1dAxUMqGfXjlLqVyU7oawHZL4m5vkuhZLoD486vldgW/DD0zLbgOcALyYaGWmZe9sWva9pmV3jHppH+mbViqndGpj8MSYADtsExmM759bzZ1v6AU5lMpFaa1Je65zfArXVWta9m3ABNOyF0p/8ljgILkN21eGYn0cvQ7Tsm8CenmuM0wmVOkPtDct+2KgCrgS2E2ay5XKOT065PHEmFJOv6+c1Zu25GTe9FIVHUsNRhxelPD9SqnskmspJROBu4GZwBrgXKC/5zoLfcv0lNtVMd7fQyZBwXOdoIyzbis15++B44DjPNf5X2Y+jlKp17tzHjNGB2hXHPn8n/5TyXOf6AU5lMolOTfjWJbQQkuCJpikRmPL8d1vaxg6JUiF7/obhfnwyMgAx++eSzmjqaH7Y2rojGOZlWs1aaVUko7YuYDJwwLk+37l1bUwZlqQBd/rPN9K5QIN0kq1YOZeBUwaFHlBjmA1DH+4nC+Xa6BWKttpkFaqhRt4UCH/1z+yg3pdEM6aEuT7X3RSHqWymQZppVqBMUcVccWJkZndKzaGGDKlnJUbNVArla00SCvVSlxxUhGjj4ycO2jpmhBnPxRkfVBzIZXKRhqklWolDMPgH/2LsQ+MzOz+/Oc6RjwSpLxKA7VS2UaDtFKtSF6ewaRBJZy4R37E8/OX1jLu8SDVtRqolcomGqSVamUK8w0mDwtw2E6RgfqVL2vp9ZdNHDJxE7MW6jSiSmWD1jejgVKK0iKDR0cGGDi5nM9/jkwc+2ldiEuequTpD6s5apcCurbLo1t7g27tDLq2y2ObUvRiHUpliAZppVqpDgGDx0cHOPimMqIvj14bgje+ruONr7euURcXQJe2Bt3abw7am4O3IYF8S0Dfto2hl8hUqok0SCvVinVtl0ddA0dgVdbAj+tC/LguBMR/c37e5mDetZ3UwttvDui/BvN2Bl3bG3Rpa1CYr8FcqVg0SCvVyvXsaEjATa3aOli+IcTyDeF1x57hzDCgU6nxa9DeHMj9NfQt993PqrnppSp+WheiZ0eDa/oWMeAgvbKXark0SCvVyl3Tt4grZ1US9F0gqzAf+u2TT5d2eazcGGLFxhArN9axYkOIshTnlIVCsKYsxJqyEIuWJ/++H9eFuHJWJYAGatViaZBWqpULB7hka6hllZuD9vINdZsD+AYJ4BtDvz5esaGO9RXp3/ZgNfzfC1UapFWLpUFaKcWAg5JvNm5TbNC72KB358QjOIPVIVZJLXxFOKDL/RUbQ6zcsPnxmrKmNbX/vCHEHa9VMu6YIgKF2retWhYN0kqptAgUGvTqZNCrE0B+3OWqa0Os2rQlaC/3BfSVG7bU0Lf0bW/tny9XMe29av7Ut5iBBxZoVrlqMTRIK6WaVWG+wXYdDLbrkHi5mQuquMqppKIm9uvL1oe45KkKHpyXx4R+xfTprYc3lft0xjGlVE448zdF3DqwmO07GhhAhwCUFm693Cc/1TFwcpBzHw3yzSq9wpfKbXqqqZTKGdF95+vKQ0x6vZIpb1dTHTXC66VFNbz6ZQ0jjyjkshM1sUzlJq1JK6VyVsdSgwn9Snjr8jb032/rOkdNHUx5u5o+t5QxdUEhlTV6ARGVWzRIK6Vy3o7b5jF5WIDnLijlN722PqxtqIBb3yrh2NvKeO6TakIhDdYqN2iQVkq1GIfumM/sC0q5b2gJO2yzdYb397+EGPd4BafdW84H38WeAU2pbKJBWinVohiGwekHFPLm5W34dO36+AAAEtxJREFU2ynFtC/ZepkPvq+j/73ljHs8yHdrNLlMZS8N0kqpFqmk0ODC3xbx9lVtGH1kIfnG1k3cz31Sw7G3lXHdnArWB7UJXGUfDdJKqRZt2zZ53HB6Cc45ZfTda+vksqpauO+tao68ZRMPzquiulaDtcoeGqSVUq3Czp1CTB0Z4JmxAfbrufWhb205/G12JcfdXsYLn2tymcoOGqSVUq1Kn10KePGiUiYNKqFH+62Ty5asDjF6WgUDJwf5+EdNLlPNSyczUUq1Onl5BoN/U8ip+xUweW4Vd75RRXnUJTjf+baW391VTqAQKqrR61erZqE1aaVUq1VaZHDpCcW8c1Ubhh1WSKzrcgSrISTXr75iViWzFqb4gtpKJaBBWinV6nVtl8e/BpTw6h9KOX73+FfsqqiGvzxXSY0ml6kM0SCtlFJiz+75PD66lBmjA3GXWReEEyeV8+r/ajS5TKWdBmmllIpy3O4F9OwY/5rUX62sY/jDQc6aEuTzZZpcptJHg7RSSsXw575FBGJcCtPvzcW1mHeWc/nMCpZv0JnLVOppkFZKqRgGHFTEvwZsuX519/YGh+9oYERVsEMhmPHB5itt3fpKJeVV2gSuUsfItT4V07JHA1cDOwLLgDs917ndtOxjgZdjvKUQeNRznVEx1hUAbgEGAe2Bz4E/eq7zWj2bkVuF1kxWL19G5+7bNfdm5Dwtx9RIVTl++lMt182pZN6S2M3c3dsbXH1yMYMOLiA/Vrp4jmtiOba8AkmznBonbVr2EODvwBDgI+Ak4DbTsud6rvMmUBK1/HbAJ8DUOKu8BzgSOB74DhgPzDEte3/Pdb7OzKdSSuWS/Xrm8/TYAK98Wcv1biWLV0U2cy/fEOKymRU8OC+PCf2KOWbXnDrMqiyTa3vPBOAqz3Xek8dz5C+eycDTnuv8N/oF07I7AcOBMz3XWSRP32pa9jAJ1lek5yMopXKdYRiYexVw3O75TJ9fzS2vVPFLWWQD2+c/1zH4wSAn7ZnPX08pZo9u8Yd2KRVPzgRp07J7AHsB+aZlfwDsASwBbvBc56kYy9vAYRKIYzlYPv/7Uc/PB45Iz6dQSrUkhfkG5x5ZxICDCrnzjSoemFtFZU3kMq98WcvrX5Uz7NBCrjKL6Nw291KBZi2s4qaXqvhpXYju7drwV6tKZ17LkJwJ0kAvuR0PDJX+6POAJ03LXuGvLZuWXQBMBK73XGddnPV1lds1Uc+vBron2pBfVi2nrlYzOetTU1PN6uXLmnszcp6WY2qkuxzHHQj9extMmleM+7/ItPDaOnj0vWqeWVjFeYdUMfzgKkpy5Og758sCrn2lhIqazd3JP2/M44pnKti4fh399qyp9/1+mlvRcDmym4BvW6/z9RdPkubpUYC/SXsg0Bl4qBH/x6gvMaxTl4QxXAlNeEoNLcfUyEQ5du4OU3aHhT/Ucu2cSuYvjUwuK6symPR2MXe9U0xtaPN84H/O8vnA/zl5IxVRsbiixuCud0sZeVzb5tqsViOX2l1Wy+3aqOeXAD2inhsBPOW5TnmC9S2X2y5Rz3f1vaaUUg120A75/GdcgAeHl7DztlsnNIdnFf1pXYhLZ1YyfX52zgc+c0EVa+McRX9ap4NcMiGXgvRiCdSHRz2/K/Bt+IFp2W2AE4AX61nfAqBKsrv9+gDzUrfZSqnWyDAM+u1byBuXteH6U4vpGGem0epauGpWJX+bXcF3a7KrG+0vsyvjvpZoRjaVOjnT3O25Tq1p2bcBE0zLXihDq8YCB8lt2L4yFOvj6HWYln0T0MtznWGe66w3LXsKcJNp2YtkCNYVMv76nsx+OqVUS1VUYDD26CIGHVzIXtdvirlMCHhwXjVT3q6m714FjD26kCN3zseInjklQ2YtrGLCnCo2VMRf5pq+2dtE35LkTJAWE6X2PxPYFvgS6O+5zkLfMj3ldlWM9/eQIBx2GfBP4HWgnYy9Ptlzne/S/DmUUq1Mx1KD7Tsa/JigmTgUghcX1fDiohr23S6PsUcVcfoBBRQXZC5Yz1pYxeXPVG6Vpe5XnE9W96O3JDk341iW0EJLgiY8pYaWY2pkQznOWljFlbMqCVYn/54ubQ3OPaKQEUcUpn341tcra+l7Z3m923fkznnMGtemMf9C28gbKNdq0koplbPCtc/wmOOeHQ2uPKkIwzB4YG4Vn/28dZ/0qk0hbnmlitteraK4EIJVsF0Ks8JnLaziereKFRuTr3t0CORSOlNu05p042ihJSEbai4tgZZjamR7OYZCId75tpYH5lbz0hc11HdozjOgT+88rH0L2bNbHnt2z2eb0vorqmWVIT77uZaPf6xj9idVLPg+1OAD2qE75vPcBaUNfBdoTbrhtCatlFJZwDAM+vQuoE/vApauqWPK21XMeL+asjijs+pCMPebOuZ+syUDu1s7gz2657FXtzw2VYXwFtWyalOI9gHYo6vBuqDB4lV11DUwKhcXENFHvfCHWmYt1FnHMkFr0o2jhZaEbK+55Aotx9TIxXLcUBHiiQ+qmfB8/KFQ6dKzo8EyaZLv0zuPpz6MnJglUAj/GlDc0ECtNekG0o4FpZTKUu1LDM4/uijjY5K372jwwZ/asmxiO97/U1vmLdm6rzxYvblvXaWXBmmllMpyf+5bRCByOnCK8uG0/fMZcGABe3fPo7ABF9napbOBfWABAw7Mpziq0zNQuPUY6GVxho3prGPpp33SSimV5WJlhV8Tld1dXRvi2zV1fLm8jiufqWBjjBbyzm0N5l3ZhvYlW2rmJ/qucBVrvUjTd6zx3TrrWPppkFZKqRww4KDEQ64K8w1275rP7l3zqakNbTUeO1AI1/UrigjQyawXmV0s1vp01rH00yCtlFItTDI178avr46eHfOatD6VPM3ubhwttCTkYjZtNtJyTA0tx9RoYjlq+3gDaeKYUkoplaU0SCullFJZSoO0UkoplaU0SCullFJZSoO0UkoplaU0u1sppZTKUlqTVkoppbKUBmmllFIqS2mQVkoppbKUBmmllFIqS2mQVkoppbKUBmmllFIqS2mQVkoppbKUXqpSNYpp2QHgFmAQ0B74HPij5zqvxVj2WODlGKspBB71XGdUZrY6+zSkHGX5PYGbgT5Sfl8C13uuMyfzW589GlGO2wMTgROADsBC4FLPdT7I/NZnF9OydwYeBn4L7Oy5ztIEyzao3FXDaU1aNdY9wEnA8UBnYAYwx7Ts3aIX9FznTc91Svx/QG9gLTC1eTY/ayRdjqZlG8BLwEZgF1l+Ov/f3r0HW1XVARz/XkEgCkpAAksEVJABzUeZkIEZi8fKsCWPqXiokIY9RrgIoz188XJGmbIykkSi4TFB07LURbJgkNQsGHQiYITREGHyAaIwAopwb//8juw53XvuOee+9j3n9/lnc/Y+Z+91fvdwfue39tp7wWOSvMtZIXFsBTwBdAc+D5wJbACisa5r8zQ/HYx1DvgHsCfPl+Qdd1UcraRVwYx1nYAJwJgY/A5ZvcBYNx6YCszIYzeLgNUx+I2N3NzUKiKOXYEewIoY/CHZx2LgQeBzUlWXnSLi2EfiNSgG/1/Zx53AROB6qQzLVSdgMHA2MCnXExvoe0DVQStpVYxL5Qfe5qz1m4Ar6nqx/Fq/HLij8ZrYIhQUxxj8m8BGYLKxrouxri3wXeBt4Omma3bqFPp5rJDlR99/Mfhq4C3gC43b1HSLwS+Owe/M8+n1+h5Q+dFKWhUj0yX4dtb6A0C3XC801rWWc4H3xuDfbbwmtgjFxHEcsAbYD1TLc8dIAi9XhcZxJ7ADmGusmwgcBqYA/YEjTdDeUlH094DKn1bSqiFVSOLIZbScu3q0idrUEtUYR2NdGzknvQv4NPAJ4C7gcWPdgOZpaqrVGMcY/ElglJzb/xewDfiU9EZ82DxNLSn5fA+oPGklrYrxhizPBPYl1ndNbKvNJGBVDP5oI7avpSg0jkOBi4GRMfi3ZN1CY90twGSgsgnanEYFfx5j8K8AX0+uM9a9CGxp1JaWlvp8D6g8aSWtirEFOA4MzFo/CHiuthcZ6z4ul7z8tfGb2CIUFcfEOdWM1mVeuRQcR2PdGGNdv8TjHjKYTC8dyl+xn19VAK2kVcFi8IdkVPF8Y90OuVxjBnCOXJKBsW4+0CMGPz7x0gFAO+liLHtFxPHvUqHcZ6ybJudPJwB9ZQBZWSry8zgZ6CCDGKuAhXKeenXzvpt0S8Yxn7ir+tNKWhVrulxrukEGMY0AhsXgM9dXdpf/rEmfkeX+Jm5rmuUdRxloNxzoLOel9wO3AGNj8M8079todoV+Hm+UAU8vA7uBo/L8sj4nbazbaax7Hwiyaqex7n1j3W/lcXYc64q7qqeK6upy7iVTSiml0ksraaWUUiqlNEkrpZRSKaVJWimllEopTdJKKaVUSmmSVkoppVJKk7RSSimVUnozE6WKZKx7GtgXg5+Qx3PPkYkdRsbgNzRSe1rLvadvjME3yTzdxrq1EoPJTXE8pcqNJmmlmoDc3KFdc7ejocXghzV3G5QqZdrdrZQqmFTtSqlGpv/RVMky1nUGfg58TX6Qbgd+FIPfaKzrAvwbWBCDf0CePxhYB1wJvCO33rwGmCP3x94D3BWDX1XL8W4AZgI9ZY7iPwPTY/DHjHU95faTJga/zlj3nExCcBy4SarsNdJVfUz2dzUwH7hQbmG5HrgtBn9AtvcHFsnEEPuA23LEYphMc9kzectGY91SoHcM/svGur4Sry8CreQe69Ni8C9wqnt/G9AHuMpY117i9VGXfx0xOF9iOlyeMxA4KDFdIq8/HZgHTJSpOF8EKmPwm2X7xcACaeN7cj/zyhj8qw3+AVIqBbSSVqVsGdABuEDmX14OrDXW9ZZE9x3gHmNdL2NdW0l482PwmxLzCs8CvgGcASwGVhrrLsw+kLHuMmAJcI8klyuBa4Hba2nbh8ANwGvA2cCX5DiTOXUO+wngNzLX8eVAN2ClbK8APPA6cBYwBJiSIxbr5bnjEm1uK8dcKqv+KJN29JBj7Qb+lLWfsTIZxcdi8CcKjEEmprPlns8dgd/JdJudZNsd0qbBEvNngaeMdR2NdR3kh8YGmR6xn8wJvUYre1Wq9IOtSpJMQzgCOC8x9/KvjXVTJDneGYN/0li3XJLOJvnCn521qwczlaex7meScK6VKjzpBaBzDP6gPH7FWPeMVHy1eTUGv0j+vc1Ytx3oL4+/B2zJVJjA68a6mcBWY11vmWTjfJlc4zBw2Fg3TxLc/4nBnzTWrZQkfb+stsDpiZmfrgCqEpX8H4BJxrpuMfjM/MB7Y/C+lveTbwyWxuC3yTFWAz8FzpO/wQ+BuTH4XbJ9DrBV2jkO+CAGP0f2c8xYd6v0MgzWaSZVKdIkrUpVX1luN9Yl158mXbYZlZJwhwCXZFeHMn0hnEp0r0mlma01MNNYN0Yq21aSWHLNTvVy1uNjQPtE+wfJjERJJ4FeUl0j1W7GzhzHQnoWKo11vWLwu4FvAY/F4A/J9quAn0i3d/tET1tywNt/cuw/3xgk3/cxWbY31n0S6JI8Rgz+SKL3oC/w2RpiUiXd60qVHE3SqlRVyfKsRGVXkzMk4Z0AzgVeytqefUqoIpFYkmZJ9TsWWC8JfYUkq7raWNu2J2Pwo2raaKz7tvwzOY1dqxz7Iwb/olTr44x1D8m5+utkf72ka/tXwPAY/OHEeeyk4zkOkW8ManvfFVnLbFXAthj8Rbnep1KlRM9Jq1K1S5aXJFfK+ecKTp3XXQKsAm4FHpEBZUkXJF7bWubSrWmu3IHAuhj8WklOp8mArvq0/yLZT+b47Yx1mYS3V5bJCrJfHvtdBoyWAXHvysAvgMuANsDd0n0OcGmBba5XDGS+7ANZMW9jrJshPyJ2Aeca6zomtlfINqVKklbSqiTF4F8y1j0F3G+sGyfdwqOAFcDVwPPAD6Rb+TqpHL8JPCxJLGOGsW6rjJ6ulIFoq2s45B5guCT5EzIC+QjQvchBTQuBacBsY9186TZ+ABhorBsA/BN4E/ixse4mGah1e1ZlXZPlMlr9ZmBZDP5kov0AXzXWPQ44YKSs6wHkM3q6IWLwEPB9Y12QXo1ZEvdH5W93L/ALY9104AMZaDZVuvDfy/MYSrUYWkmrUjZRzilnBoXdDUyKwT9vrOsD3AdMTVSONwPDjHXXJ/bxS0nKB4HxwOgY/N4ajjVXRmrvAbYAG6U67ySPCyKD1a4BhgL75TxtZ7ljWVUM/rgM/OoNvCHHexg4Kgm9tv3uBf4GfAX4fWL9ZnkPj0g1O1J+1DwL/MVYNySPZjdEDObJKPN1chncSHnP78jfaYT8aNgn73sgMFQTtCpVFdXVdf3wVqr8JK5r7qXX4CqlmotW0koppVRKaZJWSimlUkq7u5VSSqmU0kpaKaWUSilN0koppVRKaZJWSimlUkqTtFJKKZVSmqSVUkqplPof7pn4uLMr/RIAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "bento_obj_id": "140416897148096",
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# can plot variance explained on the x-axis\n",
        "\n",
        "plt.plot(explained_vars, MSE, \"-o\")\n",
        "plt.title(\"LOOCV MSE vs explained variance\")\n",
        "plt.xlabel(\"explained variance\")\n",
        "plt.ylabel(\"LOOCV MSE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1657820374420,
        "executionStopTime": 1657820375839,
        "hidden_ranges": [],
        "originalKey": "354bebfe-ef34-4e04-9705-013101cb55df",
        "requestMsgId": "354bebfe-ef34-4e04-9705-013101cb55df",
        "showInput": true
      },
      "outputs": [],
      "source": [
        "# on a bad day for PL with CI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "collapsed": false,
        "customInput": null,
        "customOutput": null,
        "executionStartTime": 1657819813258,
        "executionStopTime": 1657819814324,
        "hidden_ranges": [],
        "originalKey": "27035b96-2c40-436b-b50c-150de8e3cd0c",
        "requestMsgId": "27035b96-2c40-436b-b50c-150de8e3cd0c",
        "showInput": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "captumWidgetMessage": {},
    "dataExplorerConfig": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
    },
    "last_base_url": "https://devvm10848.prn0.facebook.com:8090/",
    "last_kernel_id": "42b08eac-443a-4ab0-8e52-64522130fe14",
    "last_msg_id": "e54ae62a-9ef63aa68d85aa153af8d86c_1114",
    "last_server_session_id": "a471731c-0244-4194-bd9a-452795d1da7f",
    "outputWidgetContext": {},
    "vscode": {
      "interpreter": {
        "hash": "f178f7686bb85c5c6e141a85fd4c17c3082d63b89f6cfaecdf98c22c0047a219"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
